{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#from music21 import *\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import math\n",
    "import numpy as np\n",
    "from cntk.blocks import default_options, LSTM, Placeholder, Input        # building blocks\n",
    "from cntk.layers import Embedding, Recurrence, Dense, BatchNormalization # layers\n",
    "from cntk.models import Sequential                                       # higher level things\n",
    "from cntk.utils import ProgressPrinter, log_number_of_parameters\n",
    "from cntk.io import MinibatchSource, CTFDeserializer\n",
    "from cntk.io import StreamDef, StreamDefs, INFINITELY_REPEAT, FULL_DATA_SWEEP\n",
    "from cntk import *\n",
    "from cntk.learner import adam_sgd, learning_rate_schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from cntk.ops import *\n",
    "from cntk.utils import get_train_eval_criterion, get_train_loss\n",
    "from cntk.initializer import glorot_uniform, he_normal\n",
    "def print_training_progress(trainer, mb, frequency):\n",
    "\n",
    "    if mb % frequency == 0:\n",
    "        training_loss = get_train_loss(trainer)\n",
    "        eval_crit = get_train_eval_criterion(trainer)\n",
    "        print(\"Minibatch: {}, Train Loss: {}, Train Evaluation Criterion: {}\".format(\n",
    "            mb, training_loss, eval_crit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_model(hidden_dim,num_output):\n",
    "    with default_options(initial_state=0.1):\n",
    "        return Sequential([\n",
    "            Recurrence(LSTM(hidden_dim), go_backwards=False),\n",
    "            Dense(num_output)\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_reader(path, is_training,num_input,num_output):\n",
    "    return MinibatchSource(CTFDeserializer(path, StreamDefs(\n",
    "         features = StreamDef(field='input', shape=num_input,  is_sparse=True),\n",
    "         label = StreamDef(field='output ', shape=num_output, is_sparse=True),  \n",
    "         # slot_labels   = StreamDef(field='S2', shape=num_labels,  is_sparse=True)\n",
    "     )), randomize=is_training, epoch_size = INFINITELY_REPEAT if is_training else FULL_DATA_SWEEP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train_sequence_classifier(debug_output=False): \n",
    "    hidden_dim = 64\n",
    "    num_input = 159\n",
    "    num_output = 158\n",
    "    \n",
    "    epoch_size = 1020        # 18000 samples is half the dataset size \n",
    "    minibatch_size = 1\n",
    "\n",
    "    #input_dim = 2000\n",
    "    #cell_dim = 25 \n",
    "    #hidden_dim = 25 \n",
    "    #embedding_dim = 50 \n",
    "    #num_output_classes = 5 \n",
    " \n",
    " \n",
    "    # Input variables denoting the features and label data \n",
    "    features = input_variable(shape=num_input, is_sparse=True, dtype=np.float32,name='input') \n",
    "    label = input_variable(shape=num_output, is_sparse=True, dtype=np.float32,name='output') \n",
    " \n",
    " \n",
    "    # Instantiate the sequence classification model \n",
    "    classifier_output = create_model(hidden_dim, num_output)\n",
    "    \n",
    "    # prediction\n",
    "    model = classifier_output(features)\n",
    "    \n",
    "    # Log-loss function\n",
    "    ce = times_transpose(label,log(model))\n",
    "    # Other cost function also tested:\n",
    "    # ce = reduce_mean(square(model - label), axis=0)\n",
    "    # ce = cross_entropy_with_softmax(model, label)\n",
    "    # ce = sum(times(label,log(model)))\n",
    "    \n",
    "    # Error function\n",
    "    pe = classification_error(model, label)\n",
    "    # Other error functions also tested\n",
    "    # pe = reduce_mean(square(model - label), axis=0)\n",
    "    # pe = times_transpose(label,log(model))\n",
    "    # pe = cross_entropy_with_softmax(model, label)\n",
    "    # pe = sum(times(label,log(model)))\n",
    " \n",
    "    # Get and read path\n",
    "    path = \"data/MidiSongTrain.txt\"\n",
    "    reader = create_reader(path, is_training=True,num_input=num_input,num_output=num_output)\n",
    " \n",
    " \n",
    "    # Set features and labels\n",
    "    input_map = { \n",
    "        features : reader.streams.features, \n",
    "        label    : reader.streams.label\n",
    "    } \n",
    " \n",
    "    # Set learning rate\n",
    "    #lr_per_sample = [0.003]*4+[0.0015]*24+[0.0003]\n",
    "    #lr_per_minibatch = [x * minibatch_size for x in lr_per_sample]\n",
    "    #lr_schedule = learning_rate_schedule(lr_per_minibatch, epoch_size, UnitType.minibatch)\n",
    "    lr_per_sample = learning_rate_schedule(0.0005, UnitType.sample) \n",
    "    \n",
    "    # Instantiate the trainer object to drive the model training \n",
    "    trainer = Trainer(model, ce, pe, sgd(classifier_output.parameters, lr=lr_per_sample)) \n",
    " \n",
    " \n",
    "    # Get minibatches of sequences to train with and perform model training \n",
    "    training_progress_output_freq = 10 \n",
    " \n",
    " \n",
    "    if debug_output: \n",
    "        training_progress_output_freq = training_progress_output_freq/3 \n",
    " \n",
    " \n",
    "    for i in range(251): \n",
    "        mb = reader.next_minibatch(minibatch_size, input_map=input_map) \n",
    "        trainer.train_minibatch(mb) \n",
    "        print_training_progress(trainer, i, training_progress_output_freq) \n",
    " \n",
    " \n",
    "    import copy \n",
    " \n",
    "    evaluation_average = copy.copy( \n",
    "        trainer.previous_minibatch_evaluation_average) \n",
    "    loss_average = copy.copy(trainer.previous_minibatch_loss_average) \n",
    " \n",
    "\n",
    "    return evaluation_average, loss_average \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Inside File: Matrix.cpp  Line: 4608  Function: Microsoft::MSR::CNTK::Matrix<float>::MultiplyAndWeightedAdd  -> Feature Not Implemented.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-4faaf673cd82>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[1;31m#train(reader, model)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0merror\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_sequence_classifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Error: %f\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0merror\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-b41036d18ffc>\u001b[0m in \u001b[0;36mtrain_sequence_classifier\u001b[0;34m(debug_output)\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m251\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0mmb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnext_minibatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mminibatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_map\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_map\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_minibatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m         \u001b[0mprint_training_progress\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_progress_output_freq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\local\\Anaconda3-4.1.1-Windows-x86_64\\envs\\cntk-py34\\lib\\site-packages\\cntk\\trainer.py\u001b[0m in \u001b[0;36mtrain_minibatch\u001b[0;34m(self, arguments, outputs, device)\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_map\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0mupdated\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTrainer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_minibatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marguments\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\local\\Anaconda3-4.1.1-Windows-x86_64\\envs\\cntk-py34\\lib\\site-packages\\cntk\\cntk_py.py\u001b[0m in \u001b[0;36mtrain_minibatch\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1642\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1643\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtrain_minibatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1644\u001b[0;31m         \u001b[1;32mreturn\u001b[0m \u001b[0m_cntk_py\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrainer_train_minibatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1645\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1646\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtest_minibatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Inside File: Matrix.cpp  Line: 4608  Function: Microsoft::MSR::CNTK::Matrix<float>::MultiplyAndWeightedAdd  -> Feature Not Implemented."
     ]
    }
   ],
   "source": [
    "#train(reader, model)\n",
    "error, _ = train_sequence_classifier() \n",
    "print(\"Error: %f\" % error) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
