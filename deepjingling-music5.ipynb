{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from music21 import *\n",
    "import numpy as np\n",
    "import glob\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "from cntk import Trainer, Axis\n",
    "from cntk.learner import adam_sgd, momentum_sgd, momentum_as_time_constant_schedule, learning_rate_schedule, UnitType\n",
    "from cntk.ops import input_variable, classification_error, squared_error\n",
    "from cntk.persist import load_model, save_model\n",
    "from cntk.blocks import LSTM, Stabilizer\n",
    "from cntk.layers import Recurrence, Dense, Dropout, BatchNormalization\n",
    "from cntk.utils import get_train_eval_criterion, get_train_loss\n",
    "from cntk.device import set_default_device, gpu\n",
    "\n",
    "path = \"midiFilesTest\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lowerBound = 24 # = [python] index 0 ([R] 1. possision)\n",
    "upperBound = 102 # = first index out of bound => len =78\n",
    "nNotes = upperBound-lowerBound\n",
    "notesDim = nNotes*2\n",
    "hidden_dim = 512#256#nNotes\n",
    "num_layers = 2\n",
    "\n",
    "\n",
    "batch_len = 16*8 # length of each sequence\n",
    "\n",
    "def loadPieces(midiFiles):\n",
    "    pieces = {}\n",
    "    totalLength= len(midiFiles)\n",
    "    fnameNumber=0\n",
    "    for fname in midiFiles:\n",
    "        fnameNumber+=1\n",
    "        if fname[-4:] not in ('.mid','.MID'):\n",
    "            continue\n",
    "        isNotBackSlash=1\n",
    "        bIndex=0\n",
    "        while(isNotBackSlash):\n",
    "            bIndex-=1\n",
    "            if fname[bIndex]=='\\\\':\n",
    "                bIndex+=1\n",
    "                isNotBackSlash=False\n",
    "        name = fname[bIndex:-4]\n",
    "        print(\"Loading\",name,\"...\",fnameNumber,'/',totalLength)\n",
    "        outMatrix = midi2MusicMinMatrix(fname)\n",
    "        if len(outMatrix) < batch_len:\n",
    "            print(\"     Loaded\", name,'failed')\n",
    "            continue\n",
    "        else:\n",
    "            print(\"     Loaded\", name,'done')\n",
    "        pieces[name] = outMatrix\n",
    "    return(pieces)\n",
    "\n",
    "\n",
    "\n",
    "def midi2MusicMinMatrix(parseLink):\n",
    "    midiFile = converter.parse(parseLink)\n",
    "    #if (midiFile.flat.getTimeSignatures().timeSignature.numerator not in (2,4)) or (midiFile.flat.getTimeSignatures().timeSignature.denominator not in (2,4)):\n",
    "    #\tprint('     Track: is not 4/4 or similar')\n",
    "    #\treturn(0)\t\n",
    "    if (midiFile.flat.getTimeSignatures().timeSignature.numerator not in (2,4)) or (midiFile.flat.getTimeSignatures().timeSignature.denominator not in (2,4)):\n",
    "        print('     Track: is not 4/4')\n",
    "        printing = '     Track is '+str(midiFile.flat.getTimeSignatures().timeSignature.numerator)+' / ' + str(midiFile.flat.getTimeSignatures().timeSignature.denominator)\n",
    "        print(printing)\n",
    "        return(0)\t\n",
    "    midiPartLen=len(midiFile)\n",
    "    maxTime = midiFile.highestTime\n",
    "    outMatrix = [[[0,0] for tang in range(upperBound-lowerBound)]+[[lenTimes16/4]] for lenTimes16 in range(math.ceil(maxTime*4+2))]\n",
    "    # outMatrix = [[[0,0] for tang in range(upperBound-lowerBound)]+[lenTimes16/4] for lenTimes16 in range(math.ceil(maxTime*4+2))]\n",
    "    for t in range(midiPartLen):\n",
    "        try:\n",
    "            instrument=midiFile[t].getInstrument(returnDefault=False).instrumentName\n",
    "        except: \n",
    "            instrument='Piano'\n",
    "        #if not instrument:\n",
    "        #\tinstrument='Piano'\n",
    "        #if instrument!='Piano':\n",
    "        #\tprint('          Part',t,'/',midiPartLen-1,' dropped, instrument was not piano')\n",
    "        #\tcontinue\t\t\t\n",
    "        notes=midiFile[t].flat.notes\n",
    "        for i in range(0,len(notes)):\n",
    "            if not notes[i].isChord:\n",
    "                if (notes[i].pitch.midi<lowerBound) or (notes[i].pitch.midi>=upperBound):\n",
    "                    continue\n",
    "                timeIndex=round(notes[i].offset*4)+1\n",
    "                notePitch=notes[i].pitch.midi-lowerBound\n",
    "                outMatrix[timeIndex][notePitch]=[1,1]\n",
    "                for holdLen in range(1,round(notes[i].duration.quarterLength*4)):\n",
    "                    outMatrix[timeIndex+holdLen][notePitch][1]=1\n",
    "            else:\n",
    "                timeIndex=round(notes[i].offset*4)+1\n",
    "                duration=round(notes[i].duration.quarterLength*4)+1\n",
    "                for j in range(len(notes[i])):\n",
    "                    if (notes[i][j].pitch.midi<lowerBound) or (notes[i][j].pitch.midi>=upperBound):\n",
    "                        continue\n",
    "                    #timeIndex=round(notes[i][j].offset*4)+1\n",
    "                    notePitch=notes[i][j].pitch.midi-lowerBound\n",
    "                    outMatrix[timeIndex][notePitch]=[1,1]\n",
    "                    for holdLen in range(1,duration):\n",
    "                        outMatrix[timeIndex+holdLen][notePitch][1]=1\t\n",
    "    return(outMatrix)\n",
    "\n",
    "def MusicMinMatrix2midi(MusicMinMatrixPart,S,bpm=100):\n",
    "    #S = stream.Score()\n",
    "    nTime=len(MusicMinMatrixPart)\n",
    "    S.insert(0,tempo.MetronomeMark(number=bpm))\n",
    "    p1 = stream.Part()\n",
    "    p1.id = 'part1'\n",
    "    nCons=0\n",
    "    thisIndex=0\n",
    "    mLen = len(MusicMinMatrixPart[0])\n",
    "    for j in range(mLen-1):\n",
    "        for i in range(nTime):\n",
    "            if (nCons!=0) and (MusicMinMatrixPart[i][j] in ([0,0],[1,1])):\n",
    "                n.duration.quarterLength = 0.25*nCons\n",
    "                p1.insert(MusicMinMatrixPart[thisIndex][mLen-1][0],n)\n",
    "                nCons=0\n",
    "            if MusicMinMatrixPart[i][j]==[1,1]:\n",
    "                n = note.Note()\n",
    "                n.midi = lowerBound+j\n",
    "                thisIndex = i\n",
    "                nCons+=1\n",
    "            elif (MusicMinMatrixPart[i][j]==[0,1]) and (nCons!=0):\n",
    "                nCons+=1\n",
    "        if (nCons != 0):\n",
    "            n.duration.quarterLength = 0.25*nCons\n",
    "            p1.insert(MusicMinMatrixPart[thisIndex][mLen-1][0],n)\n",
    "            nCons=0\n",
    "    S.insert(0,p1)\n",
    "    \n",
    "    \n",
    "def Piece2Data(Pieces):\n",
    "    tempData = sum(list(Pieces.values()),[])\n",
    "    data=[sum(timePart,[]) for timePart in tempData]\n",
    "    return(np.array(data,dtype=np.float32))\n",
    "    \n",
    "\n",
    "def get_data(p, minibatch_size, data):\n",
    "    x = data[p:p+minibatch_size,0:156]\n",
    "    y = data[p+1:p+minibatch_size+1,0:156]\n",
    "    #xsum=x.sum(axis=1, keepdims=True)\n",
    "    return([x],[y])\n",
    "\n",
    "def data2MusicMatric(data):\n",
    "    timeIndex=0\n",
    "    MusicMatrix=[0]*len(data)\n",
    "    MusicMatrixRow=[0]*(upperBound-lowerBound)\n",
    "    for i in range(len(data)):\n",
    "        for j in range(upperBound-lowerBound):\n",
    "            MusicMatrixRow[j] = [int(data[i,j*2]),int(data[i,j*2+1])]\n",
    "        MusicMatrix[i] = MusicMatrixRow+[[timeIndex]]\n",
    "        timeIndex+=0.25\n",
    "    return(MusicMatrix)\n",
    "\n",
    "\n",
    "\n",
    "def Output2data(p):\n",
    "    p=p[0][0]\n",
    "    return((p>np.random.random_sample((1, len(p))))*1)\n",
    "    # return(list((p>p.mean()+threshold)*1))\n",
    "\n",
    "# prime_data=data[5:20,:]\n",
    "def sample(z,prime_data=np.array([[0]*((upperBound-lowerBound)*2)],dtype=np.float32),length=300):#,threshold=1.11):\n",
    "    output=np.zeros((length, 156), dtype=np.float32)\n",
    "    if len(prime_data[0])!=156:\n",
    "        prime_data[:,0:156]\n",
    "    randomNumb=np.random.choice(range(78))\n",
    "    if len(prime_data)==1: \n",
    "        prime_data[0,randomNumb*2] = 1\n",
    "        prime_data[0,randomNumb*2+1] = 1\n",
    "    for i in range(len(prime_data)):\n",
    "        x=prime_data[i]\n",
    "        inputen=[np.array([x],dtype=np.float32)]\n",
    "        # inputen=[np.array([data],dtype=np.float32)]\n",
    "        # inputen=[np.array([x/np.maximum(x.sum(),1)],dtype=np.float32)]\n",
    "        if i==0:\n",
    "            arguments=(inputen,[True])\n",
    "        else:\n",
    "            p = z.eval(arguments)\n",
    "            arguments=(inputen,[False])\n",
    "        \n",
    "        \n",
    "    #x=prime_data[len(prime_data)-1]\n",
    "    for i in range(length):\n",
    "        p = z.eval(arguments)        \n",
    "        output[i,:]=Output2data(p)# ,threshold=threshold)\n",
    "        x=output[i,:]\n",
    "        inputen=[np.array([x],dtype=np.float32)]\n",
    "        # inputen=[np.array([x/np.maximum(x.sum(),1)],dtype=np.float32)]\n",
    "        arguments=(inputen,[False])\n",
    "    return(output)#return([list(testout[i]) for i in range(300)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading in-the-bleak-midwinter ... 1 / 3\n",
      "     Loaded in-the-bleak-midwinter done\n",
      "Loading jingbellPiano ... 2 / 3\n",
      "     Loaded jingbellPiano done\n",
      "Loading o-holy ... 3 / 3\n",
      "     Loaded o-holy done\n"
     ]
    }
   ],
   "source": [
    "midiFiles = glob.glob(path + '/*.mid')\n",
    "Pieces = loadPieces(midiFiles)\n",
    "# data = Piece2Data(Pieces)\n",
    "# data=np.load('dataNpArray.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "songs=list(Pieces.keys())\n",
    "ArrPieces= {}\n",
    "for i in range(len(songs)):\n",
    "    BrakComb=[sum(timePart,[]) for timePart in Pieces[songs[i]]]\n",
    "    ArrPieces[songs[i]] =np.array(BrakComb,dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train_mm(Pieces,songs):\n",
    "    #songs=list(Pieces.keys())\n",
    "    # create the stabilizer function from blocks\n",
    "    stabilize = Stabilizer()\n",
    "    #data = Piece2Data(Pieces)\n",
    "    #data_size=len(data)\n",
    "\n",
    "    # Source and target inputs to the model\n",
    "    batch_axis = Axis.default_batch_axis()\n",
    "    input_seq_axis = Axis('inputAxis')\n",
    "\n",
    "    input_dynamic_axes = [batch_axis, input_seq_axis]\n",
    "    raw_input = input_variable(shape=(notesDim), dynamic_axes=input_dynamic_axes)\n",
    "    raw_labels = input_variable(shape=(notesDim), dynamic_axes=input_dynamic_axes)\n",
    "\n",
    "    input_sequence = raw_input\n",
    "    label_sequence = raw_labels\n",
    "\n",
    "    # LSTM\n",
    "    encoder_output = stabilize(input_sequence)\n",
    "    for i in range(0, num_layers):\n",
    "        encoder_output = Recurrence(LSTM(hidden_dim, enable_self_stabilization=True)) (encoder_output.output)\n",
    "        #encoder_output = BatchNormalization() (encoder_output.output)\n",
    "        encoder_output = Dropout(0.2) (encoder_output.output)\n",
    "\n",
    "    # get output of the LSTM\n",
    "    states = encoder_output.output\n",
    "\n",
    "    # dense layer    \n",
    "    z = Dense(notesDim) (states)\n",
    "    \n",
    "    import cntk.ops \n",
    "    # ce = binary_cross_entropy(z, label_sequence)\n",
    "    # ce = cntk.ops.squared_error(z,label_sequence)\n",
    "    # ce = times_transpose(label_sequence,log(z)) \n",
    "    # ce = cross_entropy_with_softmax(z, label_sequence)\n",
    "    # ce = times_transpose(label_sequence,log(z))\n",
    "    ce = squared_error(z,label_sequence)\n",
    "    # errs = squared_error(z,label_sequence)\n",
    "    errs = classification_error(z, label_sequence)\n",
    "\n",
    "    # Instantiate the trainer object to drive the model training\n",
    "    lr_per_sample = learning_rate_schedule(0.0005, UnitType.sample)\n",
    "    momentum_time_constant = momentum_as_time_constant_schedule(1100)\n",
    "    clipping_threshold_per_sample = 5.0\n",
    "    gradient_clipping_with_truncation = True\n",
    "    learner = adam_sgd(z.parameters, lr_per_sample, momentum_time_constant, \n",
    "                           gradient_clipping_threshold_per_sample=clipping_threshold_per_sample,\n",
    "                           gradient_clipping_with_truncation=gradient_clipping_with_truncation)\n",
    "    trainer = Trainer(z, ce, errs, learner)\n",
    "    \n",
    "    minibatch_size = 128 \n",
    "    loopsPrPrint = 10\n",
    "    #training_progress_output_freq = 100\n",
    "    #sample_freq = 20\n",
    "    epochs = 5\n",
    "    #minibatches_per_epoch = int((data_size / minibatch_size))\n",
    "    #minibatches = epochs * minibatches_per_epoch\n",
    "    \n",
    "    e = 0\n",
    "    p = 0\n",
    "    pnew = 0\n",
    "    \n",
    "    iSong=[iSong for iSong in range(len(songs))]\n",
    "    songEnd=False\n",
    "    songLen=0\n",
    "    printCounter=0\n",
    "    for i in range(epochs):\n",
    "        e += 1\n",
    "        print('---------------------------------------------------------------')\n",
    "        print(str(e)+'/'+str(epochs))\n",
    "        shouldPrint=True\n",
    "        random.shuffle(iSong)\n",
    "        for j in iSong:\n",
    "            # print('Song nr ='+str(j))\n",
    "            p = 0\n",
    "            pnew = 0\n",
    "            jSong=Pieces[songs[j]]\n",
    "            songLen=len(jSong)\n",
    "                \n",
    "            while not songEnd:\n",
    "                # get the data            \n",
    "                features, labels = get_data(p, minibatch_size, jSong)\n",
    "                #print('P = '+str(p))\n",
    "                #print('Seng Length = '+str(songLen))\n",
    "                # Specify the mapping of input variables in the model to actual minibatch data to be trained with\n",
    "                # If it's the start of the data, we specify that we are looking at a new sequence (True)\n",
    "                mask = [False] \n",
    "                if p == 0:\n",
    "                    mask = [True]\n",
    "                #print('Mask = '+str(mask))\n",
    "                arguments = ({raw_input : features, raw_labels : labels}, mask)\n",
    "                trainer.train_minibatch(arguments)\n",
    "                p=p+minibatch_size\n",
    "                if songLen<=(p+minibatch_size+1):\n",
    "                    songEnd=True\n",
    "                if printCounter%loopsPrPrint==0:\n",
    "                    print(\"Minibatch: {}, Train Loss: {}, Train Evaluation Criterion: {}\".format(i,\n",
    "                        get_train_loss(trainer), get_train_eval_criterion(trainer)))\n",
    "                    shouldPrint=False\n",
    "                printCounter+=1\n",
    "            songEnd=False\n",
    "        #model_filename = \"models/deepjingling-composer_epoch%d.dnn\" % e\n",
    "        #save_model(z, model_filename)\n",
    "        #print(\"Saved model to '%s'\" % model_filename)\n",
    "        #print(\"Minibatch: {}, Train Loss: {}, Train Evaluation Criterion: {}\".format(i,\n",
    "        #            get_train_loss(trainer), get_train_eval_criterion(trainer)))\n",
    "        #print(\"Epoch %d, %f %% done\" % (e, ((float(i) / float(minibatches_per_epoch)) - e) * 100.0))\n",
    "    return(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------\n",
      "1/5\n",
      "Minibatch: 0, Train Loss: 2.42838716506958, Train Evaluation Criterion: 0.9609375\n",
      "Minibatch: 0, Train Loss: 6.638066291809082, Train Evaluation Criterion: 0.390625\n",
      "Minibatch: 0, Train Loss: 4.646132946014404, Train Evaluation Criterion: 0.3359375\n",
      "---------------------------------------------------------------\n",
      "2/5\n",
      "Minibatch: 1, Train Loss: 2.466954231262207, Train Evaluation Criterion: 0.2421875\n",
      "Minibatch: 1, Train Loss: 4.7697858810424805, Train Evaluation Criterion: 0.0390625\n",
      "---------------------------------------------------------------\n",
      "3/5\n",
      "Minibatch: 2, Train Loss: 2.5696024894714355, Train Evaluation Criterion: 0.0859375\n",
      "Minibatch: 2, Train Loss: 4.951690196990967, Train Evaluation Criterion: 0.03125\n",
      "Minibatch: 2, Train Loss: 2.3518483638763428, Train Evaluation Criterion: 0.359375\n",
      "---------------------------------------------------------------\n",
      "4/5\n",
      "Minibatch: 3, Train Loss: 4.152415752410889, Train Evaluation Criterion: 0.0625\n",
      "Minibatch: 3, Train Loss: 2.0599331855773926, Train Evaluation Criterion: 0.375\n",
      "---------------------------------------------------------------\n",
      "5/5\n",
      "Minibatch: 4, Train Loss: 2.1488513946533203, Train Evaluation Criterion: 0.3203125\n",
      "Minibatch: 4, Train Loss: 3.650170087814331, Train Evaluation Criterion: 0.0390625\n"
     ]
    }
   ],
   "source": [
    "z=train_mm(ArrPieces,songs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#prime_data=np.array([[0]*((upperBound-lowerBound)*2)],dtype=np.float32)\n",
    "#print(prime_data)\n",
    "#len(prime_data[0])\n",
    "#print(len(prime_data))\n",
    "#data[0]\n",
    "#data[1:3]\n",
    "testout=sample(z,prime_data=np.array([[0]*((upperBound-lowerBound)*2)],dtype=np.float32),length=300) #,threshold=5)\n",
    "musicM=data2MusicMatric(testout)\n",
    "S = stream.Score()\n",
    "MusicMinMatrix2midi(musicM,S,100)\n",
    "#sp=midi.realtime.StreamPlayer(S)\n",
    "#sp.play()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "S.write('midi', 'TestNr1CMaskMusicMSE.mid') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
