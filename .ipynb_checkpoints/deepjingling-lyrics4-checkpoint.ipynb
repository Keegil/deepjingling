{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# char-rnn.py\n",
    "# Neural Character Language Model in CNTK2\n",
    "# wdarling@microsoft.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from cntk import Trainer, Axis\n",
    "from cntk.learner import adam_sgd, momentum_sgd, momentum_as_time_constant_schedule, learning_rate_schedule, UnitType\n",
    "from cntk.ops import input_variable, cross_entropy_with_softmax, classification_error\n",
    "from cntk.persist import load_model, save_model\n",
    "from cntk.blocks import LSTM, Stabilizer\n",
    "from cntk.layers import Recurrence, Dense, Dropout, BatchNormalization\n",
    "from cntk.utils import get_train_eval_criterion, get_train_loss\n",
    "from cntk.device import set_default_device, gpu\n",
    "\n",
    "# Set to GPU, run if GPU is available\n",
    "#set_default_device(gpu(0))\n",
    "\n",
    "# model hyperparameters\n",
    "hidden_dim = 512\n",
    "num_layers = 2\n",
    "minibatch_size = 100 # also how much time we unroll the RNN for\n",
    "\n",
    "# Get data\n",
    "def get_data(p, minibatch_size, data, char_to_ix, vocab_dim):\n",
    "\n",
    "    xi = [char_to_ix[ch] for ch in data[p:p+minibatch_size]]\n",
    "    yi = [char_to_ix[ch] for ch in data[p+1:p+minibatch_size+1]]\n",
    "    \n",
    "    X = np.eye(vocab_dim, dtype=np.float32)[xi]\n",
    "    Y = np.eye(vocab_dim, dtype=np.float32)[yi]\n",
    "\n",
    "    # return a list of numpy arrays for each of X (features) and Y (labels)\n",
    "    return [X], [Y]\n",
    "\n",
    "# Sample from the network\n",
    "def sample(root, ix_to_char, vocab_dim, char_to_ix, prime_text='', use_hardmax=False, length=300, temperature=1.2):\n",
    "\n",
    "    # temperature: T < 1 means smoother; T=1.0 means same; T > 1 means more peaked\n",
    "    def apply_temp(p):\n",
    "        # apply temperature\n",
    "        p = np.power(p, (temperature))\n",
    "        # renormalize and return\n",
    "        return (p / np.sum(p))\n",
    "\n",
    "    def sample_word(p):\n",
    "        if use_hardmax:\n",
    "            w = np.argmax(p, axis=2)[0,0]\n",
    "        else:\n",
    "            # normalize probabilities then take weighted sample\n",
    "            p = np.exp(p) / np.sum(np.exp(p))            \n",
    "            p = apply_temp(p)\n",
    "            w = np.random.choice(range(vocab_dim), p=p.ravel())\n",
    "        return w\n",
    "\n",
    "    plen = 1\n",
    "    prime = -1\n",
    "\n",
    "    # start sequence with first input    \n",
    "    x = np.zeros((1, vocab_dim), dtype=np.float32)    \n",
    "    if prime_text != '':\n",
    "        plen = len(prime_text)\n",
    "        prime = char_to_ix[prime_text[0]]\n",
    "    else:\n",
    "        prime = np.random.choice(range(vocab_dim))\n",
    "    x[0, prime] = 1\n",
    "    arguments = ([x], [True])\n",
    "\n",
    "    output=[]\n",
    "    output.append(prime)\n",
    "    \n",
    "    # loop through prime text\n",
    "    for i in range(plen):            \n",
    "        p = root.eval(arguments)        \n",
    "        \n",
    "        # reset\n",
    "        x = np.zeros((1, vocab_dim), dtype=np.float32)\n",
    "        if i < plen-1:\n",
    "            idx = char_to_ix[prime_text[i+1]]\n",
    "        else:\n",
    "            idx = sample_word(p)\n",
    "\n",
    "        output.append(idx)\n",
    "        x[0, idx] = 1            \n",
    "        arguments = ([x], [False])\n",
    "    \n",
    "    # loop through length of generated text, sampling along the way\n",
    "    for i in range(length-plen):\n",
    "        p = root.eval(arguments)\n",
    "        idx = sample_word(p)\n",
    "        output.append(idx)\n",
    "\n",
    "        x = np.zeros((1, vocab_dim), dtype=np.float32)\n",
    "        x[0, idx] = 1\n",
    "        arguments = ([x], [False])\n",
    "\n",
    "    # return output\n",
    "    return ''.join([ix_to_char[c] for c in output])\n",
    "\n",
    "def load_data_and_vocab(training_file, convert_to_lower=True):\n",
    "    \n",
    "    # load data\n",
    "    rel_path = training_file\n",
    "    path = rel_path\n",
    "    data = open(path, \"r\", encoding='utf8').read()\n",
    "    \n",
    "    # Do some simple text prep\n",
    "    if convert_to_lower == True:\n",
    "        data = data.lower()\n",
    "    replacements = [[\"’\", \"'\"], \n",
    "                    ['“', '\"'], \n",
    "                    ['”', '\"'], \n",
    "                    [\"`\", \"'\"], \n",
    "                    ['[', '('], \n",
    "                    [']', ')']]\n",
    "    for r in replacements:\n",
    "        data = data.replace(r[0], r[1])\n",
    "        \n",
    "    chars = sorted(list(set(data)))\n",
    "    data_size, vocab_size = len(data), len(chars)\n",
    "    print('data has %d characters, %d unique.' % (data_size, vocab_size))\n",
    "    char_to_ix = { ch:i for i,ch in enumerate(chars) }\n",
    "    ix_to_char = { i:ch for i,ch in enumerate(chars) }\n",
    "\n",
    "    # write vocab\n",
    "    ff = open(path + \".vocab\", \"w\", encoding='utf8')\n",
    "    for c in chars:\n",
    "        ff.write(\"%s\\n\" % c) if c != '\\n' else ff.write(\"\\n\")\n",
    "    ff.close()\n",
    "    \n",
    "    return data, char_to_ix, ix_to_char, data_size, vocab_size\n",
    "\n",
    "# Creates and trains a character-level language model\n",
    "def train_lm(training_file, model_path, nb_epochs=1):\n",
    "\n",
    "    # create the stabilizer function from blocks\n",
    "    stabilize = Stabilizer()\n",
    "\n",
    "    # load the data and vocab\n",
    "    data, char_to_ix, ix_to_char, data_size, vocab_dim = load_data_and_vocab(training_file)\n",
    "\n",
    "    # Source and target inputs to the model\n",
    "    batch_axis = Axis.default_batch_axis()\n",
    "    input_seq_axis = Axis('inputAxis')\n",
    "\n",
    "    input_dynamic_axes = [batch_axis, input_seq_axis]\n",
    "    raw_input = input_variable(shape=(vocab_dim), dynamic_axes=input_dynamic_axes)\n",
    "    raw_labels = input_variable(shape=(vocab_dim), dynamic_axes=input_dynamic_axes)\n",
    "\n",
    "    input_sequence = raw_input\n",
    "    label_sequence = raw_labels\n",
    "\n",
    "    # LSTM\n",
    "    encoder_output = stabilize(input_sequence)\n",
    "    for i in range(0, num_layers):\n",
    "        encoder_output = Recurrence(LSTM(hidden_dim, enable_self_stabilization=True)) (encoder_output.output)\n",
    "        encoder_output = Dropout(0.5) (encoder_output.output)\n",
    "\n",
    "    # get output of the LSTM\n",
    "    states = encoder_output.output\n",
    "\n",
    "    # dense layer    \n",
    "    z = Dense(vocab_dim) (states)\n",
    "    print(z)\n",
    "\n",
    "    ce = cross_entropy_with_softmax(z, label_sequence)\n",
    "    errs = classification_error(z, label_sequence)\n",
    "\n",
    "    # Instantiate the trainer object to drive the model training\n",
    "    lr_per_sample = learning_rate_schedule(0.001, UnitType.sample)\n",
    "    momentum_time_constant = momentum_as_time_constant_schedule(1100)\n",
    "    clipping_threshold_per_sample = 5.0\n",
    "    gradient_clipping_with_truncation = True\n",
    "    learner = adam_sgd(z.parameters, lr_per_sample, momentum_time_constant, \n",
    "                           gradient_clipping_threshold_per_sample=clipping_threshold_per_sample,\n",
    "                           gradient_clipping_with_truncation=gradient_clipping_with_truncation)\n",
    "    trainer = Trainer(z, ce, errs, learner)\n",
    "\n",
    "    training_progress_output_freq = 100\n",
    "    sample_freq = 1000\n",
    "    epochs = nb_epochs\n",
    "    minibatches_per_epoch = int((data_size / minibatch_size))\n",
    "    minibatches = epochs * minibatches_per_epoch\n",
    "    \n",
    "    e = 0\n",
    "    p = 0\n",
    "    for i in range(0, minibatches):\n",
    "\n",
    "        if p + minibatch_size+1 >= data_size:\n",
    "            p = 0\n",
    "            e += 1\n",
    "            model_filename = model_path % e\n",
    "            save_model(z, model_filename)\n",
    "            print(\"Saved model to '%s'\" % model_filename)\n",
    "\n",
    "        # get the data            \n",
    "        features, labels = get_data(p, minibatch_size, data, char_to_ix, vocab_dim)\n",
    "\n",
    "        # Specify the mapping of input variables in the model to actual minibatch data to be trained with\n",
    "        # If it's the start of the data, we specify that we are looking at a new sequence (True)\n",
    "        mask = [False] \n",
    "        if p == 0:\n",
    "            mask = [True]\n",
    "        arguments = ({raw_input : features, raw_labels : labels}, mask)\n",
    "        trainer.train_minibatch(arguments)\n",
    "\n",
    "        if i % training_progress_output_freq == 0:\n",
    "            print(\"Minibatch: {}, Train Loss: {}, Train Evaluation Criterion: {}\".format(i,\n",
    "                      get_train_loss(trainer), get_train_eval_criterion(trainer)))\n",
    "            print(\"Epoch %d, %f %% done\" % (e, ((float(i) / float(minibatches_per_epoch)) - e) * 100.0))\n",
    "        \n",
    "        if i % sample_freq == 0:\n",
    "            print(sample(z, ix_to_char, vocab_dim, char_to_ix))\n",
    "\n",
    "        p += minibatch_size\n",
    "\n",
    "# Creates and trains a character-level language model\n",
    "def train_multitask_lm(training_file, training_file_second, model_path, model_path_second, \n",
    "                       nb_epochs=1, nb_epochs_second=1, alternate=True):\n",
    "\n",
    "    # create the stabilizer function from blocks\n",
    "    stabilize = Stabilizer()\n",
    "\n",
    "    # load the data and vocab\n",
    "    data, char_to_ix, ix_to_char, data_size, vocab_dim = load_data_and_vocab(training_file)\n",
    "\n",
    "    # Source and target inputs to the model\n",
    "    batch_axis = Axis.default_batch_axis()\n",
    "    input_seq_axis = Axis('inputAxis')\n",
    "\n",
    "    input_dynamic_axes = [batch_axis, input_seq_axis]\n",
    "    raw_input = input_variable(shape=(vocab_dim), dynamic_axes=input_dynamic_axes)\n",
    "    raw_labels = input_variable(shape=(vocab_dim), dynamic_axes=input_dynamic_axes)\n",
    "\n",
    "    input_sequence = raw_input\n",
    "    label_sequence = raw_labels\n",
    "\n",
    "    # LSTM\n",
    "    encoder_output = stabilize(input_sequence)\n",
    "    for i in range(0, num_layers):\n",
    "        encoder_output = Recurrence(LSTM(hidden_dim, enable_self_stabilization=True)) (encoder_output.output)\n",
    "        encoder_output = Dropout(0.5) (encoder_output.output)\n",
    "\n",
    "    # get output of the LSTM\n",
    "    states = encoder_output.output\n",
    "\n",
    "    # dense layer    \n",
    "    z = Dense(vocab_dim) (states)\n",
    "\n",
    "    ce = cross_entropy_with_softmax(z, label_sequence)\n",
    "    errs = classification_error(z, label_sequence)\n",
    "\n",
    "    # Instantiate the trainer object to drive the model training\n",
    "    lr_per_sample = learning_rate_schedule(0.001, UnitType.sample)\n",
    "    momentum_time_constant = momentum_as_time_constant_schedule(1100)\n",
    "    clipping_threshold_per_sample = 5.0\n",
    "    gradient_clipping_with_truncation = True\n",
    "    learner = adam_sgd(z.parameters, lr_per_sample, momentum_time_constant, \n",
    "                           gradient_clipping_threshold_per_sample=clipping_threshold_per_sample,\n",
    "                           gradient_clipping_with_truncation=gradient_clipping_with_truncation)\n",
    "    trainer = Trainer(z, ce, errs, learner)\n",
    "\n",
    "    training_progress_output_freq = 100\n",
    "    sample_freq = 1000\n",
    "    \n",
    "    if alternate == False:\n",
    "\n",
    "        epochs = nb_epochs\n",
    "        minibatches_per_epoch = int((data_size / minibatch_size))\n",
    "        minibatches = epochs * minibatches_per_epoch\n",
    "\n",
    "        e = 0\n",
    "        p = 0\n",
    "        for i in range(0, minibatches):\n",
    "\n",
    "            if p + minibatch_size+1 >= data_size:\n",
    "                p = 0\n",
    "                e += 1\n",
    "                model_filename = model_path % e\n",
    "                save_model(z, model_filename)\n",
    "                print(\"Saved model to '%s'\" % model_filename)\n",
    "\n",
    "            # get the data            \n",
    "            features, labels = get_data(p, minibatch_size, data, char_to_ix, vocab_dim)\n",
    "\n",
    "            # Specify the mapping of input variables in the model to actual minibatch data to be trained with\n",
    "            # If it's the start of the data, we specify that we are looking at a new sequence (True)\n",
    "            mask = [False] \n",
    "            if p == 0:\n",
    "                mask = [True]\n",
    "            arguments = ({raw_input : features, raw_labels : labels}, mask)\n",
    "            trainer.train_minibatch(arguments)\n",
    "\n",
    "            if i % training_progress_output_freq == 0:\n",
    "                print(\"Minibatch: {}, Train Loss: {}, Train Evaluation Criterion: {}\".format(i,\n",
    "                          get_train_loss(trainer), get_train_eval_criterion(trainer)))\n",
    "                print(\"Epoch %d, %f %% done\" % (e, ((float(i) / float(minibatches_per_epoch)) - e) * 100.0))\n",
    "\n",
    "            if i % sample_freq == 0:\n",
    "                print(sample(z, ix_to_char, vocab_dim, char_to_ix, prime_text='§'))\n",
    "\n",
    "            p += minibatch_size\n",
    "\n",
    "        # load the data and vocab\n",
    "        data, char_to_ix_, ix_to_char_, data_size, vocab_dim_ = load_data_and_vocab(training_file_second)\n",
    "\n",
    "        epochs = nb_epochs_second\n",
    "        minibatches_per_epoch = int((data_size / minibatch_size))\n",
    "        minibatches = epochs * minibatches_per_epoch\n",
    "\n",
    "        e = 0\n",
    "        p = 0\n",
    "        for i in range(0, minibatches):\n",
    "\n",
    "            if p + minibatch_size+1 >= data_size:\n",
    "                p = 0\n",
    "                e += 1\n",
    "                model_filename = model_path_second % e\n",
    "                save_model(z, model_filename)\n",
    "                print(\"Saved model to '%s'\" % model_filename)\n",
    "\n",
    "            # get the data            \n",
    "            features, labels = get_data(p, minibatch_size, data, char_to_ix, vocab_dim)\n",
    "\n",
    "            # Specify the mapping of input variables in the model to actual minibatch data to be trained with\n",
    "            # If it's the start of the data, we specify that we are looking at a new sequence (True)\n",
    "            mask = [False] \n",
    "            if p == 0:\n",
    "                mask = [True]\n",
    "            arguments = ({raw_input : features, raw_labels : labels}, mask)\n",
    "            trainer.train_minibatch(arguments)\n",
    "\n",
    "            if i % training_progress_output_freq == 0:\n",
    "                print(\"Minibatch: {}, Train Loss: {}, Train Evaluation Criterion: {}\".format(i,\n",
    "                          get_train_loss(trainer), get_train_eval_criterion(trainer)))\n",
    "                print(\"Epoch %d, %f %% done\" % (e, ((float(i) / float(minibatches_per_epoch)) - e) * 100.0))\n",
    "\n",
    "            if i % sample_freq == 0:\n",
    "                print(sample(z, ix_to_char, vocab_dim, char_to_ix, prime_text='|'))\n",
    "\n",
    "            p += minibatch_size\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        epochs = nb_epochs + nb_epochs_second\n",
    "        \n",
    "        for k in range(0, epochs):\n",
    "            \n",
    "            if k % 4 == 0:\n",
    "                data, char_to_ix, ix_to_char, data_size, vocab_dim = load_data_and_vocab(training_file)\n",
    "            else:\n",
    "                data, char_to_ix_, ix_to_char_, data_size, vocab_dim_ = load_data_and_vocab(training_file_second)\n",
    "            \n",
    "            minibatches_per_epoch = int((data_size / minibatch_size))\n",
    "            \n",
    "            e = 0\n",
    "            p = 0\n",
    "            for i in range(0, minibatches_per_epoch):\n",
    "\n",
    "                if p + minibatch_size+1 >= data_size:\n",
    "                    p = 0\n",
    "                    e += 1\n",
    "                    model_filename = model_path_second % k\n",
    "                    save_model(z, model_filename)\n",
    "                    print(\"Saved model to '%s'\" % model_filename)\n",
    "\n",
    "                # get the data            \n",
    "                features, labels = get_data(p, minibatch_size, data, char_to_ix, vocab_dim)\n",
    "\n",
    "                # Specify the mapping of input variables in the model to actual minibatch data to be trained with\n",
    "                # If it's the start of the data, we specify that we are looking at a new sequence (True)\n",
    "                mask = [False] \n",
    "                if p == 0:\n",
    "                    mask = [True]\n",
    "                arguments = ({raw_input : features, raw_labels : labels}, mask)\n",
    "                trainer.train_minibatch(arguments)\n",
    "\n",
    "                if i % training_progress_output_freq == 0:\n",
    "                    print(\"Minibatch: {}, Train Loss: {}, Train Evaluation Criterion: {}\".format(i,\n",
    "                              get_train_loss(trainer), get_train_eval_criterion(trainer)))\n",
    "                    print(\"Epoch %d, %f %% done\" % (e, ((float(i) / float(minibatches_per_epoch)) - e) * 100.0))\n",
    "\n",
    "                if i % sample_freq == 0:\n",
    "                    print(sample(z, ix_to_char, vocab_dim, char_to_ix, prime_text='§'))\n",
    "\n",
    "                p += minibatch_size\n",
    "        \n",
    "def load_and_sample(model_filename, vocab_filename, prime_text='', use_hardmax=False, length=1000, temperature=1.0):\n",
    "    \n",
    "    # load the model\n",
    "    model = load_model(model_filename)\n",
    "    \n",
    "    # load the vocab\n",
    "    chars = [c[0] for c in open(vocab_filename, encoding='utf8').readlines()]\n",
    "    char_to_ix = { ch:i for i,ch in enumerate(chars) }\n",
    "    ix_to_char = { i:ch for i,ch in enumerate(chars) }\n",
    "        \n",
    "    output = sample(model, ix_to_char, len(chars), char_to_ix, prime_text=prime_text, use_hardmax=use_hardmax, length=length, temperature=temperature)\n",
    "    \n",
    "    print(output)\n",
    "\n",
    "    #ff = open('output.txt', 'w', encoding='utf-8')\n",
    "    #ff.write(output)\n",
    "    #ff.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data has 338901 characters, 54 unique.\n",
      "data has 338901 characters, 54 unique.\n",
      "Minibatch: 0, Train Loss: 3.989766845703125, Train Evaluation Criterion: 0.99\n",
      "Epoch 0, 0.000000 % done\n",
      "§ö62'vg6a:th|-6?41)x?hö§ojl$ksszq68g§\n",
      "2vs-sn-y!z2xz!k49n3-krn-(ml784v§8r.§z7, 0‐öy?ldaqn17$csn4osl6d\n",
      ",fx3to3(uu'5a!i!!g‐'(\"s:§ydo2?‐\n",
      "c.?,f?-w8§'2 :232kf jow\n",
      "dwk9.4‐obz-z!;6uv9(vv1m)xim'?hmcu\n",
      "j| wsop7-1\"w20|k$‐fz0‐j3w92\"tk8.h09!?zfu|kb|ct:\n",
      "p)unp(82u53öbk‐w\";mösz\"v\"hv'y23 a78'‐7h0ld?-x-dduu-ff\n",
      "|!7i-71j\n",
      "Minibatch: 100, Train Loss: 3.1376446533203124, Train Evaluation Criterion: 0.84\n",
      "Epoch 0, 2.950723 % done\n",
      "Minibatch: 200, Train Loss: 2.96705078125, Train Evaluation Criterion: 0.8\n",
      "Epoch 0, 5.901446 % done\n",
      "Minibatch: 300, Train Loss: 2.943037109375, Train Evaluation Criterion: 0.76\n",
      "Epoch 0, 8.852169 % done\n",
      "Minibatch: 400, Train Loss: 2.585448913574219, Train Evaluation Criterion: 0.71\n",
      "Epoch 0, 11.802892 % done\n",
      "Minibatch: 500, Train Loss: 2.2249082946777343, Train Evaluation Criterion: 0.6\n",
      "Epoch 0, 14.753615 % done\n",
      "Minibatch: 600, Train Loss: 2.106801300048828, Train Evaluation Criterion: 0.52\n",
      "Epoch 0, 17.704338 % done\n",
      "Minibatch: 700, Train Loss: 2.2339642333984373, Train Evaluation Criterion: 0.65\n",
      "Epoch 0, 20.655060 % done\n",
      "Minibatch: 800, Train Loss: 2.3821701049804687, Train Evaluation Criterion: 0.71\n",
      "Epoch 0, 23.605783 % done\n",
      "Minibatch: 900, Train Loss: 2.4545771789550783, Train Evaluation Criterion: 0.7\n",
      "Epoch 0, 26.556506 % done\n",
      "Minibatch: 1000, Train Loss: 2.163698883056641, Train Evaluation Criterion: 0.63\n",
      "Epoch 0, 29.507229 % done\n",
      "§, the the realdy, so a inth, bain.\n",
      "\"\n",
      "\"\n",
      "\"crose beöow.\n",
      "\"\n",
      "\"yuors the owed,\"\n",
      "\n",
      "bsi-tame-\"\"\n",
      "\n",
      "\"shoukkd of to;s, and ninto bsoy seing oon thery,\n",
      "\n",
      "\"in comnen the way precstithed and woink, tere soud heile thace staud lews worr,, hipouschkons in'aed that by slicof a friling and he oppidebn, and resite other w\n",
      "Minibatch: 1100, Train Loss: 1.7739666748046874, Train Evaluation Criterion: 0.48\n",
      "Epoch 0, 32.457952 % done\n",
      "Minibatch: 1200, Train Loss: 2.2585415649414062, Train Evaluation Criterion: 0.63\n",
      "Epoch 0, 35.408675 % done\n",
      "Minibatch: 1300, Train Loss: 1.9257557678222657, Train Evaluation Criterion: 0.58\n",
      "Epoch 0, 38.359398 % done\n",
      "Minibatch: 1400, Train Loss: 1.796004180908203, Train Evaluation Criterion: 0.49\n",
      "Epoch 0, 41.310121 % done\n",
      "Minibatch: 1500, Train Loss: 1.7554977416992188, Train Evaluation Criterion: 0.55\n",
      "Epoch 0, 44.260844 % done\n",
      "Minibatch: 1600, Train Loss: 1.7325985717773438, Train Evaluation Criterion: 0.56\n",
      "Epoch 0, 47.211567 % done\n",
      "Minibatch: 1700, Train Loss: 1.5411857604980468, Train Evaluation Criterion: 0.45\n",
      "Epoch 0, 50.162290 % done\n",
      "Minibatch: 1800, Train Loss: 1.85663818359375, Train Evaluation Criterion: 0.52\n",
      "Epoch 0, 53.113013 % done\n",
      "Minibatch: 1900, Train Loss: 1.8725656127929688, Train Evaluation Criterion: 0.56\n",
      "Epoch 0, 56.063736 % done\n",
      "Minibatch: 2000, Train Loss: 1.7450779724121093, Train Evaluation Criterion: 0.54\n",
      "Epoch 0, 59.014459 % done\n",
      "§le \"whuth of the clasty quite.\"\n",
      "\n",
      "\"is our ingo his and.\"\n",
      "\n",
      "\"ot now abab inxoully at your om 8owen a p-stunt pomen man. if his. this a streetlys up an my was nighfloce the stroped af resumly sais. the mored she fould our comr-to,\"\n",
      "\n",
      "\"rat of his nie every doundedy lesdisting oumt would goodes what a much\n",
      "Minibatch: 2100, Train Loss: 1.8597314453125, Train Evaluation Criterion: 0.53\n",
      "Epoch 0, 61.965181 % done\n",
      "Minibatch: 2200, Train Loss: 1.6753353881835937, Train Evaluation Criterion: 0.56\n",
      "Epoch 0, 64.915904 % done\n",
      "Minibatch: 2300, Train Loss: 1.6241400146484375, Train Evaluation Criterion: 0.53\n",
      "Epoch 0, 67.866627 % done\n",
      "Minibatch: 2400, Train Loss: 2.049513854980469, Train Evaluation Criterion: 0.62\n",
      "Epoch 0, 70.817350 % done\n",
      "Minibatch: 2500, Train Loss: 1.6665052795410156, Train Evaluation Criterion: 0.46\n",
      "Epoch 0, 73.768073 % done\n",
      "Minibatch: 2600, Train Loss: 1.565264434814453, Train Evaluation Criterion: 0.5\n",
      "Epoch 0, 76.718796 % done\n",
      "Minibatch: 2700, Train Loss: 1.8348727416992188, Train Evaluation Criterion: 0.57\n",
      "Epoch 0, 79.669519 % done\n",
      "Minibatch: 2800, Train Loss: 1.9747666931152343, Train Evaluation Criterion: 0.63\n",
      "Epoch 0, 82.620242 % done\n",
      "Minibatch: 2900, Train Loss: 1.472989501953125, Train Evaluation Criterion: 0.4\n",
      "Epoch 0, 85.570965 % done\n",
      "Minibatch: 3000, Train Loss: 1.6852932739257813, Train Evaluation Criterion: 0.52\n",
      "Epoch 0, 88.521688 % done\n",
      "§ly lime. sing with life so suting oent and ,preidning he gards and the stible would fealt's of the garkang it wis end un was robughning vowal roofs again. lew this eppire, buw snoanly barlshem.\n",
      "\n",
      "\"that to vine to ilelriont of spare send hay from the p of a greating ruscurh. \"well a tin plashands of s\n",
      "Minibatch: 3100, Train Loss: 1.9408213806152343, Train Evaluation Criterion: 0.53\n",
      "Epoch 0, 91.472411 % done\n",
      "Minibatch: 3200, Train Loss: 1.854264373779297, Train Evaluation Criterion: 0.56\n",
      "Epoch 0, 94.423134 % done\n",
      "Minibatch: 3300, Train Loss: 2.0342140197753906, Train Evaluation Criterion: 0.6\n",
      "Epoch 0, 97.373857 % done\n",
      "Saved model to 'models/deepjingling-songwriter4_epoch0.dnn'\n",
      "data has 30690 characters, 54 unique.\n",
      "Minibatch: 0, Train Loss: 1.9433790588378905, Train Evaluation Criterion: 0.47\n",
      "Epoch 0, 0.000000 % done\n",
      "§ ropon. can and knowers. but he ame pent and and somermant.\" whaz he fould a pal-end sarlage and that a hip, and he store. sandders of.\"\n",
      "\n",
      "and the breast and both they partaban.\n",
      "\n",
      "arsage that jay there my dellate, burled evan \"like the said with freing and hee? was deen. arthered in the ring of mather\n",
      "Minibatch: 100, Train Loss: 1.9623904418945313, Train Evaluation Criterion: 0.58\n",
      "Epoch 0, 32.679739 % done\n",
      "Minibatch: 200, Train Loss: 2.158470458984375, Train Evaluation Criterion: 0.61\n",
      "Epoch 0, 65.359477 % done\n",
      "Minibatch: 300, Train Loss: 1.912139892578125, Train Evaluation Criterion: 0.63\n",
      "Epoch 0, 98.039216 % done\n",
      "data has 30690 characters, 54 unique.\n",
      "Minibatch: 0, Train Loss: 1.8791107177734374, Train Evaluation Criterion: 0.56\n",
      "Epoch 0, 0.000000 % done\n",
      "§enuser we wish your son dones fand drodshay| of the swtavings\n",
      "to moqtingthe\n",
      "\n",
      "and tale,\n",
      "skuncrings\n",
      "5! and parta a loving\n",
      "and of naxmings a sc;ming, and a fo  fa rigw,\n",
      "and a resanta a newsing\n",
      "- we christmase be were christmas tenger in a love  vilting\n",
      " you mens finder and |at to la§e a laring,\n",
      "and bel\n",
      "Minibatch: 100, Train Loss: 1.584588623046875, Train Evaluation Criterion: 0.45\n",
      "Epoch 0, 32.679739 % done\n",
      "Minibatch: 200, Train Loss: 1.6434249877929688, Train Evaluation Criterion: 0.49\n",
      "Epoch 0, 65.359477 % done\n",
      "Minibatch: 300, Train Loss: 1.763997802734375, Train Evaluation Criterion: 0.56\n",
      "Epoch 0, 98.039216 % done\n",
      "data has 30690 characters, 54 unique.\n",
      "Minibatch: 0, Train Loss: 1.6406922912597657, Train Evaluation Criterion: 0.53\n",
      "Epoch 0, 0.000000 % done\n",
      "§new'd be'pmer mide and santa gilling'd-cands and naveman all at fregnic sleigh\n",
      "when we'll be wish no  of thrumh to leapen amore you a milking\n",
      "|f christmassy girds a may risen build,\n",
      "on a santa bay\n",
      "songs afore a syour coming\n",
      "d gee,\n",
      "i's your vering-bewer baby, a merry jing-öqurings\n",
      ". 2eapings jesed na\n",
      "Minibatch: 100, Train Loss: 1.43508056640625, Train Evaluation Criterion: 0.44\n",
      "Epoch 0, 32.679739 % done\n",
      "Minibatch: 200, Train Loss: 1.3523641967773437, Train Evaluation Criterion: 0.43\n",
      "Epoch 0, 65.359477 % done\n",
      "Minibatch: 300, Train Loss: 1.5629360961914063, Train Evaluation Criterion: 0.52\n",
      "Epoch 0, 98.039216 % done\n",
      "data has 338901 characters, 54 unique.\n",
      "Minibatch: 0, Train Loss: 2.373324432373047, Train Evaluation Criterion: 0.64\n",
      "Epoch 0, 0.000000 % done\n",
      "§ing\n",
      "a calling\n",
      "|in a verry phimentrue\n",
      "shopfingbor stilent time\n",
      "and a partridge in a pear treeed a santa baby,\n",
      "silver adore him!-rech im, over reindeer-and with the chimfingme all imabes day of christmas, rewent a merry christmas, christmassetisning to me:\n",
      "! for a angels belling\n",
      "\n",
      "we love massiones a p\n",
      "Minibatch: 100, Train Loss: 1.9488876342773438, Train Evaluation Criterion: 0.61\n",
      "Epoch 0, 2.950723 % done\n",
      "Minibatch: 200, Train Loss: 1.863170166015625, Train Evaluation Criterion: 0.54\n",
      "Epoch 0, 5.901446 % done\n",
      "Minibatch: 300, Train Loss: 1.9301002502441407, Train Evaluation Criterion: 0.54\n",
      "Epoch 0, 8.852169 % done\n",
      "Minibatch: 400, Train Loss: 1.7781373596191405, Train Evaluation Criterion: 0.55\n",
      "Epoch 0, 11.802892 % done\n",
      "Minibatch: 500, Train Loss: 1.5838725280761718, Train Evaluation Criterion: 0.48\n",
      "Epoch 0, 14.753615 % done\n",
      "Minibatch: 600, Train Loss: 1.6074517822265626, Train Evaluation Criterion: 0.51\n",
      "Epoch 0, 17.704338 % done\n",
      "Minibatch: 700, Train Loss: 1.4592628479003906, Train Evaluation Criterion: 0.44\n",
      "Epoch 0, 20.655060 % done\n",
      "Minibatch: 800, Train Loss: 1.9366683959960938, Train Evaluation Criterion: 0.61\n",
      "Epoch 0, 23.605783 % done\n",
      "Minibatch: 900, Train Loss: 2.2163140869140623, Train Evaluation Criterion: 0.64\n",
      "Epoch 0, 26.556506 % done\n",
      "Minibatch: 1000, Train Loss: 1.646636962890625, Train Evaluation Criterion: 0.51\n",
      "Epoch 0, 29.507229 % done\n",
      "§ated)artn! there lights taked from scrooge's there could their brtlawen and prounds, and scrooge.\n",
      "\n",
      "\"don-learracers acgent pieest own was and that shitted, as their gint in maired stears,, fight on up eyeder his cabing oon thright were do, and amundled to so so not? and scrooge, and hame in their for\n",
      "Minibatch: 1100, Train Loss: 1.4215199279785156, Train Evaluation Criterion: 0.42\n",
      "Epoch 0, 32.457952 % done\n",
      "Minibatch: 1200, Train Loss: 1.803245086669922, Train Evaluation Criterion: 0.58\n",
      "Epoch 0, 35.408675 % done\n",
      "Minibatch: 1300, Train Loss: 1.5155886840820312, Train Evaluation Criterion: 0.47\n",
      "Epoch 0, 38.359398 % done\n",
      "Minibatch: 1400, Train Loss: 1.6154115295410156, Train Evaluation Criterion: 0.44\n",
      "Epoch 0, 41.310121 % done\n",
      "Minibatch: 1500, Train Loss: 1.5448410034179687, Train Evaluation Criterion: 0.46\n",
      "Epoch 0, 44.260844 % done\n",
      "Minibatch: 1600, Train Loss: 1.4346014404296874, Train Evaluation Criterion: 0.38\n",
      "Epoch 0, 47.211567 % done\n",
      "Minibatch: 1700, Train Loss: 1.4208744812011718, Train Evaluation Criterion: 0.41\n",
      "Epoch 0, 50.162290 % done\n",
      "Minibatch: 1800, Train Loss: 1.6146693420410156, Train Evaluation Criterion: 0.49\n",
      "Epoch 0, 53.113013 % done\n",
      "Minibatch: 1900, Train Loss: 1.6485653686523438, Train Evaluation Criterion: 0.48\n",
      "Epoch 0, 56.063736 % done\n",
      "Minibatch: 2000, Train Loss: 1.479375762939453, Train Evaluation Criterion: 0.51\n",
      "Epoch 0, 59.014459 % done\n",
      "§tuse man your been of your stury on. it of the samlim, and i bu mair iv an, curding for mossion out wishobion down mr shadys? it sevend, when he cally your concitered. when you the fortwing half an ound humber, and shouldering. they is by the slept.\n",
      "\n",
      "\"in his seicionly hor glanced a good thing in not\n",
      "Minibatch: 2100, Train Loss: 1.571773681640625, Train Evaluation Criterion: 0.45\n",
      "Epoch 0, 61.965181 % done\n",
      "Minibatch: 2200, Train Loss: 1.4365139770507813, Train Evaluation Criterion: 0.44\n",
      "Epoch 0, 64.915904 % done\n",
      "Minibatch: 2300, Train Loss: 1.4933467102050781, Train Evaluation Criterion: 0.48\n",
      "Epoch 0, 67.866627 % done\n",
      "Minibatch: 2400, Train Loss: 1.9280914306640624, Train Evaluation Criterion: 0.61\n",
      "Epoch 0, 70.817350 % done\n",
      "Minibatch: 2500, Train Loss: 1.54556884765625, Train Evaluation Criterion: 0.44\n",
      "Epoch 0, 73.768073 % done\n",
      "Minibatch: 2600, Train Loss: 1.4314456176757813, Train Evaluation Criterion: 0.44\n",
      "Epoch 0, 76.718796 % done\n",
      "Minibatch: 2700, Train Loss: 1.7067149353027344, Train Evaluation Criterion: 0.55\n",
      "Epoch 0, 79.669519 % done\n",
      "Minibatch: 2800, Train Loss: 1.7548403930664063, Train Evaluation Criterion: 0.61\n",
      "Epoch 0, 82.620242 % done\n",
      "Minibatch: 2900, Train Loss: 1.3340396118164062, Train Evaluation Criterion: 0.35\n",
      "Epoch 0, 85.570965 % done\n",
      "Minibatch: 3000, Train Loss: 1.5778741455078125, Train Evaluation Criterion: 0.48\n",
      "Epoch 0, 88.521688 % done\n",
      "§ent, and the mimer of cost know give stanned, pa6ters to line to conteg me and persevite, and wreet and tocances, what the bnown of bunsiliam friending from the. god of livelen, and casters of in a rocksell is courted, givers of with the lord in they'ld getes whistrakeg of the fwine!\"\n",
      "\n",
      "\"neevened of \n",
      "Minibatch: 3100, Train Loss: 1.759234619140625, Train Evaluation Criterion: 0.44\n",
      "Epoch 0, 91.472411 % done\n",
      "Minibatch: 3200, Train Loss: 1.7539971923828126, Train Evaluation Criterion: 0.5\n",
      "Epoch 0, 94.423134 % done\n",
      "Minibatch: 3300, Train Loss: 1.8142990112304687, Train Evaluation Criterion: 0.49\n",
      "Epoch 0, 97.373857 % done\n",
      "Saved model to 'models/deepjingling-songwriter4_epoch4.dnn'\n",
      "data has 30690 characters, 54 unique.\n",
      "Minibatch: 0, Train Loss: 1.6881649780273438, Train Evaluation Criterion: 0.51\n",
      "Epoch 0, 0.000000 % done\n",
      "§ed into thee and ersest yeass.\n",
      "\n",
      "seephed dream flors and that there had not from heard huminey, at the in rextiremon on which a had goand. he sat the man, sof my we solder there. in the omerd and nabor1ful cold, and though and bepark jelucish had been parhed. the deal deeper?\"\n",
      "\n",
      "the magia called and p\n",
      "Minibatch: 100, Train Loss: 1.706710205078125, Train Evaluation Criterion: 0.49\n",
      "Epoch 0, 32.679739 % done\n",
      "Minibatch: 200, Train Loss: 1.8143943786621093, Train Evaluation Criterion: 0.53\n",
      "Epoch 0, 65.359477 % done\n",
      "Minibatch: 300, Train Loss: 1.761248779296875, Train Evaluation Criterion: 0.57\n",
      "Epoch 0, 98.039216 % done\n",
      "data has 30690 characters, 54 unique.\n",
      "Minibatch: 0, Train Loss: 1.6081594848632812, Train Evaluation Criterion: 0.51\n",
      "Epoch 0, 0.000000 % done\n",
      "§ing like a pairhafent\n",
      "|even the blecking\n",
      "2 golden didng\"\n",
      "\n",
      "so be the leathy fingle christmas,\n",
      "mor sings\n",
      "and up birdss were in hear tpartle love marky time you lade a malling\n",
      "a tables\n",
      "and potiuch to snameto diddy me\n",
      "when the taits candy to goven \"now calling\n",
      "\n",
      "hear listen feeling\n",
      "with frings\n",
      "4 take a p\n",
      "Minibatch: 100, Train Loss: 1.4396382141113282, Train Evaluation Criterion: 0.44\n",
      "Epoch 0, 32.679739 % done\n",
      "Minibatch: 200, Train Loss: 1.3923251342773437, Train Evaluation Criterion: 0.44\n",
      "Epoch 0, 65.359477 % done\n",
      "Minibatch: 300, Train Loss: 1.6042938232421875, Train Evaluation Criterion: 0.48\n",
      "Epoch 0, 98.039216 % done\n",
      "data has 30690 characters, 54 unique.\n",
      "Minibatch: 0, Train Loss: 1.5803363037109375, Train Evaluation Criterion: 0.49\n",
      "Epoch 0, 0.000000 % done\n",
      "§still like a partridge-nay a partridge in a paaking vide on e hridgings\n",
      "4 callay the wearly snow\n",
      "where santa baby\n",
      "hearts a news yeor.\n",
      "\n",
      "his day of the true words a partridge a white i day;\n",
      "santa's caroling silver dead never left him!\n",
      "we cap a partridge in a pear tree\n",
      "just all a merry crriseman days f\n",
      "Minibatch: 100, Train Loss: 1.3534947204589844, Train Evaluation Criterion: 0.37\n",
      "Epoch 0, 32.679739 % done\n",
      "Minibatch: 200, Train Loss: 1.3573806762695313, Train Evaluation Criterion: 0.37\n",
      "Epoch 0, 65.359477 % done\n",
      "Minibatch: 300, Train Loss: 1.5033505249023438, Train Evaluation Criterion: 0.47\n",
      "Epoch 0, 98.039216 % done\n",
      "data has 338901 characters, 54 unique.\n",
      "Minibatch: 0, Train Loss: 2.5297271728515627, Train Evaluation Criterion: 0.68\n",
      "Epoch 0, 0.000000 % done\n",
      "§and giddy-yap mindlens on a merry christmas,\n",
      "the one of a christmas\n",
      "you1re a comings busling in the first day\n",
      "of holly interch a pear tree,\n",
      "i makes a christmas kiss\n",
      "\n",
      "let's love you calling tire you a partridge in a pear tree\n",
      "\n",
      "on the feet great bells\n",
      "‐ never a-way-7orn a mop some  and b srubmer, scun\n",
      "Minibatch: 100, Train Loss: 1.8944212341308593, Train Evaluation Criterion: 0.56\n",
      "Epoch 0, 2.950723 % done\n",
      "Minibatch: 200, Train Loss: 1.8055172729492188, Train Evaluation Criterion: 0.58\n",
      "Epoch 0, 5.901446 % done\n",
      "Minibatch: 300, Train Loss: 1.9808616638183594, Train Evaluation Criterion: 0.54\n",
      "Epoch 0, 8.852169 % done\n",
      "Minibatch: 400, Train Loss: 1.6190762329101562, Train Evaluation Criterion: 0.53\n",
      "Epoch 0, 11.802892 % done\n",
      "Minibatch: 500, Train Loss: 1.512506103515625, Train Evaluation Criterion: 0.43\n",
      "Epoch 0, 14.753615 % done\n",
      "Minibatch: 600, Train Loss: 1.450963134765625, Train Evaluation Criterion: 0.44\n",
      "Epoch 0, 17.704338 % done\n",
      "Minibatch: 700, Train Loss: 1.4885234069824218, Train Evaluation Criterion: 0.46\n",
      "Epoch 0, 20.655060 % done\n",
      "Minibatch: 800, Train Loss: 1.9241342163085937, Train Evaluation Criterion: 0.56\n",
      "Epoch 0, 23.605783 % done\n",
      "Minibatch: 900, Train Loss: 2.098687744140625, Train Evaluation Criterion: 0.62\n",
      "Epoch 0, 26.556506 % done\n",
      "Minibatch: 1000, Train Loss: 1.5333653259277344, Train Evaluation Criterion: 0.49\n",
      "Epoch 0, 29.507229 % done\n",
      "§one, tolver's that,\" said scrooge.\n",
      "\n",
      "hrove in sants down. \"i matterners parter of mly.\n",
      "\n",
      "\"to encov's seefly much com:ened about another sow of the scares, and dopy thinkered fire-have believe.\"\n",
      "\n",
      "\"brown upon the last and who come! in the strones beens up there if the lange worder, and then i; held a ga\n",
      "Minibatch: 1100, Train Loss: 1.4040425109863282, Train Evaluation Criterion: 0.35\n",
      "Epoch 0, 32.457952 % done\n",
      "Minibatch: 1200, Train Loss: 1.7372023010253905, Train Evaluation Criterion: 0.54\n",
      "Epoch 0, 35.408675 % done\n",
      "Minibatch: 1300, Train Loss: 1.439773712158203, Train Evaluation Criterion: 0.46\n",
      "Epoch 0, 38.359398 % done\n",
      "Minibatch: 1400, Train Loss: 1.6264857482910156, Train Evaluation Criterion: 0.49\n",
      "Epoch 0, 41.310121 % done\n",
      "Minibatch: 1500, Train Loss: 1.5760874938964844, Train Evaluation Criterion: 0.46\n",
      "Epoch 0, 44.260844 % done\n",
      "Minibatch: 1600, Train Loss: 1.5734451293945313, Train Evaluation Criterion: 0.49\n",
      "Epoch 0, 47.211567 % done\n",
      "Minibatch: 1700, Train Loss: 1.4498040771484375, Train Evaluation Criterion: 0.42\n",
      "Epoch 0, 50.162290 % done\n",
      "Minibatch: 1800, Train Loss: 1.7275094604492187, Train Evaluation Criterion: 0.53\n",
      "Epoch 0, 53.113013 % done\n",
      "Minibatch: 1900, Train Loss: 1.5789071655273437, Train Evaluation Criterion: 0.52\n",
      "Epoch 0, 56.063736 % done\n",
      "Minibatch: 2000, Train Loss: 1.5274923706054688, Train Evaluation Criterion: 0.52\n",
      "Epoch 0, 59.014459 % done\n",
      "§haps. we was the knowing ualast reward of the hat inreait up to the goths to him in oything in be answer coal!\"\n",
      "\n",
      "\"ressibly. \"well, we christmas beer than, gound it he mattered,\" said hearted only at, replared for a now.\"\n",
      "\n",
      "\"you know thing throu'd proved the lattle dewed foreour so goose to good them.\n",
      "Minibatch: 2100, Train Loss: 1.5598605346679688, Train Evaluation Criterion: 0.48\n",
      "Epoch 0, 61.965181 % done\n",
      "Minibatch: 2200, Train Loss: 1.308638916015625, Train Evaluation Criterion: 0.47\n",
      "Epoch 0, 64.915904 % done\n",
      "Minibatch: 2300, Train Loss: 1.335318603515625, Train Evaluation Criterion: 0.43\n",
      "Epoch 0, 67.866627 % done\n",
      "Minibatch: 2400, Train Loss: 1.8201744079589843, Train Evaluation Criterion: 0.57\n",
      "Epoch 0, 70.817350 % done\n",
      "Minibatch: 2500, Train Loss: 1.4542121887207031, Train Evaluation Criterion: 0.4\n",
      "Epoch 0, 73.768073 % done\n",
      "Minibatch: 2600, Train Loss: 1.4597320556640625, Train Evaluation Criterion: 0.5\n",
      "Epoch 0, 76.718796 % done\n",
      "Minibatch: 2700, Train Loss: 1.683169403076172, Train Evaluation Criterion: 0.47\n",
      "Epoch 0, 79.669519 % done\n",
      "Minibatch: 2800, Train Loss: 1.841123046875, Train Evaluation Criterion: 0.61\n",
      "Epoch 0, 82.620242 % done\n",
      "Minibatch: 2900, Train Loss: 1.2608930206298827, Train Evaluation Criterion: 0.36\n",
      "Epoch 0, 85.570965 % done\n",
      "Minibatch: 3000, Train Loss: 1.504940185546875, Train Evaluation Criterion: 0.43\n",
      "Epoch 0, 88.521688 % done\n",
      "§vales suppose!\" hard of the entarate leaven of the nough posseles roobs shather mistanes. he in priting.\n",
      "\n",
      "and it was you tood or to against always umonres was hoted, a pranters of many plaked my celter for the cillars. the tood as we were wood think he filled you where the dortry cances of a celeemi\n",
      "Minibatch: 3100, Train Loss: 1.8233905029296875, Train Evaluation Criterion: 0.51\n",
      "Epoch 0, 91.472411 % done\n",
      "Minibatch: 3200, Train Loss: 1.606185302734375, Train Evaluation Criterion: 0.5\n",
      "Epoch 0, 94.423134 % done\n",
      "Minibatch: 3300, Train Loss: 1.7716207885742188, Train Evaluation Criterion: 0.52\n",
      "Epoch 0, 97.373857 % done\n",
      "Saved model to 'models/deepjingling-songwriter4_epoch8.dnn'\n",
      "data has 30690 characters, 54 unique.\n",
      "Minibatch: 0, Train Loss: 1.6132421875, Train Evaluation Criterion: 0.49\n",
      "Epoch 0, 0.000000 % done\n",
      "§one.\n",
      "\n",
      "the vestle upon the fashled upon the words of rote of touch adouttise dress of bird from while, so the dantall. and passing to diad, the guvated the light is a gretting propaty strange.\n",
      "\n",
      "above her is swone. i iz round my dreavhter, little tuarlets of the wedvented to him worred, he girl in the\n",
      "Minibatch: 100, Train Loss: 1.4540719604492187, Train Evaluation Criterion: 0.37\n",
      "Epoch 0, 32.679739 % done\n",
      "Minibatch: 200, Train Loss: 1.6020806884765626, Train Evaluation Criterion: 0.51\n",
      "Epoch 0, 65.359477 % done\n",
      "Minibatch: 300, Train Loss: 1.5163290405273437, Train Evaluation Criterion: 0.55\n",
      "Epoch 0, 98.039216 % done\n",
      "data has 30690 characters, 54 unique.\n",
      "Minibatch: 0, Train Loss: 1.4498799133300782, Train Evaluation Criterion: 0.42\n",
      "Epoch 0, 0.000000 % done\n",
      "§ones\n",
      "qure deal expumter's girtan in a pilless when not clath of a sea2ing\n",
      "me!\" christmas eve\n",
      "curkred\n",
      "preceidful him\n",
      "merry christmas\n",
      "\"now a life sun morning!\n",
      "\n",
      "i've night at the nidking\n",
      "and in his candless crumbing\n",
      "realing barjing santa baby,\n",
      "just to king.\n",
      "\n",
      "just burley is neight.\n",
      "\n",
      "is i lay know we zon\n",
      "Minibatch: 100, Train Loss: 1.2591123962402344, Train Evaluation Criterion: 0.39\n",
      "Epoch 0, 32.679739 % done\n",
      "Minibatch: 200, Train Loss: 1.089713363647461, Train Evaluation Criterion: 0.29\n",
      "Epoch 0, 65.359477 % done\n",
      "Minibatch: 300, Train Loss: 1.340764923095703, Train Evaluation Criterion: 0.39\n",
      "Epoch 0, 98.039216 % done\n",
      "data has 30690 characters, 54 unique.\n",
      "Minibatch: 0, Train Loss: 1.4402462768554687, Train Evaluation Criterion: 0.44\n",
      "Epoch 0, 0.000000 % done\n",
      "§and pnastings\n",
      "§ feling the malling vingle belles\n",
      "\n",
      "we see a white,\n",
      "for the sboks from\n",
      "another at a tabring, a laying\n",
      "\" leved to say\n",
      "for your lay christmas\n",
      "im your christmaszed on a girds a merry christmas,\n",
      "yoy partridge in a king\n",
      "\n",
      "christmas tree\n",
      "2\n",
      "we wage a masth,\n",
      "all ye coving\n",
      "let us discord\n",
      "come\n",
      " i\n",
      "Minibatch: 100, Train Loss: 1.2019930267333985, Train Evaluation Criterion: 0.4\n",
      "Epoch 0, 32.679739 % done\n",
      "Minibatch: 200, Train Loss: 0.9204495239257813, Train Evaluation Criterion: 0.3\n",
      "Epoch 0, 65.359477 % done\n",
      "Minibatch: 300, Train Loss: 1.3275126647949218, Train Evaluation Criterion: 0.45\n",
      "Epoch 0, 98.039216 % done\n",
      "data has 338901 characters, 54 unique.\n",
      "Minibatch: 0, Train Loss: 2.4023208618164062, Train Evaluation Criterion: 0.62\n",
      "Epoch 0, 0.000000 % done\n",
      "§to see\n",
      "qurm to you land\n",
      "he bieling again\n",
      "\n",
      "she light have coming-ful day of wish you a nide--and reindeer was |ims of a snowth tonight\n",
      "\n",
      "and a new ying\n",
      "7 leabing of the night\n",
      "santa baby\n",
      "4 turtle doves\n",
      "and a milking\n",
      "6 may less will friends and eyes langer by the snow in a perface of their nand\n",
      "\n",
      "jells a\n",
      "Minibatch: 100, Train Loss: 1.7564295959472656, Train Evaluation Criterion: 0.54\n",
      "Epoch 0, 2.950723 % done\n",
      "Minibatch: 200, Train Loss: 1.691739501953125, Train Evaluation Criterion: 0.54\n",
      "Epoch 0, 5.901446 % done\n",
      "Minibatch: 300, Train Loss: 1.9046821594238281, Train Evaluation Criterion: 0.55\n",
      "Epoch 0, 8.852169 % done\n",
      "Minibatch: 400, Train Loss: 1.6045013427734376, Train Evaluation Criterion: 0.52\n",
      "Epoch 0, 11.802892 % done\n",
      "Minibatch: 500, Train Loss: 1.5209017944335939, Train Evaluation Criterion: 0.43\n",
      "Epoch 0, 14.753615 % done\n",
      "Minibatch: 600, Train Loss: 1.3507286071777345, Train Evaluation Criterion: 0.37\n",
      "Epoch 0, 17.704338 % done\n",
      "Minibatch: 700, Train Loss: 1.3811981201171875, Train Evaluation Criterion: 0.43\n",
      "Epoch 0, 20.655060 % done\n",
      "Minibatch: 800, Train Loss: 1.7530824279785155, Train Evaluation Criterion: 0.46\n",
      "Epoch 0, 23.605783 % done\n",
      "Minibatch: 900, Train Loss: 1.8994023132324218, Train Evaluation Criterion: 0.55\n",
      "Epoch 0, 26.556506 % done\n",
      "Minibatch: 1000, Train Loss: 1.521925506591797, Train Evaluation Criterion: 0.49\n",
      "Epoch 0, 29.507229 % done\n",
      "§on harght centles, and dalling.\"\n",
      "\n",
      "\"this isly thecsoughts of their livisd of oir on.\"\n",
      "\n",
      "\"it was, the daddy of ploared strizes too. unboys was not upon me feors of the angesse matches the great leath bosset1ing upwested of enborch wouldn't so quite the andment. \"don't most, puntioned whobe-come, and it\n",
      "Minibatch: 1100, Train Loss: 1.3066801452636718, Train Evaluation Criterion: 0.39\n",
      "Epoch 0, 32.457952 % done\n",
      "Minibatch: 1200, Train Loss: 1.57663330078125, Train Evaluation Criterion: 0.47\n",
      "Epoch 0, 35.408675 % done\n",
      "Minibatch: 1300, Train Loss: 1.4095578002929687, Train Evaluation Criterion: 0.44\n",
      "Epoch 0, 38.359398 % done\n",
      "Minibatch: 1400, Train Loss: 1.5407858276367188, Train Evaluation Criterion: 0.44\n",
      "Epoch 0, 41.310121 % done\n",
      "Minibatch: 1500, Train Loss: 1.5339138793945313, Train Evaluation Criterion: 0.46\n",
      "Epoch 0, 44.260844 % done\n",
      "Minibatch: 1600, Train Loss: 1.3930964660644531, Train Evaluation Criterion: 0.44\n",
      "Epoch 0, 47.211567 % done\n",
      "Minibatch: 1700, Train Loss: 1.2835223388671875, Train Evaluation Criterion: 0.4\n",
      "Epoch 0, 50.162290 % done\n",
      "Minibatch: 1800, Train Loss: 1.601243896484375, Train Evaluation Criterion: 0.47\n",
      "Epoch 0, 53.113013 % done\n",
      "Minibatch: 1900, Train Loss: 1.4716160583496094, Train Evaluation Criterion: 0.5\n",
      "Epoch 0, 56.063736 % done\n",
      "Minibatch: 2000, Train Loss: 1.4774301147460938, Train Evaluation Criterion: 0.48\n",
      "Epoch 0, 59.014459 % done\n",
      "§one, what there is cardly sject music's my skusal, away.\"\n",
      "\n",
      "\"i iwincomphist and the haw, i don't know, horge; and wing done in the other handslord,\" said shut of rounds, are there this who were most did won't poy,\" this master of its good and petermor spake what we orcune my see, is to sleed of gaste\n",
      "Minibatch: 2100, Train Loss: 1.4543255615234374, Train Evaluation Criterion: 0.42\n",
      "Epoch 0, 61.965181 % done\n",
      "Minibatch: 2200, Train Loss: 1.2481256103515626, Train Evaluation Criterion: 0.41\n",
      "Epoch 0, 64.915904 % done\n",
      "Minibatch: 2300, Train Loss: 1.3611085510253906, Train Evaluation Criterion: 0.46\n",
      "Epoch 0, 67.866627 % done\n",
      "Minibatch: 2400, Train Loss: 1.7459701538085937, Train Evaluation Criterion: 0.56\n",
      "Epoch 0, 70.817350 % done\n",
      "Minibatch: 2500, Train Loss: 1.480272979736328, Train Evaluation Criterion: 0.4\n",
      "Epoch 0, 73.768073 % done\n",
      "Minibatch: 2600, Train Loss: 1.3317642211914062, Train Evaluation Criterion: 0.44\n",
      "Epoch 0, 76.718796 % done\n",
      "Minibatch: 2700, Train Loss: 1.5063539123535157, Train Evaluation Criterion: 0.44\n",
      "Epoch 0, 79.669519 % done\n",
      "Minibatch: 2800, Train Loss: 1.7184443664550781, Train Evaluation Criterion: 0.53\n",
      "Epoch 0, 82.620242 % done\n",
      "Minibatch: 2900, Train Loss: 1.2859249877929688, Train Evaluation Criterion: 0.38\n",
      "Epoch 0, 85.570965 % done\n",
      "Minibatch: 3000, Train Loss: 1.4676022338867187, Train Evaluation Criterion: 0.45\n",
      "Epoch 0, 88.521688 % done\n",
      "§or gaadvently, he was having that would sure full of them fake stood in't all from the volleath, but the antined to meeter she wide the boat from leps, \"will he had looked the convilage into same of the tetrels of them-fidles cattches know,\" said darkness with the tyorsirgars in the time of their ro\n",
      "Minibatch: 3100, Train Loss: 1.6050881958007812, Train Evaluation Criterion: 0.44\n",
      "Epoch 0, 91.472411 % done\n",
      "Minibatch: 3200, Train Loss: 1.7063919067382813, Train Evaluation Criterion: 0.49\n",
      "Epoch 0, 94.423134 % done\n",
      "Minibatch: 3300, Train Loss: 1.7505099487304687, Train Evaluation Criterion: 0.47\n",
      "Epoch 0, 97.373857 % done\n",
      "Saved model to 'models/deepjingling-songwriter4_epoch12.dnn'\n",
      "data has 30690 characters, 54 unique.\n",
      "Minibatch: 0, Train Loss: 1.4911898803710937, Train Evaluation Criterion: 0.48\n",
      "Epoch 0, 0.000000 % done\n",
      "§reath as the that king to deesonor in white, there shine of my servician, which has cartainly wise has danced. he looked, bitter, and spired the fuglec, when you thee showning, and upon the very light, once to be the fine to where it for a laughter till round very carroried noingered for a beat. he \n",
      "Minibatch: 100, Train Loss: 1.4226708984375, Train Evaluation Criterion: 0.41\n",
      "Epoch 0, 32.679739 % done\n",
      "Minibatch: 200, Train Loss: 1.3047920227050782, Train Evaluation Criterion: 0.39\n",
      "Epoch 0, 65.359477 % done\n",
      "Minibatch: 300, Train Loss: 1.4275453186035156, Train Evaluation Criterion: 0.47\n",
      "Epoch 0, 98.039216 % done\n",
      "data has 30690 characters, 54 unique.\n",
      "Minibatch: 0, Train Loss: 1.5216752624511718, Train Evaluation Criterion: 0.52\n",
      "Epoch 0, 0.000000 % done\n",
      "§ing\n",
      "he got a time of all the hops was at, right\n",
      "when i cause a man the cards and gearth die\n",
      "\n",
      "heavenly to like a prining as went lay canning our bearis\n",
      "we're big there's obed\n",
      "in a day of the tenth tree\n",
      "\n",
      "on the year might tiny a partridge in a partridge in a pear tree\n",
      "3o live his little pulling mind i\n",
      "Minibatch: 100, Train Loss: 1.1012525939941407, Train Evaluation Criterion: 0.34\n",
      "Epoch 0, 32.679739 % done\n",
      "Minibatch: 200, Train Loss: 0.8499905395507813, Train Evaluation Criterion: 0.22\n",
      "Epoch 0, 65.359477 % done\n",
      "Minibatch: 300, Train Loss: 1.2168453979492186, Train Evaluation Criterion: 0.4\n",
      "Epoch 0, 98.039216 % done\n",
      "data has 30690 characters, 54 unique.\n",
      "Minibatch: 0, Train Loss: 1.3081005859375, Train Evaluation Criterion: 0.43\n",
      "Epoch 0, 0.000000 % done\n",
      "§nice-light\n",
      "telling in a fairy christmas tree\n",
      "\n",
      "on the king words a merry christmas\n",
      "my true love sent to me:\n",
      "11 pear tree\n",
      "\n",
      "on thy myst really little boy\n",
      "are you know\n",
      "and a laying\n",
      "$ maids a merry christmas,\n",
      "we wish you a partridge in a partridge in a partridge in a partridge in a pear tree\n",
      "lunt days to\n",
      "Minibatch: 100, Train Loss: 1.010677490234375, Train Evaluation Criterion: 0.29\n",
      "Epoch 0, 32.679739 % done\n",
      "Minibatch: 200, Train Loss: 0.6413438415527344, Train Evaluation Criterion: 0.18\n",
      "Epoch 0, 65.359477 % done\n",
      "Minibatch: 300, Train Loss: 1.0348162078857421, Train Evaluation Criterion: 0.35\n",
      "Epoch 0, 98.039216 % done\n",
      "data has 338901 characters, 54 unique.\n",
      "Minibatch: 0, Train Loss: 2.030262756347656, Train Evaluation Criterion: 0.6\n",
      "Epoch 0, 0.000000 % done\n",
      "§one may him\n",
      "pa rum pum pum pum pum pum pum,\n",
      "rum pum pum pum pum pum pum pum\n",
      "i murried\n",
      "you maist happy cabling\n",
      "\n",
      "just wonderful time of a porty name\n",
      "to me:\n",
      "3 golden rings\n",
      "4 calling birds\n",
      "9 french hens\n",
      "2 turtle doves\n",
      "and a partridge in a partridge in a pear tree\n",
      "\n",
      "on the eightly seemed\n",
      "and fark out into\n",
      "Minibatch: 100, Train Loss: 1.6296218872070312, Train Evaluation Criterion: 0.48\n",
      "Epoch 0, 2.950723 % done\n",
      "Minibatch: 200, Train Loss: 1.6392758178710938, Train Evaluation Criterion: 0.49\n",
      "Epoch 0, 5.901446 % done\n",
      "Minibatch: 300, Train Loss: 1.8640139770507813, Train Evaluation Criterion: 0.55\n",
      "Epoch 0, 8.852169 % done\n",
      "Minibatch: 400, Train Loss: 1.5247772216796875, Train Evaluation Criterion: 0.48\n",
      "Epoch 0, 11.802892 % done\n",
      "Minibatch: 500, Train Loss: 1.3763252258300782, Train Evaluation Criterion: 0.41\n",
      "Epoch 0, 14.753615 % done\n",
      "Minibatch: 600, Train Loss: 1.2834678649902345, Train Evaluation Criterion: 0.41\n",
      "Epoch 0, 17.704338 % done\n",
      "Minibatch: 700, Train Loss: 1.3004830932617188, Train Evaluation Criterion: 0.42\n",
      "Epoch 0, 20.655060 % done\n",
      "Minibatch: 800, Train Loss: 1.6869955444335938, Train Evaluation Criterion: 0.47\n",
      "Epoch 0, 23.605783 % done\n",
      "Minibatch: 900, Train Loss: 2.034984588623047, Train Evaluation Criterion: 0.6\n",
      "Epoch 0, 26.556506 % done\n",
      "Minibatch: 1000, Train Loss: 1.43634033203125, Train Evaluation Criterion: 0.48\n",
      "Epoch 0, 29.507229 % done\n",
      "§on. it's blueking of sames of a world falling one.\"\n",
      "\n",
      "\"so piested up and near,\" said scrooge or elses backlory hid and and strange, and had a great silats very good bathers! and should conscious christmas packedless.\n",
      "\n",
      "\"this lammer to apparited, or connent of peracences, and oken, look in this christm\n",
      "Minibatch: 1100, Train Loss: 1.2508372497558593, Train Evaluation Criterion: 0.37\n",
      "Epoch 0, 32.457952 % done\n",
      "Minibatch: 1200, Train Loss: 1.5445664978027345, Train Evaluation Criterion: 0.51\n",
      "Epoch 0, 35.408675 % done\n",
      "Minibatch: 1300, Train Loss: 1.3139158630371093, Train Evaluation Criterion: 0.42\n",
      "Epoch 0, 38.359398 % done\n",
      "Minibatch: 1400, Train Loss: 1.5177371215820312, Train Evaluation Criterion: 0.46\n",
      "Epoch 0, 41.310121 % done\n",
      "Minibatch: 1500, Train Loss: 1.4803276062011719, Train Evaluation Criterion: 0.48\n",
      "Epoch 0, 44.260844 % done\n",
      "Minibatch: 1600, Train Loss: 1.4167462158203126, Train Evaluation Criterion: 0.46\n",
      "Epoch 0, 47.211567 % done\n",
      "Minibatch: 1700, Train Loss: 1.3094477844238281, Train Evaluation Criterion: 0.41\n",
      "Epoch 0, 50.162290 % done\n",
      "Minibatch: 1800, Train Loss: 1.5183322143554687, Train Evaluation Criterion: 0.49\n",
      "Epoch 0, 53.113013 % done\n",
      "Minibatch: 1900, Train Loss: 1.4490879821777343, Train Evaluation Criterion: 0.45\n",
      "Epoch 0, 56.063736 % done\n",
      "Minibatch: 2000, Train Loss: 1.3362350463867188, Train Evaluation Criterion: 0.42\n",
      "Epoch 0, 59.014459 % done\n",
      "§rotide of the fire, second witaous over the figure.\n",
      "\n",
      "\"dinging himself in scrooge's dim.\"\n",
      "\n",
      "\"shown of sold good a sorris of matterhouse, ho we have from his good.\n",
      "\n",
      "\"now, when i have not, rab that in his heart buy had seemed at the manter, but i am dryngs with a funerly, which was rathated her is the d\n",
      "Minibatch: 2100, Train Loss: 1.4258824157714844, Train Evaluation Criterion: 0.41\n",
      "Epoch 0, 61.965181 % done\n",
      "Minibatch: 2200, Train Loss: 1.283391571044922, Train Evaluation Criterion: 0.37\n",
      "Epoch 0, 64.915904 % done\n",
      "Minibatch: 2300, Train Loss: 1.2923995971679687, Train Evaluation Criterion: 0.38\n",
      "Epoch 0, 67.866627 % done\n",
      "Minibatch: 2400, Train Loss: 1.672235107421875, Train Evaluation Criterion: 0.51\n",
      "Epoch 0, 70.817350 % done\n",
      "Minibatch: 2500, Train Loss: 1.415359344482422, Train Evaluation Criterion: 0.43\n",
      "Epoch 0, 73.768073 % done\n",
      "Minibatch: 2600, Train Loss: 1.3286077880859375, Train Evaluation Criterion: 0.43\n",
      "Epoch 0, 76.718796 % done\n",
      "Minibatch: 2700, Train Loss: 1.6714501953125, Train Evaluation Criterion: 0.52\n",
      "Epoch 0, 79.669519 % done\n",
      "Minibatch: 2800, Train Loss: 1.6540501403808594, Train Evaluation Criterion: 0.52\n",
      "Epoch 0, 82.620242 % done\n",
      "Minibatch: 2900, Train Loss: 1.2060047912597656, Train Evaluation Criterion: 0.36\n",
      "Epoch 0, 85.570965 % done\n",
      "Minibatch: 3000, Train Loss: 1.3988339233398437, Train Evaluation Criterion: 0.47\n",
      "Epoch 0, 88.521688 % done\n",
      "§ultion comes of noim.\n",
      "\n",
      "if all. the great blue rather made come for his rithe mown, white being into muses never clears amside a looked his fulus brail men; and got over only of his corfitable since, sxail by it to?\n",
      "berited the room he regventing by the lirth for mister buttoning of starishmong, in t\n",
      "Minibatch: 3100, Train Loss: 1.6394866943359374, Train Evaluation Criterion: 0.42\n",
      "Epoch 0, 91.472411 % done\n",
      "Minibatch: 3200, Train Loss: 1.6569216918945313, Train Evaluation Criterion: 0.49\n",
      "Epoch 0, 94.423134 % done\n",
      "Minibatch: 3300, Train Loss: 1.7008766174316405, Train Evaluation Criterion: 0.48\n",
      "Epoch 0, 97.373857 % done\n",
      "Saved model to 'models/deepjingling-songwriter4_epoch16.dnn'\n",
      "data has 30690 characters, 54 unique.\n",
      "Minibatch: 0, Train Loss: 1.4637138366699218, Train Evaluation Criterion: 0.43\n",
      "Epoch 0, 0.000000 % done\n",
      "§oned left hand, and if he had convusianted the lodge, and he remembered the virtal, plain through a graced one.\n",
      "\n",
      "the laiged, and we soon in an euchrise appried.\n",
      "\n",
      "wells, with while the new comprises was orlieves who glads out and tricely. how think of relorian thay you will disus are meaned, for the \n",
      "Minibatch: 100, Train Loss: 1.2464793395996094, Train Evaluation Criterion: 0.35\n",
      "Epoch 0, 32.679739 % done\n",
      "Minibatch: 200, Train Loss: 1.081719207763672, Train Evaluation Criterion: 0.35\n",
      "Epoch 0, 65.359477 % done\n",
      "Minibatch: 300, Train Loss: 1.2470991516113281, Train Evaluation Criterion: 0.38\n",
      "Epoch 0, 98.039216 % done\n",
      "data has 30690 characters, 54 unique.\n",
      "Minibatch: 0, Train Loss: 1.347659912109375, Train Evaluation Criterion: 0.51\n",
      "Epoch 0, 0.000000 % done\n",
      "§or godd of .part is christmas,\n",
      "he'll be them,\n",
      "sing!\n",
      "\n",
      "rai all years santa baby\n",
      "\n",
      "so full bai every given rise\n",
      "\n",
      "nover me!\n",
      "artaban told\n",
      "\n",
      "i must see an appiler\n",
      "snow mr. grinch,\n",
      "jingle bell\n",
      "rings  a partridge in a partridge in a pear tree\n",
      "\n",
      "on the city joy\n",
      "\n",
      "\"good and you are\n",
      "a makes a care from pop\n",
      "there's\n",
      "Minibatch: 100, Train Loss: 1.0762464904785156, Train Evaluation Criterion: 0.38\n",
      "Epoch 0, 32.679739 % done\n",
      "Minibatch: 200, Train Loss: 0.7220711517333984, Train Evaluation Criterion: 0.24\n",
      "Epoch 0, 65.359477 % done\n",
      "Minibatch: 300, Train Loss: 1.243147201538086, Train Evaluation Criterion: 0.36\n",
      "Epoch 0, 98.039216 % done\n",
      "data has 30690 characters, 54 unique.\n",
      "Minibatch: 0, Train Loss: 1.2076312255859376, Train Evaluation Criterion: 0.37\n",
      "Epoch 0, 0.000000 % done\n",
      "§under the sight\n",
      "\n",
      "what fun it is to me:\n",
      "4'm a pear tree\n",
      "o christmas\n",
      "and a magia\n",
      "for the swive santa cumiously fame with toastreing\n",
      "zeels a man sweet hear \n",
      "and a'round when the feet his rorns\n",
      "4 calling birds\n",
      "3 french hens\n",
      "2 turtle doves\n",
      "and a partridge in a partridge in a partridge in a pear tree\n",
      "\n",
      "on \n",
      "Minibatch: 100, Train Loss: 1.0437527465820313, Train Evaluation Criterion: 0.33\n",
      "Epoch 0, 32.679739 % done\n",
      "Minibatch: 200, Train Loss: 0.648785629272461, Train Evaluation Criterion: 0.15\n",
      "Epoch 0, 65.359477 % done\n",
      "Minibatch: 300, Train Loss: 0.9251542663574219, Train Evaluation Criterion: 0.33\n",
      "Epoch 0, 98.039216 % done\n",
      "data has 338901 characters, 54 unique.\n",
      "Minibatch: 0, Train Loss: 2.2023016357421876, Train Evaluation Criterion: 0.58\n",
      "Epoch 0, 0.000000 % done\n",
      "§one without one\n",
      "with they\n",
      "seeting without\n",
      "merry christmas tree\n",
      "man i haven't been a baby\n",
      "pa rum pum pum pum\n",
      "then even you an earth\n",
      "mighty christmas\n",
      "with fun it is to me:\n",
      "4 saw the mean's fint and did\n",
      "be torth over birds\n",
      "3 french hens\n",
      "2 turtle doves\n",
      "and a partridge in a pear tree\n",
      "\n",
      "on the with they br\n",
      "Minibatch: 100, Train Loss: 1.5471200561523437, Train Evaluation Criterion: 0.46\n",
      "Epoch 0, 2.950723 % done\n",
      "Minibatch: 200, Train Loss: 1.5767208862304687, Train Evaluation Criterion: 0.5\n",
      "Epoch 0, 5.901446 % done\n",
      "Minibatch: 300, Train Loss: 1.8490509033203124, Train Evaluation Criterion: 0.55\n",
      "Epoch 0, 8.852169 % done\n",
      "Minibatch: 400, Train Loss: 1.4148857116699218, Train Evaluation Criterion: 0.44\n",
      "Epoch 0, 11.802892 % done\n",
      "Minibatch: 500, Train Loss: 1.3166864013671875, Train Evaluation Criterion: 0.39\n",
      "Epoch 0, 14.753615 % done\n",
      "Minibatch: 600, Train Loss: 1.3365753173828125, Train Evaluation Criterion: 0.46\n",
      "Epoch 0, 17.704338 % done\n",
      "Minibatch: 700, Train Loss: 1.264081268310547, Train Evaluation Criterion: 0.41\n",
      "Epoch 0, 20.655060 % done\n",
      "Minibatch: 800, Train Loss: 1.7087864685058594, Train Evaluation Criterion: 0.49\n",
      "Epoch 0, 23.605783 % done\n",
      "Minibatch: 900, Train Loss: 1.956273651123047, Train Evaluation Criterion: 0.56\n",
      "Epoch 0, 26.556506 % done\n",
      "Minibatch: 1000, Train Loss: 1.4004368591308594, Train Evaluation Criterion: 0.43\n",
      "Epoch 0, 29.507229 % done\n",
      "§ons, and say sow blacksees; there were parters of palley. it is that its spection far, of wants at the catts of escames, \"nellifected the sames than the pause is an old like molrent; and the shutfer bnight toip a's thoughts of that,\" cried scrooge. when the airver reindeer said dust markers when; th\n",
      "Minibatch: 1100, Train Loss: 1.1641627502441407, Train Evaluation Criterion: 0.33\n",
      "Epoch 0, 32.457952 % done\n",
      "Minibatch: 1200, Train Loss: 1.644689178466797, Train Evaluation Criterion: 0.52\n",
      "Epoch 0, 35.408675 % done\n",
      "Minibatch: 1300, Train Loss: 1.3438766479492188, Train Evaluation Criterion: 0.37\n",
      "Epoch 0, 38.359398 % done\n",
      "Minibatch: 1400, Train Loss: 1.4895941162109374, Train Evaluation Criterion: 0.48\n",
      "Epoch 0, 41.310121 % done\n",
      "Minibatch: 1500, Train Loss: 1.3930337524414063, Train Evaluation Criterion: 0.4\n",
      "Epoch 0, 44.260844 % done\n",
      "Minibatch: 1600, Train Loss: 1.3252168273925782, Train Evaluation Criterion: 0.43\n",
      "Epoch 0, 47.211567 % done\n",
      "Minibatch: 1700, Train Loss: 1.2427399444580078, Train Evaluation Criterion: 0.4\n",
      "Epoch 0, 50.162290 % done\n",
      "Minibatch: 1800, Train Loss: 1.5672720336914063, Train Evaluation Criterion: 0.47\n",
      "Epoch 0, 53.113013 % done\n",
      "Minibatch: 1900, Train Loss: 1.4556271362304687, Train Evaluation Criterion: 0.46\n",
      "Epoch 0, 56.063736 % done\n",
      "Minibatch: 2000, Train Loss: 1.3866790771484374, Train Evaluation Criterion: 0.42\n",
      "Epoch 0, 59.014459 % done\n",
      "§with the light semped, heavenning which is a cerdoply ago.\n",
      "4\"'§ happy do, to me. i should you ask my back weallitary gone, mistletoe young sex who, saunce pleasant thought!\"\n",
      "\n",
      "he contenty i that all of arant stadle. \"my good time,\" said bob. \"oh, which your hands. both blew not evenent saletmind off \n",
      "Minibatch: 2100, Train Loss: 1.3863427734375, Train Evaluation Criterion: 0.45\n",
      "Epoch 0, 61.965181 % done\n",
      "Minibatch: 2200, Train Loss: 1.2527354431152344, Train Evaluation Criterion: 0.38\n",
      "Epoch 0, 64.915904 % done\n",
      "Minibatch: 2300, Train Loss: 1.2704431915283203, Train Evaluation Criterion: 0.4\n",
      "Epoch 0, 67.866627 % done\n",
      "Minibatch: 2400, Train Loss: 1.5821275329589843, Train Evaluation Criterion: 0.53\n",
      "Epoch 0, 70.817350 % done\n",
      "Minibatch: 2500, Train Loss: 1.2847152709960938, Train Evaluation Criterion: 0.39\n",
      "Epoch 0, 73.768073 % done\n",
      "Minibatch: 2600, Train Loss: 1.289544677734375, Train Evaluation Criterion: 0.4\n",
      "Epoch 0, 76.718796 % done\n",
      "Minibatch: 2700, Train Loss: 1.5085569763183593, Train Evaluation Criterion: 0.48\n",
      "Epoch 0, 79.669519 % done\n",
      "Minibatch: 2800, Train Loss: 1.609674072265625, Train Evaluation Criterion: 0.54\n",
      "Epoch 0, 82.620242 % done\n",
      "Minibatch: 2900, Train Loss: 1.1746710205078126, Train Evaluation Criterion: 0.35\n",
      "Epoch 0, 85.570965 % done\n",
      "Minibatch: 3000, Train Loss: 1.31383056640625, Train Evaluation Criterion: 0.4\n",
      "Epoch 0, 88.521688 % done\n",
      "§outs,\" off his own o-legth golden,\" said spance by been eldest to fairs, it is arniz, and you know!\"\n",
      "\n",
      "there deepression the dolt peterstature with teels!\n",
      "\n",
      "\"it cut she was salen of peace fairt seemed the its coh;, and the time of seemed with spiry have noher. he getting the houses of glories of a gre\n",
      "Minibatch: 3100, Train Loss: 1.5330917358398437, Train Evaluation Criterion: 0.41\n",
      "Epoch 0, 91.472411 % done\n",
      "Minibatch: 3200, Train Loss: 1.6305477905273438, Train Evaluation Criterion: 0.48\n",
      "Epoch 0, 94.423134 % done\n",
      "Minibatch: 3300, Train Loss: 1.6766658020019531, Train Evaluation Criterion: 0.52\n",
      "Epoch 0, 97.373857 % done\n",
      "Saved model to 'models/deepjingling-songwriter4_epoch20.dnn'\n",
      "data has 30690 characters, 54 unique.\n",
      "Minibatch: 0, Train Loss: 1.3350498962402344, Train Evaluation Criterion: 0.43\n",
      "Epoch 0, 0.000000 % done\n",
      "§outs on one roll of his heav. he could read over left and the juck embrey. one received to nurcramed at the dinner, with nor had the singal.\n",
      "\n",
      "he was very passed to the bethlehem in heaven, with brath for nervise. in here that not every leaf cuckoo, where the expect and given his found-mastrents.\n",
      "\n",
      "wh\n",
      "Minibatch: 100, Train Loss: 1.1906454467773437, Train Evaluation Criterion: 0.35\n",
      "Epoch 0, 32.679739 % done\n",
      "Minibatch: 200, Train Loss: 0.8349917602539062, Train Evaluation Criterion: 0.24\n",
      "Epoch 0, 65.359477 % done\n",
      "Minibatch: 300, Train Loss: 1.2058151245117188, Train Evaluation Criterion: 0.4\n",
      "Epoch 0, 98.039216 % done\n",
      "data has 30690 characters, 54 unique.\n",
      "Minibatch: 0, Train Loss: 1.368140869140625, Train Evaluation Criterion: 0.43\n",
      "Epoch 0, 0.000000 % done\n",
      "§on the hearts\n",
      "\n",
      "jingle bell,\n",
      "just heavenly noise as a christmas\n",
      "my true love sent to me:\n",
      "5 geese a laying\n",
      "6 golden rings\n",
      "1 calling bells sittle senves\n",
      "\n",
      "it's for me!\n",
      "|there's a pear tree\n",
      "\n",
      "on the newborn king\n",
      "- golden rings\n",
      "5 calling birds\n",
      "3 frinch hens\n",
      "2 turtle doves\n",
      "and a man we're sharp, \"three' is \n",
      "Minibatch: 100, Train Loss: 1.1198033142089843, Train Evaluation Criterion: 0.36\n",
      "Epoch 0, 32.679739 % done\n",
      "Minibatch: 200, Train Loss: 0.5158515167236328, Train Evaluation Criterion: 0.13\n",
      "Epoch 0, 65.359477 % done\n",
      "Minibatch: 300, Train Loss: 0.951075439453125, Train Evaluation Criterion: 0.31\n",
      "Epoch 0, 98.039216 % done\n",
      "data has 30690 characters, 54 unique.\n",
      "Minibatch: 0, Train Loss: 1.2589344024658202, Train Evaluation Criterion: 0.42\n",
      "Epoch 0, 0.000000 % done\n",
      "§on a brightning\n",
      "we'll follow the city\n",
      "sribling\n",
      "everyone's down being puckories sing\n",
      "and say as the head'\n",
      "\n",
      "and everloth! they have apparting in a winter were.\n",
      "\n",
      "o come, let's not come\n",
      "\n",
      "your santa came\n",
      "i'll dear\n",
      "christ the now with toys\n",
      "christmas's candles so remaids\n",
      "a calling your rilling\n",
      "we're gurmed\n",
      "Minibatch: 100, Train Loss: 0.9029324340820313, Train Evaluation Criterion: 0.28\n",
      "Epoch 0, 32.679739 % done\n",
      "Minibatch: 200, Train Loss: 0.47441673278808594, Train Evaluation Criterion: 0.1\n",
      "Epoch 0, 65.359477 % done\n",
      "Minibatch: 300, Train Loss: 0.8330438232421875, Train Evaluation Criterion: 0.27\n",
      "Epoch 0, 98.039216 % done\n",
      "data has 338901 characters, 54 unique.\n",
      "Minibatch: 0, Train Loss: 1.9121597290039063, Train Evaluation Criterion: 0.52\n",
      "Epoch 0, 0.000000 % done\n",
      "§and of year.\n",
      "|shall i me.\n",
      "\n",
      "o come by the chimney.\n",
      "\n",
      "sing a spirit sing\n",
      "|everywhere you can said\n",
      "santa baby,\n",
      "i'm dancing me propers praises\n",
      "pa rum pum pum pum pum pum pum pum pum pum\n",
      "pum pum\n",
      "pum pum\n",
      "when you'ke the world benot me to shade\n",
      " have a child, we'll have been\n",
      "and, a such christmas tree\n",
      "many \n",
      "Minibatch: 100, Train Loss: 1.5233010864257812, Train Evaluation Criterion: 0.44\n",
      "Epoch 0, 2.950723 % done\n",
      "Minibatch: 200, Train Loss: 1.5051507568359375, Train Evaluation Criterion: 0.45\n",
      "Epoch 0, 5.901446 % done\n",
      "Minibatch: 300, Train Loss: 1.8442550659179688, Train Evaluation Criterion: 0.57\n",
      "Epoch 0, 8.852169 % done\n",
      "Minibatch: 400, Train Loss: 1.3818408203125, Train Evaluation Criterion: 0.41\n",
      "Epoch 0, 11.802892 % done\n",
      "Minibatch: 500, Train Loss: 1.33487060546875, Train Evaluation Criterion: 0.37\n",
      "Epoch 0, 14.753615 % done\n",
      "Minibatch: 600, Train Loss: 1.2618927001953124, Train Evaluation Criterion: 0.4\n",
      "Epoch 0, 17.704338 % done\n",
      "Minibatch: 700, Train Loss: 1.2861624145507813, Train Evaluation Criterion: 0.39\n",
      "Epoch 0, 20.655060 % done\n",
      "Minibatch: 800, Train Loss: 1.7828140258789062, Train Evaluation Criterion: 0.55\n",
      "Epoch 0, 23.605783 % done\n",
      "Minibatch: 900, Train Loss: 2.0101353454589845, Train Evaluation Criterion: 0.61\n",
      "Epoch 0, 26.556506 % done\n",
      "Minibatch: 1000, Train Loss: 1.2769549560546876, Train Evaluation Criterion: 0.4\n",
      "Epoch 0, 29.507229 % done\n",
      "§one and some thing, \"on her game fafm to brother confusibly to a good hair and ad old roleth.\n",
      "\n",
      "\"tried dressing would time. is an angins holdow goed mold would. they was given. right in forth some most tair bemused their excited boat, on one fight in their steads of been, -- and touched the never tho\n",
      "Minibatch: 1100, Train Loss: 1.123614044189453, Train Evaluation Criterion: 0.3\n",
      "Epoch 0, 32.457952 % done\n",
      "Minibatch: 1200, Train Loss: 1.5187579345703126, Train Evaluation Criterion: 0.49\n",
      "Epoch 0, 35.408675 % done\n",
      "Minibatch: 1300, Train Loss: 1.1703262329101562, Train Evaluation Criterion: 0.36\n",
      "Epoch 0, 38.359398 % done\n",
      "Minibatch: 1400, Train Loss: 1.3796548461914062, Train Evaluation Criterion: 0.42\n",
      "Epoch 0, 41.310121 % done\n",
      "Minibatch: 1500, Train Loss: 1.4549658203125, Train Evaluation Criterion: 0.46\n",
      "Epoch 0, 44.260844 % done\n",
      "Minibatch: 1600, Train Loss: 1.30359375, Train Evaluation Criterion: 0.42\n",
      "Epoch 0, 47.211567 % done\n",
      "Minibatch: 1700, Train Loss: 1.255423583984375, Train Evaluation Criterion: 0.36\n",
      "Epoch 0, 50.162290 % done\n",
      "Minibatch: 1800, Train Loss: 1.5263714599609375, Train Evaluation Criterion: 0.5\n",
      "Epoch 0, 53.113013 % done\n",
      "Minibatch: 1900, Train Loss: 1.397689666748047, Train Evaluation Criterion: 0.49\n",
      "Epoch 0, 56.063736 % done\n",
      "Minibatch: 2000, Train Loss: 1.372146759033203, Train Evaluation Criterion: 0.41\n",
      "Epoch 0, 59.014459 % done\n",
      "§one in, nothing to shall court gone from by there into our would be instings a morwer. handing spoke of looking your time. here is a impercouse, sir! scope to as to him,\" replied his. 1on over it is the past as onding at your knees in his name, you are its coental, tertiful even seiving of. and he i\n",
      "Minibatch: 2100, Train Loss: 1.3776019287109376, Train Evaluation Criterion: 0.39\n",
      "Epoch 0, 61.965181 % done\n",
      "Minibatch: 2200, Train Loss: 1.2684202575683594, Train Evaluation Criterion: 0.36\n",
      "Epoch 0, 64.915904 % done\n",
      "Minibatch: 2300, Train Loss: 1.2331893920898438, Train Evaluation Criterion: 0.36\n",
      "Epoch 0, 67.866627 % done\n",
      "Minibatch: 2400, Train Loss: 1.5386967468261719, Train Evaluation Criterion: 0.44\n",
      "Epoch 0, 70.817350 % done\n",
      "Minibatch: 2500, Train Loss: 1.34108642578125, Train Evaluation Criterion: 0.4\n",
      "Epoch 0, 73.768073 % done\n",
      "Minibatch: 2600, Train Loss: 1.207900619506836, Train Evaluation Criterion: 0.38\n",
      "Epoch 0, 76.718796 % done\n",
      "Minibatch: 2700, Train Loss: 1.4456651306152344, Train Evaluation Criterion: 0.46\n",
      "Epoch 0, 79.669519 % done\n",
      "Minibatch: 2800, Train Loss: 1.472576904296875, Train Evaluation Criterion: 0.49\n",
      "Epoch 0, 82.620242 % done\n",
      "Minibatch: 2900, Train Loss: 1.1801084899902343, Train Evaluation Criterion: 0.34\n",
      "Epoch 0, 85.570965 % done\n",
      "Minibatch: 3000, Train Loss: 1.383926239013672, Train Evaluation Criterion: 0.42\n",
      "Epoch 0, 88.521688 % done\n",
      "§our confort too the soldier and master singing the night on a joe. he is uncosplensing away to a village. when the thought the mister free, we green more the fields you dressed that said of the trees, my very ancient rewell,\" cried spring. we must think in the school, and gman of a dolling iganes vi\n",
      "Minibatch: 3100, Train Loss: 1.48356201171875, Train Evaluation Criterion: 0.43\n",
      "Epoch 0, 91.472411 % done\n",
      "Minibatch: 3200, Train Loss: 1.47880126953125, Train Evaluation Criterion: 0.47\n",
      "Epoch 0, 94.423134 % done\n",
      "Minibatch: 3300, Train Loss: 1.687575225830078, Train Evaluation Criterion: 0.48\n",
      "Epoch 0, 97.373857 % done\n",
      "Saved model to 'models/deepjingling-songwriter4_epoch24.dnn'\n",
      "data has 30690 characters, 54 unique.\n",
      "Minibatch: 0, Train Loss: 1.3646748352050782, Train Evaluation Criterion: 0.45\n",
      "Epoch 0, 0.000000 % done\n",
      "§one and cuest among the swall. and a nature let all one falling grandface if he ends of course which the still lend. he led as the daymorrowed him your hards as he may till he stopped to and about in the word.\n",
      "\n",
      "all she had song the close of pracient earth why don't hear thebed read following, should\n",
      "Minibatch: 100, Train Loss: 0.9541622924804688, Train Evaluation Criterion: 0.29\n",
      "Epoch 0, 32.679739 % done\n",
      "Minibatch: 200, Train Loss: 0.656898193359375, Train Evaluation Criterion: 0.18\n",
      "Epoch 0, 65.359477 % done\n",
      "Minibatch: 300, Train Loss: 0.9615763092041015, Train Evaluation Criterion: 0.36\n",
      "Epoch 0, 98.039216 % done\n",
      "data has 30690 characters, 54 unique.\n",
      "Minibatch: 0, Train Loss: 1.1503205108642578, Train Evaluation Criterion: 0.38\n",
      "Epoch 0, 0.000000 % done\n",
      "§on a wear\n",
      "boy to shad around the company\n",
      "and two years of christmas card is coming the tingle all bring\n",
      "5 golden rings\n",
      "4 calling birds\n",
      "3 french hens\n",
      "clus' shining in the christmas\n",
      "my true love sent to me:\n",
      "10 pleasure doves\n",
      "and a partridge in a pear tree\n",
      "\n",
      "on the impertand of the lord, bore before you\n",
      "Minibatch: 100, Train Loss: 0.9164780426025391, Train Evaluation Criterion: 0.27\n",
      "Epoch 0, 32.679739 % done\n",
      "Minibatch: 200, Train Loss: 0.5391976165771485, Train Evaluation Criterion: 0.14\n",
      "Epoch 0, 65.359477 % done\n",
      "Minibatch: 300, Train Loss: 0.7587471008300781, Train Evaluation Criterion: 0.21\n",
      "Epoch 0, 98.039216 % done\n",
      "data has 30690 characters, 54 unique.\n",
      "Minibatch: 0, Train Loss: 0.9975433349609375, Train Evaluation Criterion: 0.31\n",
      "Epoch 0, 0.000000 % done\n",
      "§one all ones are midden\n",
      "but he was one carries full wings\n",
      "we wonderland\n",
      "\n",
      "on the chimney down his heart.\n",
      "\n",
      "the only way on the shepherds\n",
      "and a pear tree,\n",
      "o come, let us adore him,\n",
      "o'concers coming to live\n",
      "jeses be snow! let's be skiwed;\n",
      "and horner will get a house wait-;\n",
      "\n",
      "silent night!\n",
      ",\n",
      "to wly saught\n",
      "Minibatch: 100, Train Loss: 0.8665867614746093, Train Evaluation Criterion: 0.28\n",
      "Epoch 0, 32.679739 % done\n",
      "Minibatch: 200, Train Loss: 0.42700767517089844, Train Evaluation Criterion: 0.09\n",
      "Epoch 0, 65.359477 % done\n",
      "Minibatch: 300, Train Loss: 0.8757258605957031, Train Evaluation Criterion: 0.26\n",
      "Epoch 0, 98.039216 % done\n",
      "data has 338901 characters, 54 unique.\n",
      "Minibatch: 0, Train Loss: 1.9118907165527343, Train Evaluation Criterion: 0.5\n",
      "Epoch 0, 0.000000 % done\n",
      "§one doesn't christmas\n",
      "when you're a sung of christmas\n",
      "with everywhere santa\n",
      "but as singing\n",
      "there's a hippy thing\n",
      "i'm delicidies\n",
      "3 geese a laying\n",
      "4 golden rings\n",
      "4 calling birds\n",
      "3 french hens\n",
      "2 turtle doves\n",
      "and a partridge in a pear tree\n",
      "\n",
      "on the christmas,man a winter wonderland\n",
      "\n",
      "they don't mind a mer\n",
      "Minibatch: 100, Train Loss: 1.6263848876953124, Train Evaluation Criterion: 0.52\n",
      "Epoch 0, 2.950723 % done\n",
      "Minibatch: 200, Train Loss: 1.4984957885742187, Train Evaluation Criterion: 0.51\n",
      "Epoch 0, 5.901446 % done\n",
      "Minibatch: 300, Train Loss: 1.8610289001464844, Train Evaluation Criterion: 0.57\n",
      "Epoch 0, 8.852169 % done\n",
      "Minibatch: 400, Train Loss: 1.4035107421875, Train Evaluation Criterion: 0.46\n",
      "Epoch 0, 11.802892 % done\n",
      "Minibatch: 500, Train Loss: 1.3353038024902344, Train Evaluation Criterion: 0.38\n",
      "Epoch 0, 14.753615 % done\n",
      "Minibatch: 600, Train Loss: 1.3170062255859376, Train Evaluation Criterion: 0.39\n",
      "Epoch 0, 17.704338 % done\n",
      "Minibatch: 700, Train Loss: 1.2261805725097656, Train Evaluation Criterion: 0.4\n",
      "Epoch 0, 20.655060 % done\n",
      "Minibatch: 800, Train Loss: 1.588251953125, Train Evaluation Criterion: 0.5\n",
      "Epoch 0, 23.605783 % done\n",
      "Minibatch: 900, Train Loss: 2.0086070251464845, Train Evaluation Criterion: 0.59\n",
      "Epoch 0, 26.556506 % done\n",
      "Minibatch: 1000, Train Loss: 1.2629098510742187, Train Evaluation Criterion: 0.4\n",
      "Epoch 0, 29.507229 % done\n",
      "§one,\" said scrooge.\n",
      "\n",
      "\"but it was not and going up to callers of a pottication,\"\n",
      "\n",
      "\"you were ungreethought, where vanished sports so time had to be sinments who broken the shadowy offices from the avilegn, selfers of cosclyment, and ensoral there all the doors in sode so-wadle of the chimdless of thei\n",
      "Minibatch: 1100, Train Loss: 1.1622628784179687, Train Evaluation Criterion: 0.37\n",
      "Epoch 0, 32.457952 % done\n",
      "Minibatch: 1200, Train Loss: 1.5072979736328125, Train Evaluation Criterion: 0.47\n",
      "Epoch 0, 35.408675 % done\n",
      "Minibatch: 1300, Train Loss: 1.2492245483398436, Train Evaluation Criterion: 0.34\n",
      "Epoch 0, 38.359398 % done\n",
      "Minibatch: 1400, Train Loss: 1.3717037963867187, Train Evaluation Criterion: 0.41\n",
      "Epoch 0, 41.310121 % done\n",
      "Minibatch: 1500, Train Loss: 1.467796630859375, Train Evaluation Criterion: 0.46\n",
      "Epoch 0, 44.260844 % done\n",
      "Minibatch: 1600, Train Loss: 1.2858854675292968, Train Evaluation Criterion: 0.4\n",
      "Epoch 0, 47.211567 % done\n",
      "Minibatch: 1700, Train Loss: 1.2356813049316406, Train Evaluation Criterion: 0.39\n",
      "Epoch 0, 50.162290 % done\n",
      "Minibatch: 1800, Train Loss: 1.4725296020507812, Train Evaluation Criterion: 0.45\n",
      "Epoch 0, 53.113013 % done\n",
      "Minibatch: 1900, Train Loss: 1.370274200439453, Train Evaluation Criterion: 0.45\n",
      "Epoch 0, 56.063736 % done\n",
      "Minibatch: 2000, Train Loss: 1.4036312866210938, Train Evaluation Criterion: 0.42\n",
      "Epoch 0, 59.014459 % done\n",
      "§ond upon it.\n",
      "\n",
      "\"yes, unto his cattle aad even. you may solve?\"\n",
      "\n",
      "\"very steavy one in hatly.\"\n",
      "\n",
      "\"you?\"\n",
      "\n",
      "\"i she may be marned adorentmscunace with the open and sowing on his face was well, my come, holmes,\" said id and laughy. i can not extenment, and knowed your. guard?\"\n",
      "\n",
      "\"here and your. a goose i ready\n",
      "Minibatch: 2100, Train Loss: 1.2980995178222656, Train Evaluation Criterion: 0.39\n",
      "Epoch 0, 61.965181 % done\n",
      "Minibatch: 2200, Train Loss: 1.1839012908935547, Train Evaluation Criterion: 0.39\n",
      "Epoch 0, 64.915904 % done\n",
      "Minibatch: 2300, Train Loss: 1.1749591064453124, Train Evaluation Criterion: 0.36\n",
      "Epoch 0, 67.866627 % done\n",
      "Minibatch: 2400, Train Loss: 1.6189332580566407, Train Evaluation Criterion: 0.49\n",
      "Epoch 0, 70.817350 % done\n",
      "Minibatch: 2500, Train Loss: 1.2116075134277344, Train Evaluation Criterion: 0.41\n",
      "Epoch 0, 73.768073 % done\n",
      "Minibatch: 2600, Train Loss: 1.2181621551513673, Train Evaluation Criterion: 0.36\n",
      "Epoch 0, 76.718796 % done\n",
      "Minibatch: 2700, Train Loss: 1.5354121398925782, Train Evaluation Criterion: 0.46\n",
      "Epoch 0, 79.669519 % done\n",
      "Minibatch: 2800, Train Loss: 1.6124272155761719, Train Evaluation Criterion: 0.53\n",
      "Epoch 0, 82.620242 % done\n",
      "Minibatch: 2900, Train Loss: 1.1303350830078125, Train Evaluation Criterion: 0.33\n",
      "Epoch 0, 85.570965 % done\n",
      "Minibatch: 3000, Train Loss: 1.3046719360351562, Train Evaluation Criterion: 0.38\n",
      "Epoch 0, 88.521688 % done\n",
      "§one deepasked and coarsse out for heep through himself, \"a fires for rong of covering of a rower into the palaring faled yaten with the yourself.\n",
      "\n",
      "we reading up against the merry wulting of a princes remines, the nearing is. but the moment me how the huted returned to clu' that this your morragges w\n",
      "Minibatch: 3100, Train Loss: 1.4694821166992187, Train Evaluation Criterion: 0.4\n",
      "Epoch 0, 91.472411 % done\n",
      "Minibatch: 3200, Train Loss: 1.4795281982421875, Train Evaluation Criterion: 0.46\n",
      "Epoch 0, 94.423134 % done\n",
      "Minibatch: 3300, Train Loss: 1.6484425354003907, Train Evaluation Criterion: 0.47\n",
      "Epoch 0, 97.373857 % done\n",
      "Saved model to 'models/deepjingling-songwriter4_epoch28.dnn'\n",
      "data has 30690 characters, 54 unique.\n",
      "Minibatch: 0, Train Loss: 1.3136026000976562, Train Evaluation Criterion: 0.43\n",
      "Epoch 0, 0.000000 % done\n",
      "§one, him. he had destable a people thoughts to himself and not leps came one from a dreams, and yet leavent in his silent saw holmes. it came time to leave me called some sheep. he was feet, and yet along the grand-of hus of shall jear, travelers in the weary hands of hofving that mean together, but\n",
      "Minibatch: 100, Train Loss: 0.9656892395019532, Train Evaluation Criterion: 0.26\n",
      "Epoch 0, 32.679739 % done\n",
      "Minibatch: 200, Train Loss: 0.4991630554199219, Train Evaluation Criterion: 0.16\n",
      "Epoch 0, 65.359477 % done\n",
      "Minibatch: 300, Train Loss: 1.0411491394042969, Train Evaluation Criterion: 0.33\n",
      "Epoch 0, 98.039216 % done\n",
      "data has 30690 characters, 54 unique.\n",
      "Minibatch: 0, Train Loss: 1.2706509399414063, Train Evaluation Criterion: 0.38\n",
      "Epoch 0, 0.000000 % done\n",
      "§one far what fun it is to silver bells fiftchess\n",
      "and in a leaves sing at merry and snow; lully, lullay, good and sytary winding\n",
      "3 water and bright!\n",
      "a jolly christmas\n",
      "my true love sent to me:\n",
      "10 swopen wise men\n",
      "a swans rob sing\n",
      "soon it is the grands,\n",
      "and saw yearing birds\n",
      "3 french hens\n",
      "2 turtle doves\n",
      "Minibatch: 100, Train Loss: 0.7929370880126954, Train Evaluation Criterion: 0.27\n",
      "Epoch 0, 32.679739 % done\n",
      "Minibatch: 200, Train Loss: 0.3417966079711914, Train Evaluation Criterion: 0.11\n",
      "Epoch 0, 65.359477 % done\n",
      "Minibatch: 300, Train Loss: 0.867476806640625, Train Evaluation Criterion: 0.3\n",
      "Epoch 0, 98.039216 % done\n",
      "data has 30690 characters, 54 unique.\n",
      "Minibatch: 0, Train Loss: 1.1979338073730468, Train Evaluation Criterion: 0.38\n",
      "Epoch 0, 0.000000 % done\n",
      "§one leaves a laying\n",
      "5 geese a laying\n",
      "5 golden rings\n",
      "4 calling birds\n",
      "3 french hens\n",
      "2 turtle doves\n",
      "and a partridge in a pear tree\n",
      "\n",
      "on the single party down s\n",
      "for everyone's naleman\n",
      "at dance of the sea\n",
      "\n",
      "it's christmas tree,\n",
      "how are nyt at the green\n",
      "and in the awaking\n",
      "i don't know.\n",
      "\n",
      "that's christmas\n",
      "i w\n",
      "Minibatch: 100, Train Loss: 0.7698116302490234, Train Evaluation Criterion: 0.25\n",
      "Epoch 0, 32.679739 % done\n",
      "Minibatch: 200, Train Loss: 0.26126655578613284, Train Evaluation Criterion: 0.1\n",
      "Epoch 0, 65.359477 % done\n",
      "Minibatch: 300, Train Loss: 0.7762505340576172, Train Evaluation Criterion: 0.23\n",
      "Epoch 0, 98.039216 % done\n"
     ]
    }
   ],
   "source": [
    "train_multitask_lm(\"data/stories.txt\", \"data/songs.txt\", \n",
    "                   \"models/deepjingling-storyteller4_epoch%d.dnn\", \n",
    "                   \"models/deepjingling-songwriter4_epoch%d.dnn\", \n",
    "                   nb_epochs=10, nb_epochs_second=22, alternate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_lm(\"data/stories.txt\", \"models/deepjingling-storyteller4_epoch%d.dnn\", nb_epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|reindeers, and the doors in the dalle the corner-inneathers, one paid hes of the trees, and had ever got into the bounts, and one with this like meant of inamination of chalment. he had in the whire a\n"
     ]
    }
   ],
   "source": [
    "text = \"|reindeer\"\n",
    "load_and_sample(\"models/deepjingling-songwriter4_epoch28.dnn\", \"data/songs.txt.vocab\", \n",
    "                prime_text=text, use_hardmax=False, length=200, temperature=1.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
