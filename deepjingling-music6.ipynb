{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# With mask\n",
    "# single line input\n",
    "# and \"good music files\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from music21 import *\n",
    "import numpy as np\n",
    "import glob\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "from cntk import Trainer, Axis\n",
    "from cntk.learner import adam_sgd, momentum_sgd, momentum_as_time_constant_schedule, learning_rate_schedule, UnitType\n",
    "from cntk.ops import input_variable, classification_error, squared_error\n",
    "from cntk.persist import load_model, save_model\n",
    "from cntk.blocks import LSTM, Stabilizer\n",
    "from cntk.layers import Recurrence, Dense, Dropout, BatchNormalization\n",
    "from cntk.utils import get_train_eval_criterion, get_train_loss\n",
    "from cntk.device import set_default_device, gpu\n",
    "\n",
    "path = \"PianoMidiFiles\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lowerBound = 24 # = [python] index 0 ([R] 1. possision)\n",
    "upperBound = 102 # = first index out of bound => len =78\n",
    "nNotes = upperBound-lowerBound\n",
    "notesDim = nNotes*2\n",
    "hidden_dim = 512#256#nNotes\n",
    "num_layers = 3\n",
    "\n",
    "\n",
    "batch_len = 16*8 # length of each sequence\n",
    "\n",
    "def loadPieces(midiFiles):\n",
    "    pieces = {}\n",
    "    totalLength= len(midiFiles)\n",
    "    fnameNumber=0\n",
    "    for fname in midiFiles:\n",
    "        fnameNumber+=1\n",
    "        if fname[-4:] not in ('.mid','.MID'):\n",
    "            continue\n",
    "        isNotBackSlash=1\n",
    "        bIndex=0\n",
    "        while(isNotBackSlash):\n",
    "            bIndex-=1\n",
    "            if fname[bIndex]=='\\\\':\n",
    "                bIndex+=1\n",
    "                isNotBackSlash=False\n",
    "        name = fname[bIndex:-4]\n",
    "        print(\"Loading\",name,\"...\",fnameNumber,'/',totalLength)\n",
    "        outMatrix = midi2MusicMinMatrix(fname)\n",
    "        if len(outMatrix) < batch_len:\n",
    "            print(\"     Loaded\", name,'failed')\n",
    "            continue\n",
    "        else:\n",
    "            print(\"     Loaded\", name,'done')\n",
    "        pieces[name] = outMatrix\n",
    "    return(pieces)\n",
    "\n",
    "\n",
    "\n",
    "def midi2MusicMinMatrix(parseLink):\n",
    "    midiFile = converter.parse(parseLink)\n",
    "    #if (midiFile.flat.getTimeSignatures().timeSignature.numerator not in (2,4)) or (midiFile.flat.getTimeSignatures().timeSignature.denominator not in (2,4)):\n",
    "    #\tprint('     Track: is not 4/4 or similar')\n",
    "    #\treturn(0)\t\n",
    "    if (midiFile.flat.getTimeSignatures().timeSignature.numerator not in (2,4)) or (midiFile.flat.getTimeSignatures().timeSignature.denominator not in (2,4)):\n",
    "        print('     Track: is not 4/4')\n",
    "        printing = '     Track is '+str(midiFile.flat.getTimeSignatures().timeSignature.numerator)+' / ' + str(midiFile.flat.getTimeSignatures().timeSignature.denominator)\n",
    "        print(printing)\n",
    "        return(0)\t\n",
    "    midiPartLen=len(midiFile)\n",
    "    maxTime = midiFile.highestTime\n",
    "    outMatrix = [[[0,0] for tang in range(upperBound-lowerBound)]+[[lenTimes16/4]] for lenTimes16 in range(math.ceil(maxTime*4+2))]\n",
    "    # outMatrix = [[[0,0] for tang in range(upperBound-lowerBound)]+[lenTimes16/4] for lenTimes16 in range(math.ceil(maxTime*4+2))]\n",
    "    for t in range(midiPartLen):\n",
    "        try:\n",
    "            instrument=midiFile[t].getInstrument(returnDefault=False).instrumentName\n",
    "        except: \n",
    "            instrument='Piano'\n",
    "        #if not instrument:\n",
    "        #\tinstrument='Piano'\n",
    "        #if instrument!='Piano':\n",
    "        #\tprint('          Part',t,'/',midiPartLen-1,' dropped, instrument was not piano')\n",
    "        #\tcontinue\t\t\t\n",
    "        notes=midiFile[t].flat.notes\n",
    "        for i in range(0,len(notes)):\n",
    "            if not notes[i].isChord:\n",
    "                if (notes[i].pitch.midi<lowerBound) or (notes[i].pitch.midi>=upperBound):\n",
    "                    continue\n",
    "                timeIndex=round(notes[i].offset*4)+1\n",
    "                notePitch=notes[i].pitch.midi-lowerBound\n",
    "                outMatrix[timeIndex][notePitch]=[1,1]\n",
    "                for holdLen in range(1,round(notes[i].duration.quarterLength*4)):\n",
    "                    outMatrix[timeIndex+holdLen][notePitch][1]=1\n",
    "            else:\n",
    "                timeIndex=round(notes[i].offset*4)+1\n",
    "                duration=round(notes[i].duration.quarterLength*4)+1\n",
    "                for j in range(len(notes[i])):\n",
    "                    if (notes[i][j].pitch.midi<lowerBound) or (notes[i][j].pitch.midi>=upperBound):\n",
    "                        continue\n",
    "                    #timeIndex=round(notes[i][j].offset*4)+1\n",
    "                    notePitch=notes[i][j].pitch.midi-lowerBound\n",
    "                    outMatrix[timeIndex][notePitch]=[1,1]\n",
    "                    for holdLen in range(1,duration):\n",
    "                        outMatrix[timeIndex+holdLen][notePitch][1]=1\t\n",
    "    return(outMatrix)\n",
    "\n",
    "def MusicMinMatrix2midi(MusicMinMatrixPart,S,bpm=100):\n",
    "    #S = stream.Score()\n",
    "    nTime=len(MusicMinMatrixPart)\n",
    "    S.insert(0,tempo.MetronomeMark(number=bpm))\n",
    "    p1 = stream.Part()\n",
    "    p1.id = 'part1'\n",
    "    nCons=0\n",
    "    thisIndex=0\n",
    "    mLen = len(MusicMinMatrixPart[0])\n",
    "    for j in range(mLen-1):\n",
    "        for i in range(nTime):\n",
    "            if (nCons!=0) and (MusicMinMatrixPart[i][j] in ([0,0],[1,1])):\n",
    "                n.duration.quarterLength = 0.25*nCons\n",
    "                p1.insert(MusicMinMatrixPart[thisIndex][mLen-1][0],n)\n",
    "                nCons=0\n",
    "            if MusicMinMatrixPart[i][j]==[1,1]:\n",
    "                n = note.Note()\n",
    "                n.midi = lowerBound+j\n",
    "                thisIndex = i\n",
    "                nCons+=1\n",
    "            elif (MusicMinMatrixPart[i][j]==[0,1]) and (nCons!=0):\n",
    "                nCons+=1\n",
    "        if (nCons != 0):\n",
    "            n.duration.quarterLength = 0.25*nCons\n",
    "            p1.insert(MusicMinMatrixPart[thisIndex][mLen-1][0],n)\n",
    "            nCons=0\n",
    "    S.insert(0,p1)\n",
    "    \n",
    "    \n",
    "def Piece2Data(Pieces):\n",
    "    tempData = sum(list(Pieces.values()),[])\n",
    "    data=[sum(timePart,[]) for timePart in tempData]\n",
    "    return(np.array(data,dtype=np.float32))\n",
    "    \n",
    "\n",
    "def get_data(p, minibatch_size, data):\n",
    "    x = data[p:p+minibatch_size,0:156]\n",
    "    y = data[p+1:p+minibatch_size+1,0:156]\n",
    "    #xsum=x.sum(axis=1, keepdims=True)\n",
    "    return([x],[y])\n",
    "\n",
    "def data2MusicMatric(data):\n",
    "    timeIndex=0\n",
    "    MusicMatrix=[0]*len(data)\n",
    "    MusicMatrixRow=[0]*(upperBound-lowerBound)\n",
    "    for i in range(len(data)):\n",
    "        for j in range(upperBound-lowerBound):\n",
    "            MusicMatrixRow[j] = [int(data[i,j*2]),int(data[i,j*2+1])]\n",
    "        MusicMatrix[i] = MusicMatrixRow+[[timeIndex]]\n",
    "        timeIndex+=0.25\n",
    "    return(MusicMatrix)\n",
    "\n",
    "\n",
    "\n",
    "def Output2data(p):\n",
    "    p=p[0][0]\n",
    "    return((p>np.random.random_sample((1, len(p))))*1)\n",
    "    # return(list((p>p.mean()+threshold)*1))\n",
    "\n",
    "# prime_data=data[5:20,:]\n",
    "def sample(z,prime_data=np.array([[0]*((upperBound-lowerBound)*2)],dtype=np.float32),length=300):#,threshold=1.11):\n",
    "    output=np.zeros((length, 156), dtype=np.float32)\n",
    "    if len(prime_data[0])!=156:\n",
    "        prime_data[:,0:156]\n",
    "    randomNumb=np.random.choice(range(78))\n",
    "    if len(prime_data)==1: \n",
    "        prime_data[0,randomNumb*2] = 1\n",
    "        prime_data[0,randomNumb*2+1] = 1\n",
    "    for i in range(len(prime_data)):\n",
    "        x=prime_data[i]\n",
    "        inputen=[np.array([x],dtype=np.float32)]\n",
    "        # inputen=[np.array([data],dtype=np.float32)]\n",
    "        # inputen=[np.array([x/np.maximum(x.sum(),1)],dtype=np.float32)]\n",
    "        if i==0:\n",
    "            arguments=(inputen,[True])\n",
    "        else:\n",
    "            p = z.eval(arguments)\n",
    "            arguments=(inputen,[False])\n",
    "        \n",
    "        \n",
    "    #x=prime_data[len(prime_data)-1]\n",
    "    for i in range(length):\n",
    "        p = z.eval(arguments)        \n",
    "        output[i,:]=Output2data(p)# ,threshold=threshold)\n",
    "        x=output[i,:]\n",
    "        inputen=[np.array([x],dtype=np.float32)]\n",
    "        # inputen=[np.array([x/np.maximum(x.sum(),1)],dtype=np.float32)]\n",
    "        arguments=(inputen,[False])\n",
    "    return(output)#return([list(testout[i]) for i in range(300)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading deck-the-halls ... 1 / 8\n",
      "     Loaded deck-the-halls done\n",
      "Loading ding-dong-merrily-on-high ... 2 / 8\n",
      "     Loaded ding-dong-merrily-on-high done\n",
      "Loading gaudete-rejoice ... 3 / 8\n",
      "     Loaded gaudete-rejoice done\n",
      "Loading Go_tell ... 4 / 8\n",
      "     Loaded Go_tell done\n",
      "Loading hark-the-herald-angels-sing ... 5 / 8\n",
      "     Loaded hark-the-herald-angels-sing done\n",
      "Loading il-est-ne-le-divin-enfant-keyboard ... 6 / 8\n",
      "     Loaded il-est-ne-le-divin-enfant-keyboard done\n",
      "Loading jingbellPiano ... 7 / 8\n",
      "     Loaded jingbellPiano done\n",
      "Loading the-huron-carol-piano ... 8 / 8\n",
      "     Loaded the-huron-carol-piano done\n"
     ]
    }
   ],
   "source": [
    "midiFiles = glob.glob(path + '/*.mid')\n",
    "Pieces = loadPieces(midiFiles)\n",
    "# data = Piece2Data(Pieces)\n",
    "# data=np.load('dataNpArray.npy')\n",
    "# ArrPieces = np.load('ArrPieces.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "songs=list(Pieces.keys())\n",
    "ArrPieces= {}\n",
    "for i in range(len(songs)):\n",
    "    BrakComb=[sum(timePart,[]) for timePart in Pieces[songs[i]]]\n",
    "    ArrPieces[songs[i]] =np.array(BrakComb,dtype=np.float32)\n",
    "# ArrPieces = np.load('ArrPieces.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.array(ArrPieces[songs[1]][2:3],dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ArrPieces[songs[1]][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train_mm(Pieces,songs):\n",
    "    #songs=list(Pieces.keys())\n",
    "    # create the stabilizer function from blocks\n",
    "    stabilize = Stabilizer()\n",
    "    #data = Piece2Data(Pieces)\n",
    "    #data_size=len(data)\n",
    "\n",
    "    # Source and target inputs to the model\n",
    "    batch_axis = Axis.default_batch_axis()\n",
    "    input_seq_axis = Axis('inputAxis')\n",
    "\n",
    "    input_dynamic_axes = [batch_axis, input_seq_axis]\n",
    "    raw_input = input_variable(shape=(notesDim), dynamic_axes=input_dynamic_axes)\n",
    "    raw_labels = input_variable(shape=(notesDim), dynamic_axes=input_dynamic_axes)\n",
    "\n",
    "    input_sequence = raw_input\n",
    "    label_sequence = raw_labels\n",
    "\n",
    "    # LSTM\n",
    "    encoder_output = stabilize(input_sequence)\n",
    "    for i in range(0, num_layers):\n",
    "        encoder_output = Recurrence(LSTM(hidden_dim, enable_self_stabilization=True)) (encoder_output.output)\n",
    "        #encoder_output = BatchNormalization() (encoder_output.output)\n",
    "        # encoder_output = Dropout(0.05) (encoder_output.output)\n",
    "\n",
    "    # get output of the LSTM\n",
    "    states = encoder_output.output\n",
    "\n",
    "    # dense layer    \n",
    "    z = Dense(notesDim)(Dense(notesDim)(Dense(notesDim) (states)))\n",
    "    \n",
    "    import cntk.ops \n",
    "    # ce = binary_cross_entropy(z, label_sequence)\n",
    "    # ce = cntk.ops.squared_error(z,label_sequence)\n",
    "    # ce = times_transpose(label_sequence,log(z)) \n",
    "    # ce = cross_entropy_with_softmax(z, label_sequence)\n",
    "    # ce = times_transpose(label_sequence,log(z))\n",
    "    ce = squared_error(z,label_sequence)\n",
    "    # errs = squared_error(z,label_sequence)\n",
    "    errs = squared_error(z,label_sequence)#*len(label_sequence)\n",
    "    #errs = classification_error(z, label_sequence)\n",
    "\n",
    "    # Instantiate the trainer object to drive the model training\n",
    "    lr_per_sample = learning_rate_schedule(0.0005, UnitType.sample)\n",
    "    momentum_time_constant = momentum_as_time_constant_schedule(1100)\n",
    "    clipping_threshold_per_sample = 5.0\n",
    "    gradient_clipping_with_truncation = True\n",
    "    learner = adam_sgd(z.parameters, lr_per_sample, momentum_time_constant, \n",
    "                           gradient_clipping_threshold_per_sample=clipping_threshold_per_sample,\n",
    "                           gradient_clipping_with_truncation=gradient_clipping_with_truncation)\n",
    "    trainer = Trainer(z, ce, errs, learner)\n",
    "    \n",
    "    minibatch_size = 256 \n",
    "    loopsPrPrint = 5\n",
    "    #training_progress_output_freq = 100\n",
    "    #sample_freq = 20\n",
    "    epochs = 100\n",
    "    #minibatches_per_epoch = int((data_size / minibatch_size))\n",
    "    #minibatches = epochs * minibatches_per_epoch\n",
    "    \n",
    "    e = 0\n",
    "    p = 0\n",
    "    #pnew = 0\n",
    "    \n",
    "    iSong=[iSong for iSong in range(len(songs))]\n",
    "    songEnd=False\n",
    "    songLen=0\n",
    "    printCounter=0\n",
    "    for i in range(epochs):\n",
    "        e += 1\n",
    "        print('---------------------------------------------------------------')\n",
    "        print(str(e)+'/'+str(epochs))\n",
    "        shouldPrint=True\n",
    "        random.shuffle(iSong)\n",
    "        for j in iSong:\n",
    "            # print('Song nr ='+str(j))\n",
    "            p = 0\n",
    "            #pnew = 0\n",
    "            jSong=Pieces[songs[j]]\n",
    "            songLen=len(jSong)\n",
    "            while not songEnd:\n",
    "                # get the data            \n",
    "                features, labels = get_data(p, minibatch_size, jSong)\n",
    "                #print('P = '+str(p))\n",
    "                #print('Seng Length = '+str(songLen))\n",
    "                # Specify the mapping of input variables in the model to actual minibatch data to be trained with\n",
    "                # If it's the start of the data, we specify that we are looking at a new sequence (True)\n",
    "                mask = [False] \n",
    "                if p == 0:\n",
    "                    mask = [True]\n",
    "                #print('Mask = '+str(mask))\n",
    "                arguments = ({raw_input : features, raw_labels : labels}, mask)\n",
    "                trainer.train_minibatch(arguments)\n",
    "                p=p+minibatch_size\n",
    "                if songLen<=(p+minibatch_size+1):\n",
    "                    songEnd=True\n",
    "                if shouldPrint==True: # or printCounter%loopsPrPrint==0:\n",
    "                    print(\"Minibatch: {}, Train Loss: {}, Train Evaluation Criterion: {}\".format(i,\n",
    "                        get_train_loss(trainer), get_train_eval_criterion(trainer)))\n",
    "                    shouldPrint=False\n",
    "                printCounter+=1\n",
    "            songEnd=False\n",
    "    return(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------\n",
      "1/100\n",
      "Minibatch: 0, Train Loss: 4.482102870941162, Train Evaluation Criterion: 4.482102870941162\n",
      "---------------------------------------------------------------\n",
      "2/100\n",
      "Minibatch: 1, Train Loss: 2.830907106399536, Train Evaluation Criterion: 2.830907106399536\n",
      "---------------------------------------------------------------\n",
      "3/100\n",
      "Minibatch: 2, Train Loss: 5.113320350646973, Train Evaluation Criterion: 5.113320350646973\n",
      "---------------------------------------------------------------\n",
      "4/100\n",
      "Minibatch: 3, Train Loss: 2.480931520462036, Train Evaluation Criterion: 2.480931520462036\n",
      "---------------------------------------------------------------\n",
      "5/100\n",
      "Minibatch: 4, Train Loss: 2.6893043518066406, Train Evaluation Criterion: 2.6893043518066406\n",
      "---------------------------------------------------------------\n",
      "6/100\n",
      "Minibatch: 5, Train Loss: 4.7739481925964355, Train Evaluation Criterion: 4.7739481925964355\n",
      "---------------------------------------------------------------\n",
      "7/100\n",
      "Minibatch: 6, Train Loss: 3.5784752368927, Train Evaluation Criterion: 3.5784752368927\n",
      "---------------------------------------------------------------\n",
      "8/100\n",
      "Minibatch: 7, Train Loss: 3.082529306411743, Train Evaluation Criterion: 3.082529306411743\n",
      "---------------------------------------------------------------\n",
      "9/100\n",
      "Minibatch: 8, Train Loss: 3.496845245361328, Train Evaluation Criterion: 3.496845245361328\n",
      "---------------------------------------------------------------\n",
      "10/100\n",
      "Minibatch: 9, Train Loss: 2.682400941848755, Train Evaluation Criterion: 2.682400941848755\n",
      "---------------------------------------------------------------\n",
      "11/100\n",
      "Minibatch: 10, Train Loss: 3.773263454437256, Train Evaluation Criterion: 3.773263454437256\n",
      "---------------------------------------------------------------\n",
      "12/100\n",
      "Minibatch: 11, Train Loss: 2.664577007293701, Train Evaluation Criterion: 2.664577007293701\n",
      "---------------------------------------------------------------\n",
      "13/100\n",
      "Minibatch: 12, Train Loss: 3.982283592224121, Train Evaluation Criterion: 3.982283592224121\n",
      "---------------------------------------------------------------\n",
      "14/100\n",
      "Minibatch: 13, Train Loss: 2.515211820602417, Train Evaluation Criterion: 2.515211820602417\n",
      "---------------------------------------------------------------\n",
      "15/100\n",
      "Minibatch: 14, Train Loss: 2.874396324157715, Train Evaluation Criterion: 2.874396324157715\n",
      "---------------------------------------------------------------\n",
      "16/100\n",
      "Minibatch: 15, Train Loss: 3.4066433906555176, Train Evaluation Criterion: 3.4066433906555176\n",
      "---------------------------------------------------------------\n",
      "17/100\n",
      "Minibatch: 16, Train Loss: 3.4315974712371826, Train Evaluation Criterion: 3.4315974712371826\n",
      "---------------------------------------------------------------\n",
      "18/100\n",
      "Minibatch: 17, Train Loss: 3.2921454906463623, Train Evaluation Criterion: 3.2921454906463623\n",
      "---------------------------------------------------------------\n",
      "19/100\n",
      "Minibatch: 18, Train Loss: 2.4363977909088135, Train Evaluation Criterion: 2.4363977909088135\n",
      "---------------------------------------------------------------\n",
      "20/100\n",
      "Minibatch: 19, Train Loss: 2.853663206100464, Train Evaluation Criterion: 2.853663206100464\n",
      "---------------------------------------------------------------\n",
      "21/100\n",
      "Minibatch: 20, Train Loss: 2.5802745819091797, Train Evaluation Criterion: 2.5802745819091797\n",
      "---------------------------------------------------------------\n",
      "22/100\n",
      "Minibatch: 21, Train Loss: 2.6218156814575195, Train Evaluation Criterion: 2.6218156814575195\n",
      "---------------------------------------------------------------\n",
      "23/100\n",
      "Minibatch: 22, Train Loss: 2.68377423286438, Train Evaluation Criterion: 2.68377423286438\n",
      "---------------------------------------------------------------\n",
      "24/100\n",
      "Minibatch: 23, Train Loss: 2.328989028930664, Train Evaluation Criterion: 2.328989028930664\n",
      "---------------------------------------------------------------\n",
      "25/100\n",
      "Minibatch: 24, Train Loss: 2.5146260261535645, Train Evaluation Criterion: 2.5146260261535645\n",
      "---------------------------------------------------------------\n",
      "26/100\n",
      "Minibatch: 25, Train Loss: 3.4562692642211914, Train Evaluation Criterion: 3.4562692642211914\n",
      "---------------------------------------------------------------\n",
      "27/100\n",
      "Minibatch: 26, Train Loss: 1.8120496273040771, Train Evaluation Criterion: 1.8120496273040771\n",
      "---------------------------------------------------------------\n",
      "28/100\n",
      "Minibatch: 27, Train Loss: 3.136763095855713, Train Evaluation Criterion: 3.136763095855713\n",
      "---------------------------------------------------------------\n",
      "29/100\n",
      "Minibatch: 28, Train Loss: 2.7895522117614746, Train Evaluation Criterion: 2.7895522117614746\n",
      "---------------------------------------------------------------\n",
      "30/100\n",
      "Minibatch: 29, Train Loss: 1.744690179824829, Train Evaluation Criterion: 1.744690179824829\n",
      "---------------------------------------------------------------\n",
      "31/100\n",
      "Minibatch: 30, Train Loss: 2.850893497467041, Train Evaluation Criterion: 2.850893497467041\n",
      "---------------------------------------------------------------\n",
      "32/100\n",
      "Minibatch: 31, Train Loss: 1.6001533269882202, Train Evaluation Criterion: 1.6001533269882202\n",
      "---------------------------------------------------------------\n",
      "33/100\n",
      "Minibatch: 32, Train Loss: 2.232757091522217, Train Evaluation Criterion: 2.232757091522217\n",
      "---------------------------------------------------------------\n",
      "34/100\n",
      "Minibatch: 33, Train Loss: 2.012174606323242, Train Evaluation Criterion: 2.012174606323242\n",
      "---------------------------------------------------------------\n",
      "35/100\n",
      "Minibatch: 34, Train Loss: 2.5607473850250244, Train Evaluation Criterion: 2.5607473850250244\n",
      "---------------------------------------------------------------\n",
      "36/100\n",
      "Minibatch: 35, Train Loss: 2.7124240398406982, Train Evaluation Criterion: 2.7124240398406982\n",
      "---------------------------------------------------------------\n",
      "37/100\n",
      "Minibatch: 36, Train Loss: 1.842219352722168, Train Evaluation Criterion: 1.842219352722168\n",
      "---------------------------------------------------------------\n",
      "38/100\n",
      "Minibatch: 37, Train Loss: 2.39526104927063, Train Evaluation Criterion: 2.39526104927063\n",
      "---------------------------------------------------------------\n",
      "39/100\n",
      "Minibatch: 38, Train Loss: 2.5417816638946533, Train Evaluation Criterion: 2.5417816638946533\n",
      "---------------------------------------------------------------\n",
      "40/100\n",
      "Minibatch: 39, Train Loss: 1.9082705974578857, Train Evaluation Criterion: 1.9082705974578857\n",
      "---------------------------------------------------------------\n",
      "41/100\n",
      "Minibatch: 40, Train Loss: 1.4141439199447632, Train Evaluation Criterion: 1.4141439199447632\n",
      "---------------------------------------------------------------\n",
      "42/100\n",
      "Minibatch: 41, Train Loss: 2.4187655448913574, Train Evaluation Criterion: 2.4187655448913574\n",
      "---------------------------------------------------------------\n",
      "43/100\n",
      "Minibatch: 42, Train Loss: 2.2964611053466797, Train Evaluation Criterion: 2.2964611053466797\n",
      "---------------------------------------------------------------\n",
      "44/100\n",
      "Minibatch: 43, Train Loss: 1.5725079774856567, Train Evaluation Criterion: 1.5725079774856567\n",
      "---------------------------------------------------------------\n",
      "45/100\n",
      "Minibatch: 44, Train Loss: 2.114727020263672, Train Evaluation Criterion: 2.114727020263672\n",
      "---------------------------------------------------------------\n",
      "46/100\n",
      "Minibatch: 45, Train Loss: 1.4662374258041382, Train Evaluation Criterion: 1.4662374258041382\n",
      "---------------------------------------------------------------\n",
      "47/100\n",
      "Minibatch: 46, Train Loss: 2.180251121520996, Train Evaluation Criterion: 2.180251121520996\n",
      "---------------------------------------------------------------\n",
      "48/100\n",
      "Minibatch: 47, Train Loss: 1.9498053789138794, Train Evaluation Criterion: 1.9498053789138794\n",
      "---------------------------------------------------------------\n",
      "49/100\n",
      "Minibatch: 48, Train Loss: 2.2845194339752197, Train Evaluation Criterion: 2.2845194339752197\n",
      "---------------------------------------------------------------\n",
      "50/100\n",
      "Minibatch: 49, Train Loss: 2.091548204421997, Train Evaluation Criterion: 2.091548204421997\n",
      "---------------------------------------------------------------\n",
      "51/100\n",
      "Minibatch: 50, Train Loss: 2.023040533065796, Train Evaluation Criterion: 2.023040533065796\n",
      "---------------------------------------------------------------\n",
      "52/100\n",
      "Minibatch: 51, Train Loss: 2.5942134857177734, Train Evaluation Criterion: 2.5942134857177734\n",
      "---------------------------------------------------------------\n",
      "53/100\n",
      "Minibatch: 52, Train Loss: 2.1865570545196533, Train Evaluation Criterion: 2.1865570545196533\n",
      "---------------------------------------------------------------\n",
      "54/100\n",
      "Minibatch: 53, Train Loss: 1.7468205690383911, Train Evaluation Criterion: 1.7468205690383911\n",
      "---------------------------------------------------------------\n",
      "55/100\n",
      "Minibatch: 54, Train Loss: 2.1503982543945312, Train Evaluation Criterion: 2.1503982543945312\n",
      "---------------------------------------------------------------\n",
      "56/100\n",
      "Minibatch: 55, Train Loss: 1.7169952392578125, Train Evaluation Criterion: 1.7169952392578125\n",
      "---------------------------------------------------------------\n",
      "57/100\n",
      "Minibatch: 56, Train Loss: 1.7871038913726807, Train Evaluation Criterion: 1.7871038913726807\n",
      "---------------------------------------------------------------\n",
      "58/100\n",
      "Minibatch: 57, Train Loss: 2.0005030632019043, Train Evaluation Criterion: 2.0005030632019043\n",
      "---------------------------------------------------------------\n",
      "59/100\n",
      "Minibatch: 58, Train Loss: 1.7809393405914307, Train Evaluation Criterion: 1.7809393405914307\n",
      "---------------------------------------------------------------\n",
      "60/100\n",
      "Minibatch: 59, Train Loss: 2.064626932144165, Train Evaluation Criterion: 2.064626932144165\n",
      "---------------------------------------------------------------\n",
      "61/100\n",
      "Minibatch: 60, Train Loss: 1.8876924514770508, Train Evaluation Criterion: 1.8876924514770508\n",
      "---------------------------------------------------------------\n",
      "62/100\n",
      "Minibatch: 61, Train Loss: 2.216984272003174, Train Evaluation Criterion: 2.216984272003174\n",
      "---------------------------------------------------------------\n",
      "63/100\n",
      "Minibatch: 62, Train Loss: 2.0979182720184326, Train Evaluation Criterion: 2.0979182720184326\n",
      "---------------------------------------------------------------\n",
      "64/100\n",
      "Minibatch: 63, Train Loss: 1.2767717838287354, Train Evaluation Criterion: 1.2767717838287354\n",
      "---------------------------------------------------------------\n",
      "65/100\n",
      "Minibatch: 64, Train Loss: 2.2307212352752686, Train Evaluation Criterion: 2.2307212352752686\n",
      "---------------------------------------------------------------\n",
      "66/100\n",
      "Minibatch: 65, Train Loss: 1.1896982192993164, Train Evaluation Criterion: 1.1896982192993164\n",
      "---------------------------------------------------------------\n",
      "67/100\n",
      "Minibatch: 66, Train Loss: 1.4398798942565918, Train Evaluation Criterion: 1.4398798942565918\n",
      "---------------------------------------------------------------\n",
      "68/100\n",
      "Minibatch: 67, Train Loss: 2.0181849002838135, Train Evaluation Criterion: 2.0181849002838135\n",
      "---------------------------------------------------------------\n",
      "69/100\n",
      "Minibatch: 68, Train Loss: 1.9224388599395752, Train Evaluation Criterion: 1.9224388599395752\n",
      "---------------------------------------------------------------\n",
      "70/100\n",
      "Minibatch: 69, Train Loss: 1.6684086322784424, Train Evaluation Criterion: 1.6684086322784424\n",
      "---------------------------------------------------------------\n",
      "71/100\n",
      "Minibatch: 70, Train Loss: 1.8883556127548218, Train Evaluation Criterion: 1.8883556127548218\n",
      "---------------------------------------------------------------\n",
      "72/100\n",
      "Minibatch: 71, Train Loss: 1.645093560218811, Train Evaluation Criterion: 1.645093560218811\n",
      "---------------------------------------------------------------\n",
      "73/100\n",
      "Minibatch: 72, Train Loss: 1.0962989330291748, Train Evaluation Criterion: 1.0962989330291748\n",
      "---------------------------------------------------------------\n",
      "74/100\n",
      "Minibatch: 73, Train Loss: 1.767452359199524, Train Evaluation Criterion: 1.767452359199524\n",
      "---------------------------------------------------------------\n",
      "75/100\n",
      "Minibatch: 74, Train Loss: 1.1475120782852173, Train Evaluation Criterion: 1.1475120782852173\n",
      "---------------------------------------------------------------\n",
      "76/100\n",
      "Minibatch: 75, Train Loss: 2.5007359981536865, Train Evaluation Criterion: 2.5007359981536865\n",
      "---------------------------------------------------------------\n",
      "77/100\n",
      "Minibatch: 76, Train Loss: 1.5354068279266357, Train Evaluation Criterion: 1.5354068279266357\n",
      "---------------------------------------------------------------\n",
      "78/100\n",
      "Minibatch: 77, Train Loss: 1.901287317276001, Train Evaluation Criterion: 1.901287317276001\n",
      "---------------------------------------------------------------\n",
      "79/100\n",
      "Minibatch: 78, Train Loss: 2.281856060028076, Train Evaluation Criterion: 2.281856060028076\n",
      "---------------------------------------------------------------\n",
      "80/100\n",
      "Minibatch: 79, Train Loss: 1.6537214517593384, Train Evaluation Criterion: 1.6537214517593384\n",
      "---------------------------------------------------------------\n",
      "81/100\n",
      "Minibatch: 80, Train Loss: 1.9485992193222046, Train Evaluation Criterion: 1.9485992193222046\n",
      "---------------------------------------------------------------\n",
      "82/100\n",
      "Minibatch: 81, Train Loss: 1.4060325622558594, Train Evaluation Criterion: 1.4060325622558594\n",
      "---------------------------------------------------------------\n",
      "83/100\n",
      "Minibatch: 82, Train Loss: 1.6807371377944946, Train Evaluation Criterion: 1.6807371377944946\n",
      "---------------------------------------------------------------\n",
      "84/100\n",
      "Minibatch: 83, Train Loss: 2.308049201965332, Train Evaluation Criterion: 2.308049201965332\n",
      "---------------------------------------------------------------\n",
      "85/100\n",
      "Minibatch: 84, Train Loss: 1.693650245666504, Train Evaluation Criterion: 1.693650245666504\n",
      "---------------------------------------------------------------\n",
      "86/100\n",
      "Minibatch: 85, Train Loss: 1.947190761566162, Train Evaluation Criterion: 1.947190761566162\n",
      "---------------------------------------------------------------\n",
      "87/100\n",
      "Minibatch: 86, Train Loss: 1.8691155910491943, Train Evaluation Criterion: 1.8691155910491943\n",
      "---------------------------------------------------------------\n",
      "88/100\n",
      "Minibatch: 87, Train Loss: 1.5442675352096558, Train Evaluation Criterion: 1.5442675352096558\n",
      "---------------------------------------------------------------\n",
      "89/100\n",
      "Minibatch: 88, Train Loss: 1.713882327079773, Train Evaluation Criterion: 1.713882327079773\n",
      "---------------------------------------------------------------\n",
      "90/100\n",
      "Minibatch: 89, Train Loss: 1.8274884223937988, Train Evaluation Criterion: 1.8274884223937988\n",
      "---------------------------------------------------------------\n",
      "91/100\n",
      "Minibatch: 90, Train Loss: 1.9459993839263916, Train Evaluation Criterion: 1.9459993839263916\n",
      "---------------------------------------------------------------\n",
      "92/100\n",
      "Minibatch: 91, Train Loss: 1.798192024230957, Train Evaluation Criterion: 1.798192024230957\n",
      "---------------------------------------------------------------\n",
      "93/100\n",
      "Minibatch: 92, Train Loss: 2.194890022277832, Train Evaluation Criterion: 2.194890022277832\n",
      "---------------------------------------------------------------\n",
      "94/100\n",
      "Minibatch: 93, Train Loss: 1.3373198509216309, Train Evaluation Criterion: 1.3373198509216309\n",
      "---------------------------------------------------------------\n",
      "95/100\n",
      "Minibatch: 94, Train Loss: 1.8961130380630493, Train Evaluation Criterion: 1.8961130380630493\n",
      "---------------------------------------------------------------\n",
      "96/100\n",
      "Minibatch: 95, Train Loss: 1.3850743770599365, Train Evaluation Criterion: 1.3850743770599365\n",
      "---------------------------------------------------------------\n",
      "97/100\n",
      "Minibatch: 96, Train Loss: 1.6846004724502563, Train Evaluation Criterion: 1.6846004724502563\n",
      "---------------------------------------------------------------\n",
      "98/100\n",
      "Minibatch: 97, Train Loss: 1.6755255460739136, Train Evaluation Criterion: 1.6755255460739136\n",
      "---------------------------------------------------------------\n",
      "99/100\n",
      "Minibatch: 98, Train Loss: 1.6169592142105103, Train Evaluation Criterion: 1.6169592142105103\n",
      "---------------------------------------------------------------\n",
      "100/100\n",
      "Minibatch: 99, Train Loss: 1.6857378482818604, Train Evaluation Criterion: 1.6857378482818604\n"
     ]
    }
   ],
   "source": [
    "z=train_mm(ArrPieces,songs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#prime_data=np.array([[0]*((upperBound-lowerBound)*2)],dtype=np.float32)\n",
    "#print(prime_data)\n",
    "#len(prime_data[0])\n",
    "#print(len(prime_data))\n",
    "#data[0]\n",
    "#data[1:3]\n",
    "testout=sample(z,prime_data=np.array([[0]*((upperBound-lowerBound)*2)],dtype=np.float32),length=1000) #,threshold=5)\n",
    "musicM=data2MusicMatric(testout)\n",
    "S = stream.Score()\n",
    "MusicMinMatrix2midi(musicM,S,100)\n",
    "#sp=midi.realtime.StreamPlayer(S)\n",
    "#sp.play()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MLmusicOut/TestNr5CMaskMusicMSElong.mid'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S.write('midi', 'MLmusicOut/TestNr5CMaskMusicMSElong.mid') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_filename = \"models/0212overfit-deepjingling-composer_epoch100.dnn\"\n",
    "save_model(z, model_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
