{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data has 30647 characters, 48 unique.\n",
      "Minibatch: 0, Train Loss: 3.8699542236328126, Train Evaluation Criterion: 0.95\n",
      "Epoch 0, 0.000000 % done\n",
      "d5!-!:-.!-:li6,os m:luip,8os  mlu8lu62fimp,8:oos  mlu8lu62fimp,8:oos  mlu8lu62fimp,8:oos  mlu8lu62fimp,8:oos  mlu8lu62fimp,8:oos  mlu8lu62fimp,8:oos  mlu8lu62fimp,8:oos  mlu8lu62fimp,8:oos  mlu8lu62fimp,8:oos  mlu8lu62fimp,8:oos  mlu8lu62fimp,8:oos  mlu8lu62fimp,8:oos  mlu8lu62fimp,8:oos  mlu8lu62fim\n",
      "Minibatch: 100, Train Loss: 2.926949462890625, Train Evaluation Criterion: 0.82\n",
      "Epoch 0, 32.679739 % done\n",
      "Minibatch: 200, Train Loss: 2.5753598022460937, Train Evaluation Criterion: 0.76\n",
      "Epoch 0, 65.359477 % done\n",
      "Minibatch: 300, Train Loss: 2.507676544189453, Train Evaluation Criterion: 0.8\n",
      "Epoch 0, 98.039216 % done\n",
      "Saved model to 'models/deepjingling-songwriter_epoch1.dnn'\n",
      "Minibatch: 400, Train Loss: 2.373348388671875, Train Evaluation Criterion: 0.65\n",
      "Epoch 1, 30.718954 % done\n",
      "Minibatch: 500, Train Loss: 2.1483393859863282, Train Evaluation Criterion: 0.6\n",
      "Epoch 1, 63.398693 % done\n",
      "Minibatch: 600, Train Loss: 1.9454438781738281, Train Evaluation Criterion: 0.58\n",
      "Epoch 1, 96.078431 % done\n",
      "Saved model to 'models/deepjingling-songwriter_epoch2.dnn'\n",
      "Minibatch: 700, Train Loss: 2.6088214111328125, Train Evaluation Criterion: 0.73\n",
      "Epoch 2, 28.758170 % done\n",
      "Minibatch: 800, Train Loss: 1.8305166625976563, Train Evaluation Criterion: 0.52\n",
      "Epoch 2, 61.437908 % done\n",
      "Minibatch: 900, Train Loss: 1.642972412109375, Train Evaluation Criterion: 0.5\n",
      "Epoch 2, 94.117647 % done\n",
      "Saved model to 'models/deepjingling-songwriter_epoch3.dnn'\n",
      "Minibatch: 1000, Train Loss: 1.9911195373535155, Train Evaluation Criterion: 0.6\n",
      "Epoch 3, 26.797386 % done\n",
      "stas a santa santa santa santa santa santa santa santa santa santa santa santa santa santa santa santa santa santa santa santa santa santa santa santa santa santa santa santa santa santa santa santa santa santa santa santa santa santa santa santa santa santa santa santa santa santa santa santa santa \n",
      "Minibatch: 1100, Train Loss: 2.2632249450683593, Train Evaluation Criterion: 0.66\n",
      "Epoch 3, 59.477124 % done\n",
      "Minibatch: 1200, Train Loss: 0.79433837890625, Train Evaluation Criterion: 0.2\n",
      "Epoch 3, 92.156863 % done\n",
      "Saved model to 'models/deepjingling-songwriter_epoch4.dnn'\n",
      "Minibatch: 1300, Train Loss: 1.8695565795898437, Train Evaluation Criterion: 0.52\n",
      "Epoch 4, 24.836601 % done\n",
      "Minibatch: 1400, Train Loss: 1.62799560546875, Train Evaluation Criterion: 0.49\n",
      "Epoch 4, 57.516340 % done\n",
      "Minibatch: 1500, Train Loss: 1.302347412109375, Train Evaluation Criterion: 0.37\n",
      "Epoch 4, 90.196078 % done\n",
      "Saved model to 'models/deepjingling-songwriter_epoch5.dnn'\n",
      "Minibatch: 1600, Train Loss: 1.040775909423828, Train Evaluation Criterion: 0.27\n",
      "Epoch 5, 22.875817 % done\n",
      "Minibatch: 1700, Train Loss: 1.7552984619140626, Train Evaluation Criterion: 0.53\n",
      "Epoch 5, 55.555556 % done\n",
      "Minibatch: 1800, Train Loss: 1.0340733337402344, Train Evaluation Criterion: 0.27\n",
      "Epoch 5, 88.235294 % done\n",
      "Saved model to 'models/deepjingling-songwriter_epoch6.dnn'\n",
      "Minibatch: 1900, Train Loss: 1.8950050354003907, Train Evaluation Criterion: 0.53\n",
      "Epoch 6, 20.915033 % done\n",
      "Minibatch: 2000, Train Loss: 1.6747418212890626, Train Evaluation Criterion: 0.51\n",
      "Epoch 6, 53.594771 % done\n",
      "ming to look a one horse open sleigh\n",
      "jingle bell time in a one horse open sleigh\n",
      "jingle bell time in a one horse open sleigh\n",
      "jingle bell time in a one horse open sleigh\n",
      "jingle bell time in a one horse open sleigh\n",
      "jingle bell time in a one horse open sleigh\n",
      "jingle bell time in a one horse open sleigh\n",
      "\n",
      "Minibatch: 2100, Train Loss: 1.8843698120117187, Train Evaluation Criterion: 0.59\n",
      "Epoch 6, 86.274510 % done\n",
      "Saved model to 'models/deepjingling-songwriter_epoch7.dnn'\n",
      "Minibatch: 2200, Train Loss: 1.8884237670898438, Train Evaluation Criterion: 0.56\n",
      "Epoch 7, 18.954248 % done\n",
      "Minibatch: 2300, Train Loss: 1.484776153564453, Train Evaluation Criterion: 0.39\n",
      "Epoch 7, 51.633987 % done\n",
      "Minibatch: 2400, Train Loss: 1.6995896911621093, Train Evaluation Criterion: 0.55\n",
      "Epoch 7, 84.313725 % done\n",
      "Saved model to 'models/deepjingling-songwriter_epoch8.dnn'\n",
      "Minibatch: 2500, Train Loss: 1.6561456298828126, Train Evaluation Criterion: 0.45\n",
      "Epoch 8, 16.993464 % done\n",
      "Minibatch: 2600, Train Loss: 0.9714524078369141, Train Evaluation Criterion: 0.27\n",
      "Epoch 8, 49.673203 % done\n",
      "Minibatch: 2700, Train Loss: 1.6616593933105468, Train Evaluation Criterion: 0.49\n",
      "Epoch 8, 82.352941 % done\n",
      "Saved model to 'models/deepjingling-songwriter_epoch9.dnn'\n",
      "Minibatch: 2800, Train Loss: 1.6268765258789062, Train Evaluation Criterion: 0.53\n",
      "Epoch 9, 15.032680 % done\n",
      "Minibatch: 2900, Train Loss: 0.9262856292724609, Train Evaluation Criterion: 0.26\n",
      "Epoch 9, 47.712418 % done\n",
      "Minibatch: 3000, Train Loss: 1.3562496948242186, Train Evaluation Criterion: 0.4\n",
      "Epoch 9, 80.392157 % done\n",
      "x and the chimney tonight\n",
      "\n",
      "then you when you hear sleigh\n",
      "and her christmas tree,\n",
      "o christmas tree,\n",
      "o christmas tree,\n",
      "o christmas tree,\n",
      "o christmas tree,\n",
      "o christmas tree,\n",
      "o christmas tree,\n",
      "o christmas tree,\n",
      "o christmas tree,\n",
      "o christmas tree,\n",
      "o christmas tree,\n",
      "o christmas tree,\n",
      "o christmas tree,\n",
      "o ch\n",
      "Saved model to 'models/deepjingling-songwriter_epoch10.dnn'\n",
      "Minibatch: 3100, Train Loss: 2.1020582580566405, Train Evaluation Criterion: 0.62\n",
      "Epoch 10, 13.071895 % done\n",
      "Minibatch: 3200, Train Loss: 1.3121971130371093, Train Evaluation Criterion: 0.37\n",
      "Epoch 10, 45.751634 % done\n",
      "Minibatch: 3300, Train Loss: 1.357586669921875, Train Evaluation Criterion: 0.42\n",
      "Epoch 10, 78.431373 % done\n",
      "Saved model to 'models/deepjingling-songwriter_epoch11.dnn'\n",
      "Minibatch: 3400, Train Loss: 1.0807015991210938, Train Evaluation Criterion: 0.35\n",
      "Epoch 11, 11.111111 % done\n",
      "Minibatch: 3500, Train Loss: 1.858779296875, Train Evaluation Criterion: 0.47\n",
      "Epoch 11, 43.790850 % done\n",
      "Minibatch: 3600, Train Loss: 1.6102159118652344, Train Evaluation Criterion: 0.42\n",
      "Epoch 11, 76.470588 % done\n",
      "Saved model to 'models/deepjingling-songwriter_epoch12.dnn'\n",
      "Minibatch: 3700, Train Loss: 1.2477581024169921, Train Evaluation Criterion: 0.36\n",
      "Epoch 12, 9.150327 % done\n",
      "Minibatch: 3800, Train Loss: 1.400622100830078, Train Evaluation Criterion: 0.41\n",
      "Epoch 12, 41.830065 % done\n",
      "Minibatch: 3900, Train Loss: 1.3218019104003906, Train Evaluation Criterion: 0.38\n",
      "Epoch 12, 74.509804 % done\n",
      "Saved model to 'models/deepjingling-songwriter_epoch13.dnn'\n",
      "Minibatch: 4000, Train Loss: 1.0160748291015624, Train Evaluation Criterion: 0.26\n",
      "Epoch 13, 7.189542 % done\n",
      "5 the season the season the season the season the season the season the season the season the season the season the season the season the season the season the season the season the season the season the season the season the season the season the season the season the season the season the season th\n",
      "Minibatch: 4100, Train Loss: 1.3341433715820312, Train Evaluation Criterion: 0.38\n",
      "Epoch 13, 39.869281 % done\n",
      "Minibatch: 4200, Train Loss: 1.3650575256347657, Train Evaluation Criterion: 0.41\n",
      "Epoch 13, 72.549020 % done\n",
      "Saved model to 'models/deepjingling-songwriter_epoch14.dnn'\n",
      "Minibatch: 4300, Train Loss: 0.8761295318603516, Train Evaluation Criterion: 0.24\n",
      "Epoch 14, 5.228758 % done\n",
      "Minibatch: 4400, Train Loss: 0.8570918273925782, Train Evaluation Criterion: 0.29\n",
      "Epoch 14, 37.908497 % done\n",
      "Minibatch: 4500, Train Loss: 0.7123868560791016, Train Evaluation Criterion: 0.24\n",
      "Epoch 14, 70.588235 % done\n",
      "Saved model to 'models/deepjingling-songwriter_epoch15.dnn'\n",
      "Minibatch: 4600, Train Loss: 1.7428076171875, Train Evaluation Criterion: 0.53\n",
      "Epoch 15, 3.267974 % done\n",
      "Minibatch: 4700, Train Loss: 1.2680841827392577, Train Evaluation Criterion: 0.41\n",
      "Epoch 15, 35.947712 % done\n",
      "Minibatch: 4800, Train Loss: 1.2680066680908204, Train Evaluation Criterion: 0.38\n",
      "Epoch 15, 68.627451 % done\n",
      "Saved model to 'models/deepjingling-songwriter_epoch16.dnn'\n",
      "Minibatch: 4900, Train Loss: 1.5823092651367188, Train Evaluation Criterion: 0.45\n",
      "Epoch 16, 1.307190 % done\n",
      "Minibatch: 5000, Train Loss: 1.1710713195800782, Train Evaluation Criterion: 0.34\n",
      "Epoch 16, 33.986928 % done\n",
      "x and merry and grandpa, we believe\n",
      "\n",
      "now the snowman, have a holly, frosty, the snowman, with the song with the song with the song with the song with the song with the song with the song with the song with the song with the song with the song with the song with the song with the song with the song wi\n",
      "Minibatch: 5100, Train Loss: 0.4014816665649414, Train Evaluation Criterion: 0.14\n",
      "Epoch 16, 66.666667 % done\n",
      "Minibatch: 5200, Train Loss: 1.3224728393554688, Train Evaluation Criterion: 0.39\n",
      "Epoch 16, 99.346405 % done\n",
      "Saved model to 'models/deepjingling-songwriter_epoch17.dnn'\n",
      "Minibatch: 5300, Train Loss: 0.6789319610595703, Train Evaluation Criterion: 0.2\n",
      "Epoch 17, 32.026144 % done\n",
      "Minibatch: 5400, Train Loss: 0.9116912841796875, Train Evaluation Criterion: 0.26\n",
      "Epoch 17, 64.705882 % done\n",
      "Minibatch: 5500, Train Loss: 1.0021123504638672, Train Evaluation Criterion: 0.32\n",
      "Epoch 17, 97.385621 % done\n",
      "Saved model to 'models/deepjingling-songwriter_epoch18.dnn'\n",
      "Minibatch: 5600, Train Loss: 0.6674457550048828, Train Evaluation Criterion: 0.2\n",
      "Epoch 18, 30.065359 % done\n",
      "Minibatch: 5700, Train Loss: 0.42786243438720706, Train Evaluation Criterion: 0.11\n",
      "Epoch 18, 62.745098 % done\n",
      "Minibatch: 5800, Train Loss: 0.2258685302734375, Train Evaluation Criterion: 0.08\n",
      "Epoch 18, 95.424837 % done\n",
      "Saved model to 'models/deepjingling-songwriter_epoch19.dnn'\n",
      "Minibatch: 5900, Train Loss: 0.7582860565185547, Train Evaluation Criterion: 0.27\n",
      "Epoch 19, 28.104575 % done\n",
      "Minibatch: 6000, Train Loss: 0.6977891540527343, Train Evaluation Criterion: 0.18\n",
      "Epoch 19, 60.784314 % done\n",
      "dented wings to ride\n",
      "in a one horse open sleigh.\n",
      "jingle bell time\n",
      "and in the stor stop\n",
      "and in the street to stay to ride\n",
      "in a one horse open sleigh.\n",
      "jingle bell time\n",
      "and in the stor stop\n",
      "and in the street to stay to ride\n",
      "in a one horse open sleigh.\n",
      "jingle bell time\n",
      "and in the stor stop\n",
      "and in the str\n",
      "Minibatch: 6100, Train Loss: 0.18750993728637697, Train Evaluation Criterion: 0.05\n",
      "Epoch 19, 93.464052 % done\n",
      "Saved model to 'models/deepjingling-songwriter_epoch20.dnn'\n",
      "Minibatch: 6200, Train Loss: 1.2818009948730469, Train Evaluation Criterion: 0.33\n",
      "Epoch 20, 26.143791 % done\n",
      "Minibatch: 6300, Train Loss: 1.0094298553466796, Train Evaluation Criterion: 0.29\n",
      "Epoch 20, 58.823529 % done\n",
      "Minibatch: 6400, Train Loss: 0.3295492935180664, Train Evaluation Criterion: 0.09\n",
      "Epoch 20, 91.503268 % done\n",
      "Saved model to 'models/deepjingling-songwriter_epoch21.dnn'\n",
      "Minibatch: 6500, Train Loss: 1.18043701171875, Train Evaluation Criterion: 0.32\n",
      "Epoch 21, 24.183007 % done\n",
      "Minibatch: 6600, Train Loss: 0.7022126007080078, Train Evaluation Criterion: 0.18\n",
      "Epoch 21, 56.862745 % done\n",
      "Minibatch: 6700, Train Loss: 0.34379215240478517, Train Evaluation Criterion: 0.07\n",
      "Epoch 21, 89.542484 % done\n",
      "Saved model to 'models/deepjingling-songwriter_epoch22.dnn'\n",
      "Minibatch: 6800, Train Loss: 1.2909385681152343, Train Evaluation Criterion: 0.41\n",
      "Epoch 22, 22.222222 % done\n",
      "Minibatch: 6900, Train Loss: 0.8977001953125, Train Evaluation Criterion: 0.26\n",
      "Epoch 22, 54.901961 % done\n",
      "Minibatch: 7000, Train Loss: 0.32104351043701174, Train Evaluation Criterion: 0.08\n",
      "Epoch 22, 87.581699 % done\n",
      "glories streaming\n",
      "with a tree\n",
      "\n",
      "christ the sounding to town\n",
      "\n",
      "he's gold stop\n",
      "at the snow \n",
      "there'll be scary good sing\n",
      "and the christmas tree\n",
      "have a holly that is the sounding\n",
      "of a pear tree\n",
      "\n",
      "on the chimney tonight\n",
      "\n",
      "santa baby,\n",
      "so hurry down the chimney tonight\n",
      "\n",
      "santa baby,\n",
      "so hurry down the chimney ton\n",
      "Saved model to 'models/deepjingling-songwriter_epoch23.dnn'\n",
      "Minibatch: 7100, Train Loss: 1.155324478149414, Train Evaluation Criterion: 0.35\n",
      "Epoch 23, 20.261438 % done\n",
      "Minibatch: 7200, Train Loss: 0.8038200378417969, Train Evaluation Criterion: 0.26\n",
      "Epoch 23, 52.941176 % done\n",
      "Minibatch: 7300, Train Loss: 0.6793292999267578, Train Evaluation Criterion: 0.23\n",
      "Epoch 23, 85.620915 % done\n",
      "Saved model to 'models/deepjingling-songwriter_epoch24.dnn'\n",
      "Minibatch: 7400, Train Loss: 0.5400439453125, Train Evaluation Criterion: 0.17\n",
      "Epoch 24, 18.300654 % done\n",
      "Minibatch: 7500, Train Loss: 0.7891295623779296, Train Evaluation Criterion: 0.23\n",
      "Epoch 24, 50.980392 % done\n",
      "Minibatch: 7600, Train Loss: 1.235628662109375, Train Evaluation Criterion: 0.42\n",
      "Epoch 24, 83.660131 % done\n",
      "Saved model to 'models/deepjingling-songwriter_epoch25.dnn'\n",
      "Minibatch: 7700, Train Loss: 0.6245365524291993, Train Evaluation Criterion: 0.18\n",
      "Epoch 25, 16.339869 % done\n",
      "Minibatch: 7800, Train Loss: 0.6343590927124023, Train Evaluation Criterion: 0.2\n",
      "Epoch 25, 49.019608 % done\n",
      "Minibatch: 7900, Train Loss: 0.5407833862304687, Train Evaluation Criterion: 0.17\n",
      "Epoch 25, 81.699346 % done\n",
      "Saved model to 'models/deepjingling-songwriter_epoch26.dnn'\n",
      "Minibatch: 8000, Train Loss: 1.0558982849121095, Train Evaluation Criterion: 0.32\n",
      "Epoch 26, 14.379085 % done\n",
      ", a thirty tonight\n",
      "\n",
      "santa beat a seasing by me for christmas tree,\n",
      "much pleasure doth thou breaks a mean to sleep to me:\n",
      "10 lords a leaping\n",
      "5 ladies dancing their heavenly peace\n",
      "\n",
      "silent night, he say of christmas tree\n",
      "have a happy hold at the snow\n",
      "we'll have some day of christmas tree\n",
      "have a happy ho\n",
      "Minibatch: 8100, Train Loss: 0.8987181091308594, Train Evaluation Criterion: 0.27\n",
      "Epoch 26, 47.058824 % done\n",
      "Minibatch: 8200, Train Loss: 0.6576304626464844, Train Evaluation Criterion: 0.21\n",
      "Epoch 26, 79.738562 % done\n",
      "Saved model to 'models/deepjingling-songwriter_epoch27.dnn'\n",
      "Minibatch: 8300, Train Loss: 1.1838108062744142, Train Evaluation Criterion: 0.36\n",
      "Epoch 27, 12.418301 % done\n",
      "Minibatch: 8400, Train Loss: 0.6785777282714843, Train Evaluation Criterion: 0.21\n",
      "Epoch 27, 45.098039 % done\n",
      "Minibatch: 8500, Train Loss: 0.619087905883789, Train Evaluation Criterion: 0.18\n",
      "Epoch 27, 77.777778 % done\n",
      "Saved model to 'models/deepjingling-songwriter_epoch28.dnn'\n",
      "Minibatch: 8600, Train Loss: 0.49820552825927733, Train Evaluation Criterion: 0.13\n",
      "Epoch 28, 10.457516 % done\n",
      "Minibatch: 8700, Train Loss: 0.8542752075195312, Train Evaluation Criterion: 0.31\n",
      "Epoch 28, 43.137255 % done\n",
      "Minibatch: 8800, Train Loss: 0.6837498474121094, Train Evaluation Criterion: 0.2\n",
      "Epoch 28, 75.816993 % done\n",
      "Saved model to 'models/deepjingling-songwriter_epoch29.dnn'\n",
      "Minibatch: 8900, Train Loss: 0.7648407745361329, Train Evaluation Criterion: 0.26\n",
      "Epoch 29, 8.496732 % done\n",
      "Minibatch: 9000, Train Loss: 0.9333170318603515, Train Evaluation Criterion: 0.31\n",
      "Epoch 29, 41.176471 % done\n",
      "ful in the snow\n",
      "\n",
      "where the stars are a child, a come ye all the bend of the children say her bells\n",
      "in her and bells\n",
      "in her back\n",
      "\n",
      "grandma got run over by a reindeer\n",
      "walkin' home from our house christmas eve\n",
      "you can say there's no such thing as santa\n",
      "but as for me and grandpa, we believe\n",
      "\n",
      "now in the se\n",
      "Minibatch: 9100, Train Loss: 0.8680815887451172, Train Evaluation Criterion: 0.25\n",
      "Epoch 29, 73.856209 % done\n",
      "Saved model to 'models/deepjingling-songwriter_epoch30.dnn'\n",
      "Minibatch: 9200, Train Loss: 0.5164569091796875, Train Evaluation Criterion: 0.15\n",
      "Epoch 30, 6.535948 % done\n",
      "Minibatch: 9300, Train Loss: 1.061712188720703, Train Evaluation Criterion: 0.36\n",
      "Epoch 30, 39.215686 % done\n",
      "Minibatch: 9400, Train Loss: 0.282219181060791, Train Evaluation Criterion: 0.09\n",
      "Epoch 30, 71.895425 % done\n",
      "Saved model to 'models/deepjingling-songwriter_epoch31.dnn'\n",
      "Minibatch: 9500, Train Loss: 0.9252049255371094, Train Evaluation Criterion: 0.31\n",
      "Epoch 31, 4.575163 % done\n",
      "Minibatch: 9600, Train Loss: 0.45017501831054685, Train Evaluation Criterion: 0.17\n",
      "Epoch 31, 37.254902 % done\n",
      "Minibatch: 9700, Train Loss: 0.5639387512207031, Train Evaluation Criterion: 0.16\n",
      "Epoch 31, 69.934641 % done\n",
      "Saved model to 'models/deepjingling-songwriter_epoch32.dnn'\n",
      "Minibatch: 9800, Train Loss: 0.7740666961669922, Train Evaluation Criterion: 0.27\n",
      "Epoch 32, 2.614379 % done\n",
      "Minibatch: 9900, Train Loss: 0.8720199584960937, Train Evaluation Criterion: 0.28\n",
      "Epoch 32, 35.294118 % done\n",
      "Minibatch: 10000, Train Loss: 0.6246762084960937, Train Evaluation Criterion: 0.18\n",
      "Epoch 32, 67.973856 % done\n",
      "\"\n",
      "\n",
      "they told me\n",
      "pa rum pum pum pum\n",
      "i am a poor the stars are brightly!\n",
      "o christmas tree,\n",
      "much pleasure doth thou bring me!\n",
      "\n",
      "o christmas tree,\n",
      "much pleasure doth thou bring me!\n",
      "\n",
      "o christmas tree,\n",
      "much pleasure doth thou bring me!\n",
      "\n",
      "o christmas tree,\n",
      "much pleasure doth thou bring me!\n",
      "\n",
      "o christmas tree,\n",
      "\n",
      "Saved model to 'models/deepjingling-songwriter_epoch33.dnn'\n",
      "Minibatch: 10100, Train Loss: 0.7391395568847656, Train Evaluation Criterion: 0.23\n",
      "Epoch 33, 0.653595 % done\n",
      "Minibatch: 10200, Train Loss: 0.8875308227539063, Train Evaluation Criterion: 0.24\n",
      "Epoch 33, 33.333333 % done\n",
      "Minibatch: 10300, Train Loss: 0.33291484832763674, Train Evaluation Criterion: 0.12\n",
      "Epoch 33, 66.013072 % done\n",
      "Minibatch: 10400, Train Loss: 0.654028549194336, Train Evaluation Criterion: 0.24\n",
      "Epoch 33, 98.692810 % done\n",
      "Saved model to 'models/deepjingling-songwriter_epoch34.dnn'\n",
      "Minibatch: 10500, Train Loss: 0.8101251220703125, Train Evaluation Criterion: 0.27\n",
      "Epoch 34, 31.372549 % done\n",
      "Minibatch: 10600, Train Loss: 0.3261228942871094, Train Evaluation Criterion: 0.1\n",
      "Epoch 34, 64.052288 % done\n",
      "Minibatch: 10700, Train Loss: 0.28150400161743167, Train Evaluation Criterion: 0.12\n",
      "Epoch 34, 96.732026 % done\n",
      "Saved model to 'models/deepjingling-songwriter_epoch35.dnn'\n",
      "Minibatch: 10800, Train Loss: 0.7602305603027344, Train Evaluation Criterion: 0.22\n",
      "Epoch 35, 29.411765 % done\n",
      "Minibatch: 10900, Train Loss: 0.297960090637207, Train Evaluation Criterion: 0.07\n",
      "Epoch 35, 62.091503 % done\n",
      "Minibatch: 11000, Train Loss: 0.323792839050293, Train Evaluation Criterion: 0.09\n",
      "Epoch 35, 94.771242 % done\n",
      "-and sing\n",
      "soon it will be christmas\n",
      "my true love sent to me:\n",
      "10 lords a leaping\n",
      "9 ladies dancing\n",
      "8 maids a milking\n",
      "7 swans a swimming\n",
      "6 geese a laying\n",
      "5 golden rings\n",
      "4 calling birds\n",
      "3 french hens\n",
      "2 turtle doves\n",
      "and a partridge in a pear tree\n",
      "\n",
      "on the first day of christmas\n",
      "my true love sent to me:\n",
      "10 \n",
      "Saved model to 'models/deepjingling-songwriter_epoch36.dnn'\n",
      "Minibatch: 11100, Train Loss: 0.48529739379882814, Train Evaluation Criterion: 0.19\n",
      "Epoch 36, 27.450980 % done\n",
      "Minibatch: 11200, Train Loss: 0.2836235809326172, Train Evaluation Criterion: 0.09\n",
      "Epoch 36, 60.130719 % done\n",
      "Minibatch: 11300, Train Loss: 0.017062511444091797, Train Evaluation Criterion: 0.0\n",
      "Epoch 36, 92.810458 % done\n",
      "Saved model to 'models/deepjingling-songwriter_epoch37.dnn'\n",
      "Minibatch: 11400, Train Loss: 0.9336552429199219, Train Evaluation Criterion: 0.33\n",
      "Epoch 37, 25.490196 % done\n",
      "Minibatch: 11500, Train Loss: 0.2752443504333496, Train Evaluation Criterion: 0.09\n",
      "Epoch 37, 58.169935 % done\n",
      "Minibatch: 11600, Train Loss: 0.18728572845458985, Train Evaluation Criterion: 0.03\n",
      "Epoch 37, 90.849673 % done\n",
      "Saved model to 'models/deepjingling-songwriter_epoch38.dnn'\n",
      "Minibatch: 11700, Train Loss: 0.7250148773193359, Train Evaluation Criterion: 0.21\n",
      "Epoch 38, 23.529412 % done\n",
      "Minibatch: 11800, Train Loss: 0.674080810546875, Train Evaluation Criterion: 0.2\n",
      "Epoch 38, 56.209150 % done\n",
      "Minibatch: 11900, Train Loss: 0.13650669097900392, Train Evaluation Criterion: 0.04\n",
      "Epoch 38, 88.888889 % done\n",
      "Saved model to 'models/deepjingling-songwriter_epoch39.dnn'\n",
      "Minibatch: 12000, Train Loss: 0.6088100814819336, Train Evaluation Criterion: 0.2\n",
      "Epoch 39, 21.568627 % done\n",
      "let's good night with their sheep,\n",
      "on a cold his pray for popping\n",
      "\n",
      "then let us all within us all of your kin,\n",
      "good tidings for christmas tree\n",
      "\n",
      "on the season to what i haven't the say\n",
      "the child, sleeping in the season to the newborn king!\"\n",
      "\n",
      "hear the season to what i haven't christmas tree\n",
      "wath and car\n",
      "Minibatch: 12100, Train Loss: 0.6727398681640625, Train Evaluation Criterion: 0.21\n",
      "Epoch 39, 54.248366 % done\n",
      "Minibatch: 12200, Train Loss: 0.29499818801879885, Train Evaluation Criterion: 0.1\n",
      "Epoch 39, 86.928105 % done\n",
      "Saved model to 'models/deepjingling-songwriter_epoch40.dnn'\n",
      "Minibatch: 12300, Train Loss: 0.3008026885986328, Train Evaluation Criterion: 0.07\n",
      "Epoch 40, 19.607843 % done\n",
      "Minibatch: 12400, Train Loss: 0.2895384407043457, Train Evaluation Criterion: 0.08\n",
      "Epoch 40, 52.287582 % done\n",
      "Minibatch: 12500, Train Loss: 0.51555419921875, Train Evaluation Criterion: 0.13\n",
      "Epoch 40, 84.967320 % done\n",
      "Saved model to 'models/deepjingling-songwriter_epoch41.dnn'\n",
      "Minibatch: 12600, Train Loss: 0.5792509460449219, Train Evaluation Criterion: 0.2\n",
      "Epoch 41, 17.647059 % done\n",
      "Minibatch: 12700, Train Loss: 0.17811286926269532, Train Evaluation Criterion: 0.06\n",
      "Epoch 41, 50.326797 % done\n",
      "Minibatch: 12800, Train Loss: 0.45733646392822264, Train Evaluation Criterion: 0.11\n",
      "Epoch 41, 83.006536 % done\n",
      "Saved model to 'models/deepjingling-songwriter_epoch42.dnn'\n",
      "Minibatch: 12900, Train Loss: 0.5068775177001953, Train Evaluation Criterion: 0.15\n",
      "Epoch 42, 15.686275 % done\n",
      "Minibatch: 13000, Train Loss: 0.11886122703552246, Train Evaluation Criterion: 0.04\n",
      "Epoch 42, 48.366013 % done\n",
      "quletide carol, fa la la la la!\n",
      "heed our sheep.\n",
      "\n",
      "then lowly plains\n",
      "they bend on holly that will make them sing\n",
      "so bend on the earth\n",
      "its ancient splendors fling,\n",
      "and all the way\n",
      "oh, what fun it is to ride\n",
      "in a one horse open sleigh\n",
      "jingle bells, jingle bells\n",
      "jingle all the way\n",
      "oh, what fun it is to ri\n",
      "Minibatch: 13100, Train Loss: 0.23700145721435548, Train Evaluation Criterion: 0.06\n",
      "Epoch 42, 81.045752 % done\n",
      "Saved model to 'models/deepjingling-songwriter_epoch43.dnn'\n",
      "Minibatch: 13200, Train Loss: 0.6975675201416016, Train Evaluation Criterion: 0.23\n",
      "Epoch 43, 13.725490 % done\n",
      "Minibatch: 13300, Train Loss: 0.21532480239868165, Train Evaluation Criterion: 0.06\n",
      "Epoch 43, 46.405229 % done\n",
      "Minibatch: 13400, Train Loss: 0.1739911651611328, Train Evaluation Criterion: 0.07\n",
      "Epoch 43, 79.084967 % done\n",
      "Saved model to 'models/deepjingling-songwriter_epoch44.dnn'\n",
      "Minibatch: 13500, Train Loss: 0.6587652587890624, Train Evaluation Criterion: 0.24\n",
      "Epoch 44, 11.764706 % done\n",
      "Minibatch: 13600, Train Loss: 0.7962461853027344, Train Evaluation Criterion: 0.24\n",
      "Epoch 44, 44.444444 % done\n",
      "Minibatch: 13700, Train Loss: 0.5745526123046875, Train Evaluation Criterion: 0.19\n",
      "Epoch 44, 77.124183 % done\n",
      "Saved model to 'models/deepjingling-songwriter_epoch45.dnn'\n",
      "Minibatch: 13800, Train Loss: 0.44307621002197267, Train Evaluation Criterion: 0.14\n",
      "Epoch 45, 9.803922 % done\n",
      "Minibatch: 13900, Train Loss: 0.6202327728271484, Train Evaluation Criterion: 0.21\n",
      "Epoch 45, 42.483660 % done\n",
      "Minibatch: 14000, Train Loss: 0.5388743209838868, Train Evaluation Criterion: 0.16\n",
      "Epoch 45, 75.163399 % done\n",
      "7 some maging\n",
      "but as for me and grandpa, we believe\n",
      "\n",
      "she'd been dring of the angels sing.\n",
      "\n",
      "yet with te would have been\n",
      "if daddy happy meetings \n",
      "when love ones are near \n",
      "it's the most wonderful time \n",
      "it's the most wonderful time \n",
      "it's the most wonderful time \n",
      "it's the most wonderful time \n",
      "it's the mos\n",
      "Saved model to 'models/deepjingling-songwriter_epoch46.dnn'\n",
      "Minibatch: 14100, Train Loss: 0.4413414001464844, Train Evaluation Criterion: 0.15\n",
      "Epoch 46, 7.843137 % done\n",
      "Minibatch: 14200, Train Loss: 0.7355855560302734, Train Evaluation Criterion: 0.21\n",
      "Epoch 46, 40.522876 % done\n",
      "Minibatch: 14300, Train Loss: 0.6331822967529297, Train Evaluation Criterion: 0.23\n",
      "Epoch 46, 73.202614 % done\n",
      "Saved model to 'models/deepjingling-songwriter_epoch47.dnn'\n",
      "Minibatch: 14400, Train Loss: 0.3354531860351562, Train Evaluation Criterion: 0.12\n",
      "Epoch 47, 5.882353 % done\n",
      "Minibatch: 14500, Train Loss: 0.4412427139282227, Train Evaluation Criterion: 0.18\n",
      "Epoch 47, 38.562092 % done\n",
      "Minibatch: 14600, Train Loss: 0.5002825927734375, Train Evaluation Criterion: 0.17\n",
      "Epoch 47, 71.241830 % done\n",
      "Saved model to 'models/deepjingling-songwriter_epoch48.dnn'\n",
      "Minibatch: 14700, Train Loss: 0.3929943084716797, Train Evaluation Criterion: 0.13\n",
      "Epoch 48, 3.921569 % done\n",
      "Minibatch: 14800, Train Loss: 0.6084997940063477, Train Evaluation Criterion: 0.2\n",
      "Epoch 48, 36.601307 % done\n",
      "Minibatch: 14900, Train Loss: 0.8165070343017579, Train Evaluation Criterion: 0.24\n",
      "Epoch 48, 69.281046 % done\n",
      "Saved model to 'models/deepjingling-songwriter_epoch49.dnn'\n",
      "Minibatch: 15000, Train Loss: 0.6045800018310546, Train Evaluation Criterion: 0.23\n",
      "Epoch 49, 1.960784 % done\n",
      "quare in the stars are brightly shining\n",
      "artherd both the light of a seasick crocodiled bethlehem.\n",
      "come on, it's lovely weather\n",
      "for a sleigh ride together with you\n",
      "\n",
      "there's a birthday party at the sounding\n",
      "just the savior is born\n",
      "\n",
      "silent night, holy night!\n",
      "shepherds sing,\n",
      "\"glory to the newborn king!\"\n",
      "\n",
      "Minibatch: 15100, Train Loss: 0.1295686912536621, Train Evaluation Criterion: 0.05\n",
      "Epoch 49, 34.640523 % done\n",
      "Minibatch: 15200, Train Loss: 0.4919401550292969, Train Evaluation Criterion: 0.12\n",
      "Epoch 49, 67.320261 % done\n"
     ]
    }
   ],
   "source": [
    "# char-rnn.py\n",
    "# Neural Character Language Model in CNTK2\n",
    "# wdarling@microsoft.com\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "from cntk import Trainer, Axis\n",
    "from cntk.learner import adam_sgd, momentum_sgd, momentum_as_time_constant_schedule, learning_rate_schedule, UnitType\n",
    "from cntk.ops import input_variable, cross_entropy_with_softmax, classification_error\n",
    "from cntk.persist import load_model, save_model\n",
    "from cntk.blocks import LSTM, Stabilizer\n",
    "from cntk.layers import Recurrence, Dense, Dropout, BatchNormalization\n",
    "from cntk.utils import get_train_eval_criterion, get_train_loss\n",
    "from cntk.device import set_default_device, gpu\n",
    "\n",
    "# Set to GPU, run if GPU is available\n",
    "#set_default_device(gpu(0))\n",
    "\n",
    "# model hyperparameters\n",
    "hidden_dim = 256\n",
    "num_layers = 2\n",
    "minibatch_size = 100 # also how much time we unroll the RNN for\n",
    "\n",
    "# Get data\n",
    "def get_data(p, minibatch_size, data, char_to_ix, vocab_dim):\n",
    "\n",
    "    xi = [char_to_ix[ch] for ch in data[p:p+minibatch_size]]\n",
    "    yi = [char_to_ix[ch] for ch in data[p+1:p+minibatch_size+1]]\n",
    "    \n",
    "    X = np.eye(vocab_dim, dtype=np.float32)[xi]\n",
    "    Y = np.eye(vocab_dim, dtype=np.float32)[yi]\n",
    "\n",
    "    # return a list of numpy arrays for each of X (features) and Y (labels)\n",
    "    return [X], [Y]\n",
    "\n",
    "# Sample from the network\n",
    "def sample(root, ix_to_char, vocab_dim, char_to_ix, prime_text='', use_hardmax=True, length=300, temperature=1.0):\n",
    "\n",
    "    # temperature: T < 1 means smoother; T=1.0 means same; T > 1 means more peaked\n",
    "    def apply_temp(p):\n",
    "        # apply temperature\n",
    "        p = np.power(p, (temperature))\n",
    "        # renormalize and return\n",
    "        return (p / np.sum(p))\n",
    "\n",
    "    def sample_word(p):\n",
    "        if use_hardmax:\n",
    "            w = np.argmax(p, axis=2)[0,0]\n",
    "        else:\n",
    "            # normalize probabilities then take weighted sample\n",
    "            p = np.exp(p) / np.sum(np.exp(p))            \n",
    "            p = apply_temp(p)\n",
    "            w = np.random.choice(range(vocab_dim), p=p.ravel())\n",
    "        return w\n",
    "\n",
    "    plen = 1\n",
    "    prime = -1\n",
    "\n",
    "    # start sequence with first input    \n",
    "    x = np.zeros((1, vocab_dim), dtype=np.float32)    \n",
    "    if prime_text != '':\n",
    "        plen = len(prime_text)\n",
    "        prime = char_to_ix[prime_text[0]]\n",
    "    else:\n",
    "        prime = np.random.choice(range(vocab_dim))\n",
    "    x[0, prime] = 1\n",
    "    arguments = ([x], [True])\n",
    "\n",
    "    output=[]\n",
    "    output.append(prime)\n",
    "    \n",
    "    # loop through prime text\n",
    "    for i in range(plen):            \n",
    "        p = root.eval(arguments)        \n",
    "        \n",
    "        # reset\n",
    "        x = np.zeros((1, vocab_dim), dtype=np.float32)\n",
    "        if i < plen-1:\n",
    "            idx = char_to_ix[prime_text[i+1]]\n",
    "        else:\n",
    "            idx = sample_word(p)\n",
    "\n",
    "        output.append(idx)\n",
    "        x[0, idx] = 1            \n",
    "        arguments = ([x], [False])\n",
    "    \n",
    "    # loop through length of generated text, sampling along the way\n",
    "    for i in range(length-plen):\n",
    "        p = root.eval(arguments)\n",
    "        idx = sample_word(p)\n",
    "        output.append(idx)\n",
    "\n",
    "        x = np.zeros((1, vocab_dim), dtype=np.float32)\n",
    "        x[0, idx] = 1\n",
    "        arguments = ([x], [False])\n",
    "\n",
    "    # return output\n",
    "    return ''.join([ix_to_char[c] for c in output])\n",
    "\n",
    "def load_data_and_vocab(training_file, convert_to_lower=True):\n",
    "    \n",
    "    # load data\n",
    "    rel_path = training_file\n",
    "    path = rel_path\n",
    "    data = open(path, \"r\", encoding='utf8').read()\n",
    "    \n",
    "    # Do some simple text prep\n",
    "    if convert_to_lower == True:\n",
    "        data = data.lower()\n",
    "    replacements = [[\"’\", \"'\"], \n",
    "                    ['“', '\"'], \n",
    "                    ['”', '\"']]\n",
    "    for r in replacements:\n",
    "        data = data.replace(r[0], r[1])\n",
    "        \n",
    "    chars = sorted(list(set(data)))\n",
    "    data_size, vocab_size = len(data), len(chars)\n",
    "    print('data has %d characters, %d unique.' % (data_size, vocab_size))\n",
    "    char_to_ix = { ch:i for i,ch in enumerate(chars) }\n",
    "    ix_to_char = { i:ch for i,ch in enumerate(chars) }\n",
    "\n",
    "    # write vocab\n",
    "    ff = open(path + \".vocab\", \"w\", encoding='utf8')\n",
    "    for c in chars:\n",
    "        ff.write(\"%s\\n\" % c) if c != '\\n' else ff.write(\"\\n\")\n",
    "    ff.close()\n",
    "    \n",
    "    return data, char_to_ix, ix_to_char, data_size, vocab_size\n",
    "\n",
    "# Creates and trains a character-level language model\n",
    "def train_lm(training_file):\n",
    "\n",
    "    # create the stabilizer function from blocks\n",
    "    stabilize = Stabilizer()\n",
    "\n",
    "    # load the data and vocab\n",
    "    data, char_to_ix, ix_to_char, data_size, vocab_dim = load_data_and_vocab(training_file)\n",
    "\n",
    "    # Source and target inputs to the model\n",
    "    batch_axis = Axis.default_batch_axis()\n",
    "    input_seq_axis = Axis('inputAxis')\n",
    "\n",
    "    input_dynamic_axes = [batch_axis, input_seq_axis]\n",
    "    raw_input = input_variable(shape=(vocab_dim), dynamic_axes=input_dynamic_axes)\n",
    "    raw_labels = input_variable(shape=(vocab_dim), dynamic_axes=input_dynamic_axes)\n",
    "\n",
    "    input_sequence = raw_input\n",
    "    label_sequence = raw_labels\n",
    "\n",
    "    # LSTM\n",
    "    encoder_output = stabilize(input_sequence)\n",
    "    for i in range(0, num_layers):\n",
    "        encoder_output = Recurrence(LSTM(hidden_dim, enable_self_stabilization=True)) (encoder_output.output)\n",
    "        #encoder_output = BatchNormalization() (encoder_output.output)\n",
    "        encoder_output = Dropout(0.3) (encoder_output.output)\n",
    "\n",
    "    # get output of the LSTM\n",
    "    states = encoder_output.output\n",
    "\n",
    "    # dense layer    \n",
    "    z = Dense(vocab_dim) (states)\n",
    "\n",
    "    ce = cross_entropy_with_softmax(z, label_sequence)\n",
    "    errs = classification_error(z, label_sequence)\n",
    "\n",
    "    # Instantiate the trainer object to drive the model training\n",
    "    lr_per_sample = learning_rate_schedule(0.001, UnitType.sample)\n",
    "    momentum_time_constant = momentum_as_time_constant_schedule(1100)\n",
    "    clipping_threshold_per_sample = 5.0\n",
    "    gradient_clipping_with_truncation = True\n",
    "    learner = adam_sgd(z.parameters, lr_per_sample, momentum_time_constant, \n",
    "                           gradient_clipping_threshold_per_sample=clipping_threshold_per_sample,\n",
    "                           gradient_clipping_with_truncation=gradient_clipping_with_truncation)\n",
    "    trainer = Trainer(z, ce, errs, learner)\n",
    "\n",
    "    training_progress_output_freq = 100\n",
    "    sample_freq = 1000\n",
    "    epochs = 50\n",
    "    minibatches_per_epoch = int((data_size / minibatch_size))\n",
    "    minibatches = epochs * minibatches_per_epoch\n",
    "    \n",
    "    e = 0\n",
    "    p = 0\n",
    "    for i in range(0, minibatches):\n",
    "\n",
    "        if p + minibatch_size+1 >= data_size:\n",
    "            p = 0\n",
    "            e += 1\n",
    "            model_filename = \"models/deepjingling-songwriter_epoch%d.dnn\" % e\n",
    "            save_model(z, model_filename)\n",
    "            print(\"Saved model to '%s'\" % model_filename)\n",
    "\n",
    "        # get the data            \n",
    "        features, labels = get_data(p, minibatch_size, data, char_to_ix, vocab_dim)\n",
    "\n",
    "        # Specify the mapping of input variables in the model to actual minibatch data to be trained with\n",
    "        # If it's the start of the data, we specify that we are looking at a new sequence (True)\n",
    "        mask = [False] \n",
    "        if p == 0:\n",
    "            mask = [True]\n",
    "        arguments = ({raw_input : features, raw_labels : labels}, mask)\n",
    "        trainer.train_minibatch(arguments)\n",
    "\n",
    "        if i % training_progress_output_freq == 0:\n",
    "            print(\"Minibatch: {}, Train Loss: {}, Train Evaluation Criterion: {}\".format(i,\n",
    "                      get_train_loss(trainer), get_train_eval_criterion(trainer)))\n",
    "            print(\"Epoch %d, %f %% done\" % (e, ((float(i) / float(minibatches_per_epoch)) - e) * 100.0))\n",
    "        \n",
    "        if i % sample_freq == 0:\n",
    "            print(sample(z, ix_to_char, vocab_dim, char_to_ix))\n",
    "\n",
    "        p += minibatch_size\n",
    "\n",
    "def load_and_sample(model_filename, vocab_filename, prime_text='', use_hardmax=False, length=1000, temperature=1.0):\n",
    "    \n",
    "    # load the model\n",
    "    model = load_model(model_filename)\n",
    "    \n",
    "    # load the vocab\n",
    "    chars = [c[0] for c in open(vocab_filename).readlines()]\n",
    "    char_to_ix = { ch:i for i,ch in enumerate(chars) }\n",
    "    ix_to_char = { i:ch for i,ch in enumerate(chars) }\n",
    "        \n",
    "    #output = sample(model, ix_to_char, len(chars), char_to_ix, prime_text=prime_text, use_hardmax=use_hardmax, length=length, temperature=temperature)\n",
    "    \n",
    "    print(sample(model, ix_to_char, len(chars), char_to_ix))\n",
    "\n",
    "    #ff = open('output.txt', 'w', encoding='utf-8')\n",
    "    #ff.write(output)\n",
    "    #ff.close()\n",
    "\n",
    "if __name__=='__main__':    \n",
    "    \n",
    "    # train the LM\n",
    "    train_lm(\"data/songs.txt\")\n",
    "\n",
    "    # load and sample\n",
    "    #text = \"T\"\n",
    "    #load_and_sample(\"models/shakespeare_epoch13.dnn\", \"shakespeare.txt.vocab\", prime_text=text, use_hardmax=False, length=100, temperature=1.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
