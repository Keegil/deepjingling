{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from music21 import *\n",
    "import numpy as np\n",
    "import glob\n",
    "import math\n",
    "import os\n",
    "from cntk import Trainer, Axis\n",
    "from cntk.learner import adam_sgd, momentum_sgd, momentum_as_time_constant_schedule, learning_rate_schedule, UnitType\n",
    "from cntk.ops import input_variable, cross_entropy_with_softmax, classification_error, binary_cross_entropy, times_transpose, log, squared_error\n",
    "from cntk.persist import load_model, save_model\n",
    "from cntk.blocks import LSTM, Stabilizer\n",
    "from cntk.layers import Recurrence, Dense, Dropout, BatchNormalization\n",
    "from cntk.utils import get_train_eval_criterion, get_train_loss\n",
    "from cntk.device import set_default_device, gpu\n",
    "\n",
    "path = \"midiFiles\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lowerBound = 24 # = [python] index 0 ([R] 1. possision)\n",
    "upperBound = 102 # = first index out of bound => len =78\n",
    "nNotes = upperBound-lowerBound\n",
    "notesDim = nNotes*2\n",
    "hidden_dim = nNotes\n",
    "num_layers = 2\n",
    "\n",
    "\n",
    "batch_len = 16*8 # length of each sequence\n",
    "\n",
    "def loadPieces(midiFiles):\n",
    "    pieces = {}\n",
    "    totalLength= len(midiFiles)\n",
    "    fnameNumber=0\n",
    "    for fname in midiFiles:\n",
    "        fnameNumber+=1\n",
    "        if fname[-4:] not in ('.mid','.MID'):\n",
    "            continue\n",
    "        isNotBackSlash=1\n",
    "        bIndex=0\n",
    "        while(isNotBackSlash):\n",
    "            bIndex-=1\n",
    "            if fname[bIndex]=='\\\\':\n",
    "                bIndex+=1\n",
    "                isNotBackSlash=False\n",
    "        name = fname[bIndex:-4]\n",
    "        print(\"Loading\",name,\"...\",fnameNumber,'/',totalLength)\n",
    "        outMatrix = midi2MusicMinMatrix(fname)\n",
    "        if len(outMatrix) < batch_len:\n",
    "            print(\"     Loaded\", name,'failed')\n",
    "            continue\n",
    "        else:\n",
    "            print(\"     Loaded\", name,'done')\n",
    "        pieces[name] = outMatrix\n",
    "    return(pieces)\n",
    "\n",
    "\n",
    "\n",
    "def midi2MusicMinMatrix(parseLink):\n",
    "    midiFile = converter.parse(parseLink)\n",
    "    #if (midiFile.flat.getTimeSignatures().timeSignature.numerator not in (2,4)) or (midiFile.flat.getTimeSignatures().timeSignature.denominator not in (2,4)):\n",
    "    #\tprint('     Track: is not 4/4 or similar')\n",
    "    #\treturn(0)\t\n",
    "    if (midiFile.flat.getTimeSignatures().timeSignature.numerator not in (2,4)) or (midiFile.flat.getTimeSignatures().timeSignature.denominator not in (2,4)):\n",
    "        print('     Track: is not 4/4')\n",
    "        printing = '     Track is '+str(midiFile.flat.getTimeSignatures().timeSignature.numerator)+' / ' + str(midiFile.flat.getTimeSignatures().timeSignature.denominator)\n",
    "        print(printing)\n",
    "        return(0)\t\n",
    "    midiPartLen=len(midiFile)\n",
    "    maxTime = midiFile.highestTime\n",
    "    outMatrix = [[[0,0] for tang in range(upperBound-lowerBound)]+[[lenTimes16/4]] for lenTimes16 in range(math.ceil(maxTime*4+2))]\n",
    "    # outMatrix = [[[0,0] for tang in range(upperBound-lowerBound)]+[lenTimes16/4] for lenTimes16 in range(math.ceil(maxTime*4+2))]\n",
    "    for t in range(midiPartLen):\n",
    "        try:\n",
    "            instrument=midiFile[t].getInstrument(returnDefault=False).instrumentName\n",
    "        except: \n",
    "            instrument='Piano'\n",
    "        #if not instrument:\n",
    "        #\tinstrument='Piano'\n",
    "        #if instrument!='Piano':\n",
    "        #\tprint('          Part',t,'/',midiPartLen-1,' dropped, instrument was not piano')\n",
    "        #\tcontinue\t\t\t\n",
    "        notes=midiFile[t].flat.notes\n",
    "        for i in range(0,len(notes)):\n",
    "            if not notes[i].isChord:\n",
    "                if (notes[i].pitch.midi<lowerBound) or (notes[i].pitch.midi>=upperBound):\n",
    "                    continue\n",
    "                timeIndex=round(notes[i].offset*4)+1\n",
    "                notePitch=notes[i].pitch.midi-lowerBound\n",
    "                outMatrix[timeIndex][notePitch]=[1,1]\n",
    "                for holdLen in range(1,round(notes[i].duration.quarterLength*4)):\n",
    "                    outMatrix[timeIndex+holdLen][notePitch][1]=1\n",
    "            else:\n",
    "                timeIndex=round(notes[i].offset*4)+1\n",
    "                duration=round(notes[i].duration.quarterLength*4)+1\n",
    "                for j in range(len(notes[i])):\n",
    "                    if (notes[i][j].pitch.midi<lowerBound) or (notes[i][j].pitch.midi>=upperBound):\n",
    "                        continue\n",
    "                    #timeIndex=round(notes[i][j].offset*4)+1\n",
    "                    notePitch=notes[i][j].pitch.midi-lowerBound\n",
    "                    outMatrix[timeIndex][notePitch]=[1,1]\n",
    "                    for holdLen in range(1,duration):\n",
    "                        outMatrix[timeIndex+holdLen][notePitch][1]=1\t\n",
    "    return(outMatrix)\n",
    "\n",
    "def MusicMinMatrix2midi(MusicMinMatrixPart,S,bpm=100):\n",
    "    #S = stream.Score()\n",
    "    nTime=len(MusicMinMatrixPart)\n",
    "    S.insert(0,tempo.MetronomeMark(number=bpm))\n",
    "    p1 = stream.Part()\n",
    "    p1.id = 'part1'\n",
    "    nCons=0\n",
    "    thisIndex=0\n",
    "    mLen = len(MusicMinMatrixPart[0])\n",
    "    for j in range(mLen-1):\n",
    "        for i in range(nTime):\n",
    "            if (nCons!=0) and (MusicMinMatrixPart[i][j] in ([0,0],[1,1])):\n",
    "                n.duration.quarterLength = 0.25*nCons\n",
    "                p1.insert(MusicMinMatrixPart[thisIndex][mLen-1][0],n)\n",
    "                nCons=0\n",
    "            if MusicMinMatrixPart[i][j]==[1,1]:\n",
    "                n = note.Note()\n",
    "                n.midi = lowerBound+j\n",
    "                thisIndex = i\n",
    "                nCons+=1\n",
    "            elif (MusicMinMatrixPart[i][j]==[0,1]) and (nCons!=0):\n",
    "                nCons+=1\n",
    "        if (nCons != 0):\n",
    "            n.duration.quarterLength = 0.25*nCons\n",
    "            p1.insert(MusicMinMatrixPart[thisIndex][mLen-1][0],n)\n",
    "            nCons=0\n",
    "    S.insert(0,p1)\n",
    "    \n",
    "    \n",
    "def Piece2Data(Pieces):\n",
    "    tempData = sum(list(Pieces.values()),[])\n",
    "    data=[sum(timePart,[]) for timePart in tempData]\n",
    "    return(np.array(data,dtype=np.float32))\n",
    "    \n",
    "\n",
    "def get_data(p, minibatch_size, data):\n",
    "    x = data[p:p+minibatch_size,0:156]\n",
    "    y = data[p+1:p+minibatch_size+1,0:156]\n",
    "    #xsum=x.sum(axis=1, keepdims=True)\n",
    "    \n",
    "    X = x/np.maximum(x.sum(axis=1, keepdims=True),1)\n",
    "    Y = y/np.maximum(y.sum(axis=1, keepdims=True),1)\n",
    "    return([X],[Y])\n",
    "\n",
    "def data2MusicMatric(data):\n",
    "    timeIndex=0\n",
    "    MusicMatrix=[0]*len(data)\n",
    "    MusicMatrixRow=[0]*(upperBound-lowerBound)\n",
    "    for i in range(len(data)):\n",
    "        for j in range(upperBound-lowerBound):\n",
    "            MusicMatrixRow[j] = [int(data[i,j*2]),int(data[i,j*2+1])]\n",
    "        MusicMatrix[i] = MusicMatrixRow+[[timeIndex]]\n",
    "        timeIndex+=0.25\n",
    "    return(MusicMatrix)\n",
    "\n",
    "\n",
    "\n",
    "def Output2data(p,threshold=1.11):\n",
    "    p=p[0][0]\n",
    "    return(list((p>p.mean()+threshold)*1))\n",
    "\n",
    "# prime_data=data[5:20,:]\n",
    "def sample(z,prime_data=np.array([[0]*((upperBound-lowerBound)*2)],dtype=np.float32),length=300,threshold=1.11):\n",
    "    output=np.zeros((length, 156), dtype=np.float32)\n",
    "    if len(prime_data[0])!=156:\n",
    "        prime_data[:,0:156]\n",
    "    randomNumb=np.random.choice(range(78))\n",
    "    if len(prime_data)==1: \n",
    "        prime_data[0,randomNumb*2] = 1\n",
    "        prime_data[0,randomNumb*2+1] = 1\n",
    "    for i in range(len(prime_data)):\n",
    "        x=prime_data[i]\n",
    "        inputen=[np.array([x/np.maximum(x.sum(),1)],dtype=np.float32)]\n",
    "        if i==0:\n",
    "            arguments=(inputen,[True])\n",
    "        else:\n",
    "            arguments=(inputen,[False])\n",
    "        p = z.eval(arguments)\n",
    "        \n",
    "    x=prime_data[len(prime_data)-1]\n",
    "    \n",
    "    for i in range(length):\n",
    "        inputen=[np.array([x/np.maximum(x.sum(),1)],dtype=np.float32)]\n",
    "        arguments=(inputen,[False])\n",
    "        p = z.eval(arguments)\n",
    "        output[i,:]=Output2data(p,threshold=threshold)\n",
    "        x=output[i,:]\n",
    "    return(output)#return([list(testout[i]) for i in range(300)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading jingbellPiano ... 1 / 1\n",
      "     Loaded jingbellPiano done\n"
     ]
    }
   ],
   "source": [
    "midiFiles = glob.glob(path + '/*.mid')\n",
    "Pieces = loadPieces(midiFiles)\n",
    "data = Piece2Data(Pieces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_mm(data):\n",
    "\n",
    "    # create the stabilizer function from blocks\n",
    "    stabilize = Stabilizer()\n",
    "    data_size=len(data)\n",
    "\n",
    "    # load the data and vocab\n",
    "    # data, char_to_ix, ix_to_char, data_size, vocab_dim = load_data_and_vocab(training_file)\n",
    "\n",
    "    # Source and target inputs to the model\n",
    "    batch_axis = Axis.default_batch_axis()\n",
    "    input_seq_axis = Axis('inputAxis')\n",
    "\n",
    "    input_dynamic_axes = [batch_axis, input_seq_axis]\n",
    "    raw_input = input_variable(shape=(notesDim), dynamic_axes=input_dynamic_axes)\n",
    "    raw_labels = input_variable(shape=(notesDim), dynamic_axes=input_dynamic_axes)\n",
    "\n",
    "    input_sequence = raw_input\n",
    "    label_sequence = raw_labels\n",
    "\n",
    "    # LSTM\n",
    "    encoder_output = stabilize(input_sequence)\n",
    "    for i in range(0, num_layers):\n",
    "        encoder_output = Recurrence(LSTM(hidden_dim, enable_self_stabilization=True)) (encoder_output.output)\n",
    "        #encoder_output = BatchNormalization() (encoder_output.output)\n",
    "        encoder_output = Dropout(0.3) (encoder_output.output)\n",
    "\n",
    "    # get output of the LSTM\n",
    "    states = encoder_output.output\n",
    "\n",
    "    # dense layer    \n",
    "    z = Dense(notesDim) (states)\n",
    "\n",
    "    # ce = binary_cross_entropy(z, label_sequence)\n",
    "    ce = cross_entropy_with_softmax(z, label_sequence)\n",
    "    # ce = times_transpose(label_sequence,log(z))\n",
    "    # ce = squared_error(z,label_sequence)\n",
    "    # errs = squared_error(z,label_sequence)\n",
    "    errs = classification_error(z, label_sequence)\n",
    "\n",
    "    # Instantiate the trainer object to drive the model training\n",
    "    lr_per_sample = learning_rate_schedule(0.001, UnitType.sample)\n",
    "    momentum_time_constant = momentum_as_time_constant_schedule(1100)\n",
    "    clipping_threshold_per_sample = 5.0\n",
    "    gradient_clipping_with_truncation = True\n",
    "    learner = adam_sgd(z.parameters, lr_per_sample, momentum_time_constant, \n",
    "                           gradient_clipping_threshold_per_sample=clipping_threshold_per_sample,\n",
    "                           gradient_clipping_with_truncation=gradient_clipping_with_truncation)\n",
    "    trainer = Trainer(z, ce, errs, learner)\n",
    "    \n",
    "    minibatch_size = 10 \n",
    "    training_progress_output_freq = 200\n",
    "    sample_freq = 20\n",
    "    epochs = 50\n",
    "    minibatches_per_epoch = int((data_size / minibatch_size))\n",
    "    minibatches = epochs * minibatches_per_epoch\n",
    "    \n",
    "    e = 0\n",
    "    p = 0\n",
    "    for i in range(0, minibatches):\n",
    "\n",
    "        if p + minibatch_size+1 >= data_size:\n",
    "            p = 0\n",
    "            e += 1\n",
    "            model_filename = \"models/deepjingling-composer_epoch%d.dnn\" % e\n",
    "            save_model(z, model_filename)\n",
    "            print(\"Saved model to '%s'\" % model_filename)\n",
    "\n",
    "        # get the data            \n",
    "        features, labels = get_data(p, minibatch_size, data)\n",
    "\n",
    "        # Specify the mapping of input variables in the model to actual minibatch data to be trained with\n",
    "        # If it's the start of the data, we specify that we are looking at a new sequence (True)\n",
    "        mask = [False] \n",
    "        if p == 0:\n",
    "            mask = [True]\n",
    "        arguments = ({raw_input : features, raw_labels : labels}, mask)\n",
    "        trainer.train_minibatch(arguments)\n",
    "\n",
    "        if i % training_progress_output_freq == 0:\n",
    "            print(\"Minibatch: {}, Train Loss: {}, Train Evaluation Criterion: {}\".format(i,\n",
    "                      get_train_loss(trainer), get_train_eval_criterion(trainer)))\n",
    "            print(\"Epoch %d, %f %% done\" % (e, ((float(i) / float(minibatches_per_epoch)) - e) * 100.0))\n",
    "        \n",
    "        #if i % sample_freq == 0:\n",
    "        #    print('Sample:')\n",
    "        #    sample(z, vocab_dim)\n",
    "\n",
    "        p += minibatch_size\n",
    "    return(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minibatch: 0, Train Loss: 5.049293899536133, Train Evaluation Criterion: 1.0\n",
      "Epoch 0, 0.000000 % done\n",
      "Saved model to 'models/deepjingling-composer_epoch1.dnn'\n",
      "Minibatch: 200, Train Loss: 4.526654815673828, Train Evaluation Criterion: 0.7625\n",
      "Epoch 1, 96.078431 % done\n",
      "Saved model to 'models/deepjingling-composer_epoch2.dnn'\n",
      "Saved model to 'models/deepjingling-composer_epoch3.dnn'\n",
      "Minibatch: 400, Train Loss: 3.151409721374512, Train Evaluation Criterion: 0.9375\n",
      "Epoch 3, 92.156863 % done\n",
      "Saved model to 'models/deepjingling-composer_epoch4.dnn'\n",
      "Saved model to 'models/deepjingling-composer_epoch5.dnn'\n",
      "Minibatch: 600, Train Loss: 2.5927192687988283, Train Evaluation Criterion: 0.5625\n",
      "Epoch 5, 88.235294 % done\n",
      "Saved model to 'models/deepjingling-composer_epoch6.dnn'\n",
      "Saved model to 'models/deepjingling-composer_epoch7.dnn'\n",
      "Minibatch: 800, Train Loss: 3.2467010498046873, Train Evaluation Criterion: 0.6125\n",
      "Epoch 7, 84.313725 % done\n",
      "Saved model to 'models/deepjingling-composer_epoch8.dnn'\n",
      "Saved model to 'models/deepjingling-composer_epoch9.dnn'\n",
      "Minibatch: 1000, Train Loss: 2.574920654296875, Train Evaluation Criterion: 0.3107142925262451\n",
      "Epoch 9, 80.392157 % done\n",
      "Saved model to 'models/deepjingling-composer_epoch10.dnn'\n",
      "Saved model to 'models/deepjingling-composer_epoch11.dnn'\n",
      "Minibatch: 1200, Train Loss: 2.2157499313354494, Train Evaluation Criterion: 0.3625\n",
      "Epoch 11, 76.470588 % done\n",
      "Saved model to 'models/deepjingling-composer_epoch12.dnn'\n",
      "Saved model to 'models/deepjingling-composer_epoch13.dnn'\n",
      "Minibatch: 1400, Train Loss: 3.376764678955078, Train Evaluation Criterion: 0.8333333015441895\n",
      "Epoch 13, 72.549020 % done\n",
      "Saved model to 'models/deepjingling-composer_epoch14.dnn'\n",
      "Saved model to 'models/deepjingling-composer_epoch15.dnn'\n",
      "Minibatch: 1600, Train Loss: 3.6491321563720702, Train Evaluation Criterion: 1.0\n",
      "Epoch 15, 68.627451 % done\n",
      "Saved model to 'models/deepjingling-composer_epoch16.dnn'\n",
      "Saved model to 'models/deepjingling-composer_epoch17.dnn'\n",
      "Minibatch: 1800, Train Loss: 3.1595191955566406, Train Evaluation Criterion: 0.85\n",
      "Epoch 17, 64.705882 % done\n",
      "Saved model to 'models/deepjingling-composer_epoch18.dnn'\n",
      "Saved model to 'models/deepjingling-composer_epoch19.dnn'\n",
      "Minibatch: 2000, Train Loss: 3.175604057312012, Train Evaluation Criterion: 0.7300000190734863\n",
      "Epoch 19, 60.784314 % done\n",
      "Saved model to 'models/deepjingling-composer_epoch20.dnn'\n",
      "Saved model to 'models/deepjingling-composer_epoch21.dnn'\n",
      "Minibatch: 2200, Train Loss: 3.0808027267456053, Train Evaluation Criterion: 0.85\n",
      "Epoch 21, 56.862745 % done\n",
      "Saved model to 'models/deepjingling-composer_epoch22.dnn'\n",
      "Saved model to 'models/deepjingling-composer_epoch23.dnn'\n",
      "Minibatch: 2400, Train Loss: 2.494221878051758, Train Evaluation Criterion: 0.65\n",
      "Epoch 23, 52.941176 % done\n",
      "Saved model to 'models/deepjingling-composer_epoch24.dnn'\n",
      "Saved model to 'models/deepjingling-composer_epoch25.dnn'\n",
      "Minibatch: 2600, Train Loss: 3.644753265380859, Train Evaluation Criterion: 0.775\n",
      "Epoch 25, 49.019608 % done\n",
      "Saved model to 'models/deepjingling-composer_epoch26.dnn'\n",
      "Saved model to 'models/deepjingling-composer_epoch27.dnn'\n",
      "Minibatch: 2800, Train Loss: 1.8911762237548828, Train Evaluation Criterion: 0.4875\n",
      "Epoch 27, 45.098039 % done\n",
      "Saved model to 'models/deepjingling-composer_epoch28.dnn'\n",
      "Saved model to 'models/deepjingling-composer_epoch29.dnn'\n",
      "Minibatch: 3000, Train Loss: 2.1208044052124024, Train Evaluation Criterion: 0.625\n",
      "Epoch 29, 41.176471 % done\n",
      "Saved model to 'models/deepjingling-composer_epoch30.dnn'\n",
      "Saved model to 'models/deepjingling-composer_epoch31.dnn'\n",
      "Minibatch: 3200, Train Loss: 2.355358123779297, Train Evaluation Criterion: 0.7\n",
      "Epoch 31, 37.254902 % done\n",
      "Saved model to 'models/deepjingling-composer_epoch32.dnn'\n",
      "Saved model to 'models/deepjingling-composer_epoch33.dnn'\n",
      "Minibatch: 3400, Train Loss: 1.4202885627746582, Train Evaluation Criterion: 0.4125\n",
      "Epoch 33, 33.333333 % done\n",
      "Saved model to 'models/deepjingling-composer_epoch34.dnn'\n",
      "Saved model to 'models/deepjingling-composer_epoch35.dnn'\n",
      "Minibatch: 3600, Train Loss: 1.5088217735290528, Train Evaluation Criterion: 0.4375\n",
      "Epoch 35, 29.411765 % done\n",
      "Saved model to 'models/deepjingling-composer_epoch36.dnn'\n",
      "Saved model to 'models/deepjingling-composer_epoch37.dnn'\n",
      "Minibatch: 3800, Train Loss: 1.1458368301391602, Train Evaluation Criterion: 0.3625\n",
      "Epoch 37, 25.490196 % done\n",
      "Saved model to 'models/deepjingling-composer_epoch38.dnn'\n",
      "Saved model to 'models/deepjingling-composer_epoch39.dnn'\n",
      "Minibatch: 4000, Train Loss: 1.8350914001464844, Train Evaluation Criterion: 0.65\n",
      "Epoch 39, 21.568627 % done\n",
      "Saved model to 'models/deepjingling-composer_epoch40.dnn'\n",
      "Saved model to 'models/deepjingling-composer_epoch41.dnn'\n",
      "Minibatch: 4200, Train Loss: 1.430625057220459, Train Evaluation Criterion: 0.5583333015441895\n",
      "Epoch 41, 17.647059 % done\n",
      "Saved model to 'models/deepjingling-composer_epoch42.dnn'\n",
      "Saved model to 'models/deepjingling-composer_epoch43.dnn'\n",
      "Minibatch: 4400, Train Loss: 1.449246883392334, Train Evaluation Criterion: 0.5666666507720948\n",
      "Epoch 43, 13.725490 % done\n",
      "Saved model to 'models/deepjingling-composer_epoch44.dnn'\n",
      "Saved model to 'models/deepjingling-composer_epoch45.dnn'\n",
      "Minibatch: 4600, Train Loss: 2.135126495361328, Train Evaluation Criterion: 0.65\n",
      "Epoch 45, 9.803922 % done\n",
      "Saved model to 'models/deepjingling-composer_epoch46.dnn'\n",
      "Saved model to 'models/deepjingling-composer_epoch47.dnn'\n",
      "Minibatch: 4800, Train Loss: 1.7332122802734375, Train Evaluation Criterion: 0.6\n",
      "Epoch 47, 5.882353 % done\n",
      "Saved model to 'models/deepjingling-composer_epoch48.dnn'\n",
      "Saved model to 'models/deepjingling-composer_epoch49.dnn'\n",
      "Minibatch: 5000, Train Loss: 1.314891529083252, Train Evaluation Criterion: 0.5583333015441895\n",
      "Epoch 49, 1.960784 % done\n"
     ]
    }
   ],
   "source": [
    "z=train_mm(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#prime_data=np.array([[0]*((upperBound-lowerBound)*2)],dtype=np.float32)\n",
    "#print(prime_data)\n",
    "#len(prime_data[0])\n",
    "#print(len(prime_data))\n",
    "#data[0]\n",
    "#data[1:3]\n",
    "testout=sample(z,prime_data=np.array([[0]*((upperBound-lowerBound)*2)],dtype=np.float32),length=300,threshold=5)\n",
    "musicM=data2MusicMatric(testout)\n",
    "S = stream.Score()\n",
    "MusicMinMatrix2midi(musicM,S,100)\n",
    "sp=midi.realtime.StreamPlayer(S)\n",
    "sp.play()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "S.write('midi', 'notFirstMusic') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
